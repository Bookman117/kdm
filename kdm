#!/bin/bash
#Purpose: Deploy kubernetes on ubuntu server 20.04/22.04 LTS & Rocky Linux 8/9 & RHEL 8/9.
#Create-Date: 2022-08-10

# Environment pre-setting
function os-detection()
{
  cat /etc/os-release &> /dev/null
  [ $? == 0 ] && export OS_VERSION=$(cat /etc/os-release | grep 'PRETTY_NAME' | cut -d '"' -f 2) || OS_VERSION=macOS
  echo ${OS_VERSION} | grep "Rocky" &> /dev/null && export CRIO_OS_VERSION="CentOS_8_Stream"
  echo ${OS_VERSION} | grep "Ubuntu" &> /dev/null && export CRIO_OS_VERSION="xUbuntu_20.04"
  echo ${OS_VERSION} | grep "Red Hat Enterprise Linux" &> /dev/null && export CRIO_OS_VERSION="RHEL_8"
  echo ${OS_VERSION} | grep "Alpine Linux" &> /dev/null && export CRIO_OS_VERSION="Alpine"
  echo ${OS_VERSION} | grep "macOS" &> /dev/null && export CRIO_OS_VERSION="macOS"
  #dnf lock os version
  #[ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "cat /etc/os-release | cut -d '"' -f 2 | sudo tee /etc/yum/vars/releasever"
}
# ---

# Setup basic network package
os-detection
install=1
[ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && which wget &> /dev/null && install=0
[ "${CRIO_OS_VERSION}" == "RHEL_8" ] && CRIO_OS_VERSION="CentOS_8_Stream" && which wget &> /dev/null && install=0
[ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && [ "${install}" == "1" ] && sudo dnf update -y && sudo dnf install -y --allowerasing dnf-command\(versionlock\) jq net-tools dnsutils nc wget && clear
[ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && install=2
[ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && which route &> /dev/null && install=0
[ "${install}" == "2" ] && sudo apt-get update -qy && sudo apt-get install -qy net-tools iputils-ping dnsutils netcat && clear
[ "${CRIO_OS_VERSION}" == "macOS" ] &&
os-detection  
# ---

# Set variables
# Version control
export VER_SWITCH=sub
export CRI_RELEASE=1.26
export CRI_SUBVER=${CRI_RELEASE}.1
export KUBE_RELEASE=1.26
export KUBE_SUBVER=${KUBE_RELEASE}.1
export KUBE_INIT_VER=v${KUBE_SUBVER}
export KUBE_REGISTRY=registry.k8s.io
export ROOK_TAG=v1.10.12
export PACKAGE_LIST="cri-o kubeadm kubectl kubelet podman helm"
#disable/permissive/enforcing
export SELINUX_MODE=enforcing
#disable/enable
export FIREWALLD_ENABLE=disable
count=0
cat /dev/null > /tmp/buffer
while [ ${count} -le 9 ]
  do
    test="${CRI_RELEASE}.${count}"
    echo -n "${test} " >> /tmp/buffer
    count=$((${count}+1))
  done
echo "${VER_SWITCH}" | grep "latest"  &> /dev/null
[ $? == 0 ] && export CRI_ALL_VERSION=${CRI_SUBVER} || export CRI_ALL_VERSION=`cat /tmp/buffer | sed /\n/d`
# Network info
export IP=$(ip a | grep -E 'en|eth' | grep 'inet' | awk '{ print $2 }' | cut -d '/' -f 1 | head -n 1)
export NETID=$(ip a | grep 'en' | grep 'inet' | awk '{ print $2 }' | cut -d '.' -f 1-3 | head -n 1)
[ "${CRIO_OS_VERSION}" != "macOS" ] && export GATEWAY=$(route -n | tr -s " " | grep '^0.0.0.0' | cut -d " " -f 2 | grep "${NETID}")
[ "${CRIO_OS_VERSION}" != "macOS" ] && export NETMASK=$(route -n | grep 'en' | grep -w 'U' | awk '{ print $3 }')

[ "${CRIO_OS_VERSION}" == "macOS" ] && export GATEWAY=$(netstat -nr | grep '^default' | grep "en[0-9]" | awk '{ print $2 }')
[ "${CRIO_OS_VERSION}" == "macOS" ] && export NETMASK="??"
# Storage
export CEPH_DISK="/dev/sdb"
# Kube-VIP
export VIP_TARGET=$(($(cat /etc/hosts | grep "${NETID}" | grep '\-m1' | awk '{ print $1 }' | cut -d '.' -f 4)-1))
export KUBE_VIP="${NETID}.${VIP_TARGET}"
export KUBE_INTERFACE=$(ip a | grep -B 3 "${IP}" | grep 'ens' | head -n 1 | awk '{ print $2 }' | sed 's/://g')
echo "${OS_VERSION}" | grep 'Rocky Linux 8' &> /dev/null
[ $? == 0 ] && export NETWORK_UUID=$(cat /etc/sysconfig/network-scripts/ifcfg-${KUBE_INTERFACE} | grep 'UUID' | cut -d '=' -f 2)
# node & service
export CP_NODES=$(cat /etc/hosts | grep -vE '#|ip6' | grep "${NETID}" | awk '{ print $2 }' | grep "\-m" | tr -s '\n' ' ')
export WK_NODES=$(cat /etc/hosts | grep -vE '#|ip6' | grep "${NETID}" | awk '{ print $2 }' | grep "\-w" | tr -s '\n' ' ')
export ALL_NODES=$(cat /etc/hosts | grep -vE '#|ip6' | grep "${NETID}" | awk '{ print $2 }' | grep -E "\-m|\-w" | tr -s '\n' ' ')
export ALL_NODES_EX_LOCALHOST=$(cat /etc/hosts | grep -vE '#|ip6' | grep "${NETID}" | awk '{ print $2 }' | grep -E "\-m|\-w" | grep -v `hostname` | tr -s '\n' ' ')
# text color setting
export NC="\033[0m" # Color reset
export BLACK="\033[0;30m"
export RED="\033[0;31m"
export GREEN="\033[0;32m"
export YELLOW="\033[0;33m"
export BLUE="\033[0;34m"
export PURPLE="\033[0;35m"
export CYAN="\033[0;36m"
export WHITE="\033[0;37m"
# for kubernetes project
export NAME_SPACE_0="kube-system"
export NAME_SPACE_1="local-path-storage"
export NAME_SPACE_2="metallb-system"
export NAME_SPACE_3="ingress-nginx"
export NAME_SPACE_4="jenkins"
export NAME_SPACE_5="quay"
export NAME_SPACE_6="gf" #grafana
export NAME_SPACE_7="landlord"
export NAME_SPACE_8="rook-ceph"
# kubernetes project storageclass
export STORAGE_CLASS="rook-cephfs"
#export STORAGE_CLASS="local-path"
# ---

# functions >>>
function start-info()
{
  for install_list in ${CP_NODES} ${WK_NODES}
    do
      nc -z -w 1 ${install_list} 10250 > /dev/null 2>&1
      [ $? == 0 ] && status=1 || status=0
      [ "${status}" == "1" ] && cluster_list=$(ssh ${install_list} kubectl get nodes 2> /dev/null | tail -n +2 | cut -d " " -f 1 | tr -s '\n' ' ') && cluster_ver=$(ssh ${install_list} kubectl get nodes 2> /dev/null | grep '\-m' | awk '{ print $5}' | head -n 1) && break
      [ "${status}" == "0" ] && continue
    done
  nc -z -w 1 `hostname` 10250 > /dev/null 2>&1
  [ $? != 0 ] && meassage="     | ${RED}This node not activate.${NC}"
  if [ "${status}" == "1" ]
    then
      echo -en "${GREEN}●${NC} Kubernetes deployed\t| ${cluster_ver}"
      echo -e "${YELLOW} [ Input parameter \"help\" display more information ]${NC}"
      #show nodes info
      echo -e "  ├─ Active nodes${meassage}"
      echo ${cluster_list} | grep '\-m' &> /dev/null
      [ $? == 0 ] && echo -e "  │  ├─ control-plane\t| ${GREEN}`echo ${cluster_list} | tr -s ' ' '\n' | grep '\-m' | tr -s '\n' ' '`${NC}" || echo "  │  ├─ control-plane\t| --"
      echo ${cluster_list} | grep '\-w' &> /dev/null
      [ $? == 0 ] && echo -e "  │  └─ worker\t\t| ${GREEN}`echo ${cluster_list} | tr -s ' ' '\n' | grep '\-w' | tr -s '\n' ' '`${NC}" || echo -e "  │  └─ worker\t\t| --"
      #show storageclass info
      storageclass_quantity=$(kubectl get storageclass -A 2> /dev/null | tail -n +2 | wc -l)
      storageclass_list=$(kubectl get storageclass -A 2> /dev/null | tail -n +2 | awk '{ print $1 }' | tr -s '\n' ' ' | sed 's/.$//')
      echo "${storageclass_quantity}" | grep '^0' &> /dev/null
      [ $? == 0 ] && echo -e "  ├─ StorageClass\t| ${YELLOW}Not deployed any storageclass"${NC} || \
      for list in ${storageclass_list}
        do
          echo -e "  ├─ StorageClass\t| ${GREEN}${list} deployed${NC}"
        done
      #show monitoring info
      kubectl get pods -A | grep 'metrics' &> /dev/null
      [ $? == 0 ] && echo -e "  ├─ Monitoring\t\t| ${GREEN}metrics deployed${NC}" || echo -e "  ├─ Monitoring\t\t| ${YELLOW}metrics not deploy${NC}"
      kubectl get pods -A | grep 'prometheus' &> /dev/null
      [ $? == 0 ] && echo -e "  └─ Monitoring\t\t| ${GREEN}prometheus deployed${NC}" || echo -e "  └─ Monitoring\t\t| ${YELLOW}prometheus not deploy${NC}"
    else
      echo -en "${YELLOW}●${NC} Kubernetes not detected"
      echo -e "${YELLOW} [ Input parameter \"help\" display more information ]${NC}"
      echo -e "  └─ Nodes plan list"
      echo -e "     ├─ control-plane\t| ${YELLOW}`echo -e "${CP_NODES}"`${NC}"
      echo -e "     └─ worker nodes\t| ${YELLOW}`echo ${WK_NODES}`${NC}"
  fi
}

function sys-variable ()
{
  source ~/bin/kdm &> /dev/null
  echo -e "${YELLOW}Variable list${NC}"
  echo -e " > VER_SWITCH: ${YELLOW}${VER_SWITCH}${NC}"
  echo -e " > OS_VERSION: ${YELLOW}${OS_VERSION}${NC}"
  echo -e " > CRIO_OS_VERSION: ${YELLOW}${CRIO_OS_VERSION}${NC}"
  echo -e " > CRI_RELEASE: ${YELLOW}${CRI_RELEASE}${NC}"
  echo -e " > CRI_SUBVER: ${YELLOW}${CRI_SUBVER}${NC}"
  echo -e " > KUBE_RELEASE: ${YELLOW}${KUBE_RELEASE}${NC}"
  echo -e " > KUBE_SUBVER: ${YELLOW}${KUBE_SUBVER}${NC}"
  echo -e " > CRI_ALL_VERSION: ${YELLOW}${CRI_ALL_VERSION}${NC}"
  echo -e " > ROOK_TAG: ${YELLOW}${ROOK_TAG}${NC}"; echo
  echo -e " > SELINUX_MODE: ${YELLOW}${SELINUX_MODE}${NC}"
  echo -e " > KUBE_VIP: ${YELLOW}${KUBE_VIP}${NC}"
  echo -e " > KUBE_INTERFACE: ${YELLOW}${KUBE_INTERFACE}${NC}"
  echo -e " > IP: ${YELLOW}${IP}${NC}"
  echo -e " > NETID: ${YELLOW}${NETID}${NC}"
  echo -e " > GATEWAY: ${YELLOW}${GATEWAY}${NC}"
  echo -e " > NETMASK: ${YELLOW}${NETMASK}${NC}"
  echo -e " > CP_NODES: ${YELLOW}${CP_NODES}${NC}"
  echo -e " > WK_NODES: ${YELLOW}${WK_NODES}${NC}"; echo
}

function sys-check()
{
  [ -z ${2} ] && node-message ${@} && exit
  #[ -z ${2} ] && node-selector hosts
  node-selector ${@}

  for install_list in ${cp_nodes} ${wk_nodes}
    do
      echo -e "${YELLOW}${install_list} | System status${NC}"
      nc -z -w 1 ${install_list} 22 > /dev/null 2>&1
      [ $? != 0 ] && echo -e " [${RED}●${NC}] ${install_list} This node not available\n" && continue
      #modules
      sys_modules=$(ssh ${install_list} lsmod | awk '{ print $1 }' | grep -E 'br_netfilter|overlay' | sed ":a;N;s/\n/ | /g")
      echo -e " [${GREEN}●${NC}] modules:\t\t${sys_modules}"
      #SELinux
      status=0
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo sestatus | grep 'SELinux status:' | grep 'disabled'" &> /dev/null && echo -e " [${GREEN}●${NC}] SELinux\t\tdisabled" && status=1
      [ ${status} == 0 ] && [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo sestatus | grep 'SELinux status:' | grep 'enabled'" &> /dev/null && se_status=$(ssh ${install_list} sudo sestatus | grep 'Current mode:' | awk '{ print $3 }') && echo -e " [${YELLOW}●${NC}] SELinux:\t\t${se_status}"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo sestatus | grep 'SELinux status:' | grep 'disabled'" &> /dev/null && echo -e " [${GREEN}●${NC}] SELinux disabled"
      [ ${status} == 0 ] && [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo sestatus | grep 'SELinux status:' | grep 'enabled'" &> /dev/null && se_status=$(ssh ${install_list} sudo sestatus | grep 'Current mode:' | awk '{ print $3 }') && echo -e " [${YELLOW}●${NC}] SELinux:\t\t${se_status}"
      #firewalld
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo systemctl status firewalld | grep 'active (running)'" &> /dev/null && echo -e " [${YELLOW}●${NC}] firewalld:\t\tnot disable"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo systemctl status firewalld | grep 'inactive (dead)'" &> /dev/null && echo -e " [${GREEN}●${NC}] firewalld:\t\tdisabled"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo systemctl status firewalld | grep 'active (running)'" &> /dev/null && echo -e " [${YELLOW}●${NC}] firewalld:\t\tnot disable"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo systemctl status firewalld | grep 'inactive (dead)'" &> /dev/null && echo -e " [${GREEN}●${NC}] firewalld:\t\tdisabled"
      #swap
      ssh ${install_list} "sudo swapon --show | grep '/dev'" &> /dev/null
      [ $? != 0 ] && echo -e " [${GREEN}●${NC}] swap:\t\tdisabled" || echo -e " [${RED}●${NC}] swap\t\tnot disable"
      #ipv4 forward
      forward=$(ssh ${install_list} "cat /proc/sys/net/bridge/bridge-nf-call-iptables 2> /dev/null")
      [ "${forward}" == "1" ] && echo -e " [${GREEN}●${NC}] ipv4_forward:\tenabled" || echo -e " [${YELLOW}●${NC}] ipv4 ip_forward\tnot enable."
      echo
    done
}

function interrupt()
{
  [ ${#} == 0 ] || echo -e "${@}"
  read -s -n1 -p "$(echo -e ${RED}Press 'N/n' to stop, other key to continue.${NC})" ans; echo -e "\n"
  case ${ans} in
  n|N)
    echo -e "${RED}Interrupted!${NC}\n"; exit
    ;;
  *)
    ;;
  esac
}

function node-selector ()
{
  echo "${@}" | grep -wE "hosts|local" &> /dev/null
  [ $? != 0 ] && [ -z ${2} ] && node-message ${@} && exit
  list=$(echo "${CP_NODES}${WK_NODES}" | sed 's/ /|/g' | sed 's/.$//')
  parameter=${@}
  test=${1}
  while true
    do
      echo "${1}" | grep -vwE "hosts|local|cp|wk|${list}" &> /dev/null
      [ $? == 0 ] && shift || break
    done

  echo ${@} | sed 's/ /\n/g' | grep -vwE "${list}" &> /dev/null
  [ $? == 0 ] && status=3 || status=2
  echo ${@} | grep -w "hosts" &> /dev/null
  [ $? == 0 ] && status=0
  echo ${@} | grep -w "local" &> /dev/null
  [ $? == 0 ] && status=1
  echo ${@} | grep -w "cp" &> /dev/null
  [ $? == 0 ] && status=4
  echo ${@} | grep -w "wk" &> /dev/null
  [ $? == 0 ] && status=5

  if [ "${status}" == "0" ]
    then
      list=$(echo "${CP_NODES} ${WK_NODES}")
      cp_nodes=$(echo "${list}" | tr -s ' ' '\n' | grep "\-m" | tr -s '\n' ' ')
      wk_nodes=$(echo "${list}" | tr -s ' ' '\n' | grep "\-w" | tr -s '\n' ' ')
  elif [ "${status}" == "1" ]
    then
      list=$(hostname)
      cp_nodes=$(echo "${list}" | tr -s ' ' '\n' | grep "\-m" | tr -s '\n' ' ')
      wk_nodes=$(echo "${list}" | tr -s ' ' '\n' | grep "\-w" | tr -s '\n' ' ')
  elif [ "${status}" == "2" ]
    then
      list=${@}
      cp_nodes=$(echo "${list}" | tr -s ' ' '\n' | grep "\-m" | tr -s '\n' ' ')
      wk_nodes=$(echo "${list}" | tr -s ' ' '\n' | grep "\-w" | tr -s '\n' ' ')
  elif [ "${status}" == "3" ]
    then
      parameter=$(echo ${parameter} | sed 's/ /\n/g' | grep -v ${test} | sed ":a;N;s/\\n/ /g;ta")
      echo -e "${YELLOW} \"${parameter}\" ${NC}is not effective parameter!"
      echo -e "${RED} Please check out hostname list: ${YELLOW}${ALL_NODES}${NC},${RED}or input parameter:${NC}"
      echo -e "${YELLOW}  > [ <local>\t| for this host ]${NC}"
      echo -e "${YELLOW}  > [ <hosts>\t| for all nodes in /etc/hosts ]${NC}"
      echo -e "${YELLOW}  > [ <cp>\t| for all control-plane nodes ]${NC}"
      echo -e "${YELLOW}  > [ <wk>\t| for all worker nodes ]${NC}\n" && exit
  elif [ "${status}" == "4" ]
    then
      list=$(echo "${CP_NODES} ${WK_NODES}")
      cp_nodes=$(echo "${list}" | tr -s ' ' '\n' | grep "\-m" | tr -s '\n' ' ')
  elif [ "${status}" == "5" ]
    then
      list=$(echo "${CP_NODES} ${WK_NODES}")
      wk_nodes=$(echo "${list}" | tr -s ' ' '\n' | grep "\-w" | tr -s '\n' ' ')
  fi
}

function node-message()
{
  echo -e "${RED} Please input parameter after ${YELLOW}\"${@}\" ${NC}"
  echo -e "${YELLOW}  > [ <local>\t| for this host ]${NC}"
  echo -e "${YELLOW}  > [ <hosts>\t| for all nodes in /etc/hosts ]${NC}"
  echo -e "${YELLOW}  > [ <node>\t| for specify nodes ]${NC}"
  echo -e "${YELLOW}  > [ <cp>\t| for all control-plane nodes ]${NC}"
  echo -e "${YELLOW}  > [ <wk>\t| for all worker nodes ]${NC}\n"
}

function cp-node-message()
{
  echo -e "${RED} Please input parameter after ${YELLOW}\"${@}\" ${NC}"
  echo -e "${YELLOW}  > [ <local>\t| for this host ]${NC}"
  echo -e "${YELLOW}  > [ <hosts>\t| for all control-plane nodes in /etc/hosts ]${NC}"
  echo -e "${YELLOW}  > [ <node>\t| for specify nodes ]${NC}\n"
}

function wk-node-message()
{
  echo -e "${RED} Please input parameter after ${YELLOW}\"${@}\" ${NC}"
  echo -e "${YELLOW}  > [ <local>\t| for this host ]${NC}"
  echo -e "${YELLOW}  > [ <hosts>\t| for all worker nodes in /etc/hosts ]${NC}"
  echo -e "${YELLOW}  > [ <node>\t| for specify nodes ]${NC}\n"
}

function exclude-non-join ()
{
  #Exclude non-join nodes
  which kubectl &> /dev/null
  [ $? == 0 ] && status=1 || status=0
  [ "${status}" == "0" ] && echo -e " [${YELLOW}●${NC}] This node not activate.\n" && exit
  [ "${status}" == "1" ] && cp_list=$(kubectl get nodes | tail -n +2 | awk '{ print $1 }' | grep '\-m' | tr -s '\n' '|' | sed '$ s/.$//')
  [ "${status}" == "1" ] && wk_list=$(kubectl get nodes | tail -n +2 | awk '{ print $1 }' | grep '\-w' | tr -s '\n' '|' | sed '$ s/.$//')
  [ "${status}" == "1" ] && cp_nodes=$(echo ${cp_nodes} | tr -s ' ' '\n' | grep -E ${cp_list} | tr -s '\n' ' ')
  [ "${status}" == "1" ] && wk_nodes=$(echo ${wk_nodes} | tr -s ' ' '\n' | grep -E ${wk_list} | tr -s '\n' ' ')
}

function node-power ()
{
  echo "${@}" | grep -wE "reboot|off" &> /dev/null
  [ $? != 0 ] && echo -e "${RED}Please input parameter [ reboot | off ]${NC}\n" && exit
  echo "${@}" | grep -w "reboot" &> /dev/null && power=reboot
  echo "${@}" | grep -w "off" &> /dev/null && power=poweroff
  [ -z ${3} ] && node-message ${2} && exit
  parameter=$(echo "${@}" | sed 's/ /\n/g' | grep -vwE "reboot|off" | sed ":a;N;s/\\n/ /g;ta")
  node-selector ${parameter}

  cp_nodes=$(echo ${cp_nodes} | tr -s ' ' '\n' | tac | tr -s '\n' ' ')
  message="${RED}Continue to ${power} nodes:${YELLOW} ${wk_nodes} ${cp_nodes}${NC}"
  interrupt ${message}
  echo -e "${YELLOW}nodes ${power} procedure${NC}"
  for list in ${wk_nodes} ${cp_nodes}
    do
      echo -e " [${RED}●${NC}] ${list} ${power} execute${NC}"
      sleep 3
      ssh ${list} "sudo ${power}" 2> /dev/null
    done; echo
}

function pkg-repo-add ()
{
  #cri-o package repository
  [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && CRIO_OS_VERSION="CentOS_8_Stream"

  if [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ]
    then
      [ "${VER_SWITCH}" == "latest" ] && for list in 1
        do
          status=0
          [ "${VER_SWITCH}" == "latest" ] && curl -s https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/${CRIO_OS_VERSION}/devel:kubic:libcontainers:stable.repo | grep 'devel_kubic_libcontainers_stable' &> /dev/null && status=1
          [ "${VER_SWITCH}" == "latest" ] && echo ${status} | grep "1" &> /dev/null && ssh ${install_list} "sudo curl -L -o /etc/yum.repos.d/devel:kubic:libcontainers:stable.repo https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/${CRIO_OS_VERSION}/devel:kubic:libcontainers:stable.repo" &> /dev/null && status=0
          [ "${VER_SWITCH}" == "latest" ] && curl -s https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/${CRI_RELEASE}/${CRIO_OS_VERSION}/devel:kubic:libcontainers:stable:cri-o:${CRI_RELEASE}.repo | grep 'devel_kubic_libcontainers_stable' &> /dev/null && status=1
          [ "${VER_SWITCH}" == "latest" ] && echo ${status} | grep "1" &> /dev/null && ssh ${install_list} "sudo curl -L -o /etc/yum.repos.d/devel:kubic:libcontainers:stable:cri-o:${CRI_RELEASE}.repo https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/${CRI_RELEASE}/${CRIO_OS_VERSION}/devel:kubic:libcontainers:stable:cri-o:${CRI_RELEASE}.repo" &> /dev/null
          [ "${VER_SWITCH}" == "latest" ] && echo ${status} | grep "1" &> /dev/null && echo -e " [${GREEN}●${NC}] Repository\t| ${CRI_RELEASE} repository has been added" #|| echo -e " [${YELLOW}●${NC}] ${CRI_RELEASE} repository not exist"
        done

      [ "${VER_SWITCH}" == "sub" ] && for cri_subver in ${CRI_ALL_VERSION}
        do
          status=0
          [ "${VER_SWITCH}" == "sub" ] && curl -s https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/${CRIO_OS_VERSION}/devel:kubic:libcontainers:stable.repo | grep 'devel_kubic_libcontainers_stable' &> /dev/null && status=1
          [ "${VER_SWITCH}" == "sub" ] && echo ${status} | grep "1" &> /dev/null && ssh ${install_list} "sudo curl -L -o /etc/yum.repos.d/devel:kubic:libcontainers:stable.repo https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/${CRIO_OS_VERSION}/devel:kubic:libcontainers:stable.repo" &> /dev/null && status=0
          [ "${VER_SWITCH}" == "sub" ] && curl -s https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/${CRI_RELEASE}:/${cri_subver}/${CRIO_OS_VERSION}/devel:kubic:libcontainers:stable:cri-o:${CRI_RELEASE}:${cri_subver}.repo | grep 'devel_kubic_libcontainers_stable' &> /dev/null && status=1
          [ "${VER_SWITCH}" == "sub" ] && echo ${status} | grep "1" &> /dev/null && ssh ${install_list} "sudo curl -L -o /etc/yum.repos.d/devel:kubic:libcontainers:stable:cri-o:${CRI_RELEASE}:${cri_subver}.repo https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/${CRI_RELEASE}:/${cri_subver}/${CRIO_OS_VERSION}/devel:kubic:libcontainers:stable:cri-o:${CRI_RELEASE}:${cri_subver}.repo" &> /dev/null
          [ "${VER_SWITCH}" == "sub" ] && echo ${status} | grep "1" &> /dev/null && echo -e " [${GREEN}●${NC}] Repository\t| ${cri_subver} repository has been added" #|| echo -e " [${YELLOW}●${NC}] ${cri_subver} repository not exist"
        done
  fi

  if [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ]
    then
      [ "${VER_SWITCH}" == "latest" ] && for list in 1
        do
          status=0
          [ "${VER_SWITCH}" == "latest" ] && curl -s https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/${CRIO_OS_VERSION}/Release.key | grep 'BEGIN PGP PUBLIC KEY BLOCK' &> /dev/null && status=1
          [ "${status}" == "1" ] && ssh ${install_list} "echo "deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/${CRIO_OS_VERSION}/ /" | sudo tee /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list" &> /dev/null && ssh ${install_list} "curl -L https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/${CRIO_OS_VERSION}/Release.key | sudo apt-key add - " &> /dev/null && status=0
          ssh ${install_list} "ls -al /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list &> /dev/null"
          [ $? == 0 ] && echo -e " [${GREEN}●${NC}] Repository\t| cri-o repository added" || echo -e " [${RED}●${NC}] Repository\t| cri-o repository not added"
        done

      [ "${VER_SWITCH}" == "sub" ] && for cri_subver in ${CRI_ALL_VERSION}
        do
          [ "${VER_SWITCH}" == "sub" ] && curl -s https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/${CRI_RELEASE}:/${cri_subver}/${CRIO_OS_VERSION}/Release.key | grep 'BEGIN PGP PUBLIC KEY BLOCK' &> /dev/null && status=1
          [ "${status}" == "1" ] && ssh ${install_list} "echo "deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/${CRI_RELEASE}:/${cri_subver}/${CRIO_OS_VERSION}/ /" | sudo tee /etc/apt/sources.list.d/devel:kubic:libcontainers:stable:cri-o:${CRI_RELEASE}:${CRI_SUBVER}.list" &> /dev/null && ssh ${install_list} "curl -L https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/${CRI_RELEASE}:/${cri_subver}/${CRIO_OS_VERSION}/Release.key | sudo apt-key add - " &> /dev/null && status=0
          ssh ${install_list} "ls -al /etc/apt/sources.list.d/*${cri_subver}* &> /dev/null"
          [ $? == 0 ] && echo -e " [${GREEN}●${NC}] Repository\t| cri-o ${cri_subver} repository added" || echo -e " [${RED}●${NC}] Repository\t| cri-o ${cri_subver} repository not added"
        done
  fi

  #Kubernetes package repository
  [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} 'sudo bash -c "cat << \EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\$basearch
enabled=1
gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
exclude=kubelet kubeadm kubectl
EOF"' && echo -e " [${GREEN}●${NC}] Repository\t| kubernetes.repo has been added"

  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg" &> /dev/null
  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "echo "deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list" &> /dev/null
  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "ls -al /etc/apt/sources.list.d/*:kubic:* &> /dev/null" && echo -e " [${GREEN}●${NC}] Repository\t| Kubernetes package repository added" || echo -e " [${RED}●${NC}] Repository\t| Kubernetes package repository not added"
  #helm package repository
  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "curl https://baltocdn.com/helm/signing.asc | gpg --dearmor | sudo tee /usr/share/keyrings/helm.gpg > /dev/null" &> /dev/null
  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/helm.gpg] https://baltocdn.com/helm/stable/debian/ all main" | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list" &> /dev/null
  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "ls -al /etc/apt/sources.list.d/*helm* &> /dev/null" && echo -e " [${GREEN}●${NC}] Repository\t| Helm package repository added" || echo -e " [${RED}●${NC}] Repository\t| Helm package repository not added"
  
  #update list
  [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo dnf clean all" &> /dev/null
  [ $? == 0 ] && echo -e " [${GREEN}●${NC}] Repository\t| cache cleanup"
  [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo dnf versionlock delete cri-o kubectl kubeadm kubelet podman" &> /dev/null
  [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo dnf makecache" &> /dev/null
  [ $? == 0 ] && echo -e " [${GREEN}●${NC}] Repository\t| cache updated"
  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo apt-get -qy update" &> /dev/null
  [ $? == 0 ] && echo -e " [${GREEN}●${NC}] Repository\t| cache updated"
  #sudo rm /etc/yum.repos.d/devel:*
}

function pkg-check()
{
  [ -z ${2} ] && node-message ${@} && exit
  node-selector ${@}
  #cri-o
  crio_version="crio version | grep "^Version""
  crio_status="sudo systemctl status crio | grep 'Active'"
  crio_time="sudo systemctl status crio | grep 'Active' | cut -d ';' -f 2 | grep -v 'inactive'"
  #kubelet
  kubelet_version="kubelet --version | sed 's/v//g' 2> /dev/null"
  kubelet_active="sudo systemctl status kubelet | grep 'Main PID' | grep 'kubelet' 2> /dev/null"
  kubelet_status="sudo systemctl status kubelet | grep 'Active' 2> /dev/null"
  kubelet_time="sudo systemctl status kubelet | grep 'Active' | cut -d ';' -f 2 | grep -v 'inactive' 2> /dev/null"
  #kubeadm
  kubeadm_version="kubeadm version -o yaml | grep 'gitVersion' | sed 's/v//g'"
  #kubectl
  kubectl_versio="kubectl version -o yaml 2>&1 | grep -A 9 'clientVersion:' | grep 'gitVersion' | sed 's/v//g'"

  for clist in ${cp_nodes}
    do
      echo -e "${YELLOW}${clist} | Package status${NC}"
      ssh ${clist} 'hostname' &> /dev/null 2>&1
      [ $? != 0 ] && echo -e " [${RED}●${NC}] This node not available\n" && continue

      #cri-o
      status=0
      ssh ${clist} "which crio > /dev/null 2>&1"
      [ $? != 0 ] && echo -e " [${YELLOW}●${NC}] crio\tnot install" && status=1
      #Status active
      ssh ${clist} "sudo systemctl status crio 2> /dev/null | grep "Active:" | grep "failed" &> /dev/null" && status=0
      [ $? != 0 ] && [ "${status}" == 0 ] && echo -e " [${GREEN}●${NC}] crio:\t`ssh ${clist} ${crio_version} 2>&1 | sed '/time/d' | awk '{ print $2 }'` | `ssh ${clist} ${crio_status} | awk '{ print $2,$3 }'` | `ssh ${clist} ${crio_time} | sed 's/^.//' | grep -v 'inactive'`"
      #Status failed (if cri-o has been install)
      ssh ${clist} "sudo systemctl status crio 2> /dev/null | grep "Active:" | grep "failed" &> /dev/null" ssh ${clist} sudo systemctl status crio | grep "Loaded:" | grep -v "not-found" && status=0
      [ $? == 0 ] && [ "${status}" == 0 ] && echo -e " [${YELLOW}●${NC}] crio:\t`ssh ${clist} ${crio_version} 2>&1 | sed '/time/d' | awk '{ print $2 }'` | `ssh ${clist} ${crio_status} | awk '{ print $2,$3,$4 }'` | `ssh ${clist} ${crio_time} | sed 's/^.//'`"
      #kubelet
      ssh ${clist} "which kubelet" &> /dev/null
      [ $? != 0 ] && echo -e " [${YELLOW}●${NC}] kubelet\tnot install" && status=0 || status=1
      [ "${status}" == "1" ] && ssh ${clist} "${kubelet_active}" &> /dev/null && active=0 || active=1
      [ "${status}" == "1" ] && [ "${active}" == "0" ] && echo -e " [${GREEN}●${NC}] kubelet:\t`ssh ${clist} ${kubelet_version} | awk '{ print $2 }'` | `ssh ${clist} ${kubelet_status} | awk '{ print $2,$3 }'` | `ssh ${clist} ${kubelet_time} | sed 's/^.//' | grep -v 'inactive'`"
      [ "${status}" == "1" ] && [ "${active}" == "1" ] && echo -e " [${YELLOW}●${NC}] kubelet:\t`ssh ${clist} ${kubelet_version} | awk '{ print $2 }'` | `ssh ${clist} ${kubelet_status} | awk '{ print $2,$3 }'` | `ssh ${clist} ${kubelet_time} | sed 's/^.//' | grep -v 'inactive'`"
      #kubeadm
      ssh ${clist} "which kubeadm" &> /dev/null
      [ $? != 0 ] && echo -e " [${YELLOW}●${NC}] kubeadm\tnot install" || echo -e " [${GREEN}●${NC}] kubeadm:\t`ssh ${clist} ${kubeadm_version} 2>&1 | awk '{ print $2 }' `"
      #kubectl
      ssh ${clist} "which kubectl" &> /dev/null
      [ $? != 0 ] && echo -e " [${YELLOW}●${NC}] kubectl\tnot install" || echo -e " [${GREEN}●${NC}] kubectl:\t`ssh ${clist} ${kubectl_versio} 2>&1 | sed '/localhost:8080/d' | awk '{ print $2 }'`"
      #helm
      ssh ${clist} "which helm" &> /dev/null
      [ $? != 0 ] && echo -e " [${YELLOW}●${NC}] helm\tnot install" || echo -e " [${GREEN}●${NC}] helm:\t`ssh ${clist} helm version | awk '{ print $1 }' | cut -d '"' -f 2 | sed 's/v//g'`"
      #podman
      ssh ${clist} "which podman" &> /dev/null
      [ $? != 0 ] && echo -e " [${YELLOW}●${NC}] podman\tnot install" || echo -e " [${GREEN}●${NC}] podman:\t`ssh ${clist} sudo podman version 2> /dev/null | grep '^Version' | awk '{ print $2 }'`"
      #k9s
      ssh ${clist} "which k9s" &> /dev/null 
      [ $? != 0 ] && echo -e " [${YELLOW}●${NC}] k9s\tnot install" || echo -e " [${GREEN}●${NC}] k9s:\t`ssh ${clist} k9s version -s | grep Version | awk '{ print $2 }' | sed 's/v//g'`"
      echo
    done

  for wlist in ${wk_nodes}
    do
      echo -e "${YELLOW}${wlist} | Package status${NC}"
      ssh ${wlist} 'hostname' &> /dev/null 2>&1
      [ $? != 0 ] && echo -e " [${RED}●${NC}] This node not available\n" && continue
      
      #cri-o
      status=0
      ssh ${wlist} "which crio > /dev/null 2>&1"
      [ $? != 0 ] && echo -e " [${YELLOW}●${NC}] crio\tnot install" && status=1
      ssh ${wlist} "sudo systemctl status crio 2> /dev/null | grep "Active:" | grep "failed" &> /dev/null" && status=0
      [ $? != 0 ] && [ "${status}" == 0 ] && echo -e " [${GREEN}●${NC}] crio:\t`ssh ${wlist} ${crio_version} 2>&1 | sed '/time/d' | awk '{ print $2 }'` | `ssh ${wlist} ${crio_status} | awk '{ print $2,$3 }'` | `ssh ${wlist} ${crio_time} | sed 's/^.//' | grep -v 'inactive'`"
      ssh ${wlist} "sudo systemctl status crio 2> /dev/null | grep "Active:" | grep "failed" &> /dev/null" && status=0
      [ $? == 0 ] && [ "${status}" == 0 ] && echo -e " [${YELLOW}●${NC}] crio:\t`ssh ${wlist} ${crio_version} 2>&1 | sed '/time/d' | awk '{ print $2 }'` | `ssh ${wlist} ${crio_status} | awk '{ print $2,$3,$4 }'` | `ssh ${wlist} ${crio_time} | sed 's/^.//'`"
      #kubelet
      ssh ${wlist} "which kubelet" &> /dev/null
      [ $? != 0 ] && echo -e " [${YELLOW}●${NC}] kubelet\tnot install" || echo -e " [${GREEN}●${NC}] kubelet:\t`ssh ${wlist} ${kubelet_version} | awk '{ print $2 }'` | `ssh ${wlist} ${kubelet_status} | awk '{ print $2,$3 }'` | `ssh ${wlist} ${kubelet_time} | sed 's/^.//'`"
      #kubeadm
      ssh ${wlist} "which kubeadm " &> /dev/null
      [ $? != 0 ] && echo -e " [${YELLOW}●${NC}] kubeadm\tnot install" || echo -e " [${GREEN}●${NC}] kubeadm:\t`ssh ${wlist} ${kubeadm_version} 2>&1 | awk '{ print $2 }' `"
      #podman
      ssh ${wlist} "which podman" &> /dev/null
      [ $? != 0 ] && echo -e " [${YELLOW}●${NC}] podman\tnot install" || echo -e " [${GREEN}●${NC}] podman:\t`ssh ${wlist} sudo podman version 2> /dev/null | grep '^Version' | awk '{ print $2 }'`"
      echo
    done
}

function install-docker ()
{
  #insatll docker
  ssh ${1} ls /etc/apt/keyrings/docker.gpg &> /dev/null
  [ $? == 0 ] && ssh ${1} sudo rm /etc/apt/keyrings/docker.gpg &> /dev/null || ssh ${1} "curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg"
  ssh ${1} "echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null"
  ssh ${1} sudo apt-get update
  ssh ${1} sudo apt-get install -qy docker-ce docker-ce-cli docker-buildx-plugin docker-compose-plugin
}

function sys-info ()
{
  #system information
  echo "" | sudo tee /tmp/sinfo &> /dev/null
  echo -e "[System]" | sudo tee /tmp/sinfo
  #OS information
  os_name=`cat /etc/os-release | grep 'PRETTY_NAME' | cut -d '"' -f 2`
  echo -e " OS Version: ${YELLOW}$os_name${NC}"
  echo -e " Hostname: ${YELLOW}`hostname`${NC}"
  #memory information
  sudo free -mh | grep Mem: | awk '{ print $2 }' | grep 'Gi' &> /dev/null
  [ $? == 0 ] && byte=GB || byte=MB
  m_size=$(sudo free -mh | grep Mem: | awk '{ print $2 }' | sed 's/Gi//g')
  Gi_to_GB=$(awk "BEGIN { print $m_size / .93 }")
  echo -e " Memory: ${YELLOW}${Gi_to_GB} ${byte}${NC}"
  #cpu information
  cpu_name=$(sudo cat /proc/cpuinfo | grep 'model name' | head -n 1 | cut -d ':' -f2 | tr -s '-' ' ' | sed 's/(R)//g; s/(TM)//g; s/@ //g' | sed 's/^.//')
  core_number=$(sudo cat /proc/cpuinfo | grep 'model name' | wc -l)
  cpu_architecture=$(uname -m)
  echo -e " CPU: ${YELLOW}$cpu_name (core: $core_number) | ${cpu_architecture}${NC}"
  #disk information
  disk_list=$(sudo fdisk -l | grep '^Disk' | grep 'sd' | grep 'bytes' | awk '{ print $2 }' | sed 's/://g;s/\/dev\///g' | tr -s '\n' ' ' | sed 's/.$//')
  echo -e " Disk list: ${YELLOW}${disk_list}${NC}"
  for disk_list in ${disk_list}
    do
      sudo fdisk -l | grep '^Disk' | grep 'bytes' | grep "${disk_list}" | grep -E 'GB|GiB' &> /dev/null
      [ $? == 0 ] && byte=GB || byte=MB
      disk_capacity=$(sudo fdisk -l | grep '^Disk' | grep 'bytes' | grep "${disk_list}" | awk '{ print $3 }')
      disk_usage=$(sudo du -ch / 2> /dev/null | grep 'total' | awk '{ print $1 }' | tr -s 'GM' ' ')
      sudo du -ch / 2> /dev/null | grep 'total' | awk '{ print $1 }' | grep 'G' &> /dev/null
      [ $? == 0 ] && disk_usage=$(sudo du -ch / 2> /dev/null | grep 'total' | awk '{ print $1 }' | tr -s 'GM' ' ') || disk_usage=$(awk "BEGIN { print $disk_usage / 1024 }")

      disk_percent=$(awk "BEGIN { pc=100*${disk_usage}/${disk_capacity}; i=int(pc); print (pc-i<0.5)?i:i+1 }")
      disk_type=$(sudo fdisk -l | grep -A 1 "^Disk /dev/${disk_list}:" | grep '^Disk model' | cut -d ':' -f 2 | sed 's/^.//')

      echo -e "  > Disk name: ${YELLOW}${disk_list} | ${disk_type}${NC}"
      echo -e "  > Disk capacity: ${YELLOW}${disk_capacity} ${byte}${NC}"
      echo -e "  > Disk usage: ${YELLOW}${disk_usage} ${byte} | ${disk_percent} %${NC}"
      echo "  ---"
    done
  echo ""
  #network information
  echo "[Network]"
  echo -e " IP Address: ${YELLOW}${IP}${NC}"
  echo -e " Gateway: ${YELLOW}${GATEWAY}${NC}"

  for list in $(cat /etc/resolv.conf | grep '^nameserver' | awk '{ print $2 }')
    do
      echo -e " nameserver: ${YELLOW}${list}${NC}"
    done

  ping -c 1 www.hinet.net >> /dev/null
  [ "$?" == "0" ] && echo -e " Internet access: ${GREEN}Pass${NC}" || echo -e " Internet: ${RED}Not pass${NC}"
  echo
}

function kubectl-instal-check ()
{
  status=0
  ssh ${1} "which kubectl" &> /dev/null
  [ $? == 0 ] && kubectl_check=$(ssh ${1} kubectl version -o yaml 2> /dev/null | grep -A 10 'clientVersion' | grep 'gitVersion' | awk '{ print $2 }') && status=1
  [ "${status}" == "1" ] && echo -e " [${GREEN}●${NC}] Package\t| kubectl ${kubectl_check} installed" || echo -e " [${YELLOW}●${NC}] Package\t| kubectl not install"
}

function kubeadm-install-check ()
{
  status=0
  ssh ${1} "which kubeadm" &> /dev/null
  [ $? == 0 ] && kubeadm_check=$(ssh ${1} kubeadm version -o yaml 2> /dev/null | grep "gitVersion" | awk '{ print $2 }') && status=1
  [ "${status}" == "1" ] && echo -e " [${GREEN}●${NC}] Package\t| kubeadm ${kubeadm_check} installed" || echo -e " [${YELLOW}●${NC}] Package\t| kubeadm not install"
}

function kubelet-install-check ()
{
  status=0
  ssh ${1} "which kubelet" &> /dev/null
  [ $? == 0 ] && kubelet_check=$(ssh ${1} kubelet --version 2> /dev/null | grep "^Kubernetes" | awk '{ print $2 }') && status=1
  [ "${status}" == "1" ] && echo -e " [${GREEN}●${NC}] Package\t| kubelet ${kubelet_check} installed" || echo -e " [${YELLOW}●${NC}] Package\t| kubelet not install"
  ssh ${1} ls -l /etc/systemd/system/kubelet.service.d/ 2> /dev/null | grep -w "10-kubeadm.conf$" &> /dev/null
  [ $? != 0 ] && target=$(ls /etc/systemd/system/kubelet.service.d/ 2> /dev/null) && ssh ${1} sudo mv /etc/systemd/system/kubelet.service.d/${target} /etc/systemd/system/kubelet.service.d/10-kubeadm.conf 2> /dev/null
  [ $? == 0 ] && echo -e " [${GREEN}●${NC}] Package\t| 10-kubeadm.conf checked" || echo -e " [${RED}●${NC}] Package\t| 10-kubeadm.conf not configured correctly"
}

function crio-install-check ()
{
  ssh ${1} "which crio &> /dev/null" &> /dev/null
  [ $? == 0 ] && cri_check=$(ssh ${1} crio version 2> /dev/null | grep "^Version" | awk '{ print $2 }') && echo -e " [${GREEN}●${NC}] Package\t| crio ${cri_check} installed" || echo -e " [${YELLOW}●${NC}] Package\t| crio not install"
}

function podman-install-check ()
{
  podman_check=$(ssh ${1} podman version 2> /dev/null | grep '^Version' | awk '{ print $2 }')
  ssh ${1} "which podman" &> /dev/null
  [ $? == 0 ] && echo -e " [${GREEN}●${NC}] Package\t| podman ${podman_check} installed" || echo -e " [${YELLOW}●${NC}] Package\t| podman not install"
}

function daemon-enable ()
{
  ssh ${1} "sudo systemctl enable --now crio" &> /dev/null
  [ $? == 0 ] && echo -e " [${GREEN}●${NC}] Daemon\t| crio enabled" || echo -e " [${RED}●${NC}] Daemon\t| crio not enable"
    ssh ${1} "sudo systemctl restart --now crio" &> /dev/null
  [ $? == 0 ] && echo -e " [${GREEN}●${NC}] Daemon\t| crio restarted" || echo -e " [${RED}●${NC}] Daemon\t| crio not restart"

  ssh ${1} "sudo systemctl enable --now kubelet" &> /dev/null
  [ $? == 0 ] && echo -e " [${GREEN}●${NC}] Daemon\t| kubelet enabled" || echo -e " [${RED}●${NC}] Daemon\t| kubelet not enable"
  ssh ${1} "sudo systemctl restart --now kubelet" &> /dev/null
  [ $? == 0 ] && echo -e " [${GREEN}●${NC}] Daemon\t| kubelet restarted" || echo -e " [${RED}●${NC}] Daemon\t| kubelet not restart"

  ssh ${1} "sudo systemctl daemon-reload" &> /dev/null
  [ $? == 0 ] && echo -e " [${GREEN}●${NC}] Daemon\t| daemon has been reload" || echo -e " [${YELLOW}●${NC}] Daemon\t| daemon not reload"
}

function helm-repo-add ()
{
  for clist in ${cp_nodes}
    do
      echo -e "${YELLOW}${clist} helm repositories${NC}"
      ssh ${clist} "helm repo add projectcalico https://projectcalico.docs.tigera.io/charts &> /dev/null" && echo -e "${YELLOW} > helm repository \"projectcalico\" added${NC}" || echo -e "${RED} > helm repository \"projectcalico\" not add${NC}"
      ssh ${clist} "helm repo add metrics-server https://kubernetes-sigs.github.io/metrics-server &> /dev/null" && echo -e "${YELLOW} > helm repository \"metrics-server\" added${NC}" || echo -e "${RED} > helm repository \"metrics-server\" not add${NC}"
      ssh ${clist} "helm repo add prometheus-community https://prometheus-community.github.io/helm-charts &> /dev/null" && echo -e "${YELLOW} > helm repository \"prometheus\" added${NC}\n" || echo -e "${RED} > helm repository \"prometheus\" not add${NC}"
    done
}

function helm-repo-check ()
{
  node-selector local
  helm_repo_list=$(helm repo ls | tail -n +2 | awk '{ print $1 }' | tr -s '\n' ' ' | sed 's/.$//')
  for clist in ${cp_nodes}
    do
      echo -e "${YELLOW}${clist} helm repository list${NC}"
      for list in ${helm_repo_list}
        do
          echo -e "${YELLOW}${list}${NC}"
          ssh ${clist} "helm search repo --versions ${list} | head -n 4"
          echo
        done
    done
}

function helm-repo-update ()
{
  for clist in ${cp_nodes}
    do
      echo -e "${YELLOW}${clist} helm repositories update${NC}"
      ssh ${clist} "helm repo update &> /dev/null" && echo -e "${YELLOW}${install_list} > helm repositories updated${NC}\n"
    done
}

function dir-delete-list ()
{
  [ "${wclist}" == "" ] && wclist="${wlist} ${clist}"

  ssh ${wclist} "ls ~/.kube" &> /dev/null
  [ $? == 0 ] && ssh ${wclist} "sudo rm -r ~/.kube" || echo -e "[${GREEN}●${NC}] Target has been removed: ~/.kube"
  ssh ${wclist} "sudo ls /etc/systemd/system/etcd*" &> /dev/null
  [ $? == 0 ] && ssh ${wclist} "sudo rm /etc/systemd/system/etcd*" &> /dev/null || echo -e "[${GREEN}●${NC}] Target has been removed: /etc/systemd/system/etcd*"
  empty=$(ssh ${wclist} "ls /var/log/pods/ 2> /dev/null | wc -l")
  [ ${empty} != 0 ] && ssh ${wclist} "sudo rm -r /var/log/pods/*" &> /dev/null || echo -e "[${GREEN}●${NC}] Target has been removed: /var/log/pods/*"
  empty=$(ssh ${wclist} "sudo ls /etc/kubernetes/manifests/ 2> /dev/null | wc -l")
  [ ${empty} != 0 ] && ssh ${wclist} "sudo rm /etc/kubernetes/manifests/*" &> /dev/null || echo -e "[${GREEN}●${NC}] Target has been removed: /etc/kubernetes/manifests/*"
  empty=$(ssh ${wclist} "sudo ls /etc/cni/net.d/ 2> /dev/null | wc -l")
  [ ${empty} != 0 ] && ssh ${wclist} "sudo rm /etc/cni/net.d/*" &> /dev/null || echo -e "[${GREEN}●${NC}] Target has been removed: /etc/cni/net.d/*"
  empty=$(ssh ${wclist} "ls /var/lib/calico/ 2> /dev/null | wc -l")
  [ ${empty} != 0 ] && ssh ${wclist} "sudo rm /var/lib/calico/*" &> /dev/null || echo -e "[${GREEN}●${NC}] Target has been removed: /var/lib/calico/*"
  empty=$(ssh ${wclist} "ls /var/log/containers/ 2> /dev/null | wc -l")
  [ ${empty} != 0 ] && ssh ${wclist} "sudo rm /var/log/containers/*" &> /dev/null || echo -e "[${GREEN}●${NC}] Target has been removed: /var/log/containers/*"
  empty=$(ssh ${wclist} "ls /var/log/calico/cni/ 2> /dev/null | wc -l")
  [ ${empty} != 0 ] && ssh ${wclist} "sudo rm /var/log/calico/cni/*" &> /dev/null || echo -e "[${GREEN}●${NC}] Target has been removed: /var/log/calico/cni/*"
  empty=$(ssh ${wclist} "sudo ls /opt/cni/bin/ 2> /dev/null | wc -l")
  [ ${empty} != 0 ] && ssh ${wclist} "sudo rm -r /opt/cni/bin/*" &> /dev/null || echo -e "[${GREEN}●${NC}] Target has been removed: /opt/cni/bin/*"
  empty=$(ssh ${wclist} "sudo ls /var/log/crio/pods 2> /dev/null | wc -l")
  [ ${empty} != 0 ] && ssh ${wclist} "sudo rm -r /var/log/crio/pods" &> /dev/null || echo -e "[${GREEN}●${NC}] Target has been removed: /var/log/crio/pods"
  ssh ${wclist} "sudo ls /var/lib/etcd > /dev/null 2>&1"
  [ $? == 0 ] && ssh ${wclist} "sudo rm -r /var/lib/etcd" &> /dev/null || echo -e "[${GREEN}●${NC}] Target has been removed: /var/lib/etcd/"
  #empty=$(ssh ${wclist} "ls /etc/apt/sources.list.d/ 2> /dev/null | wc -l")
  #[ ${empty} != 0 ] && ssh ${wclist} "sudo rm /etc/apt/sources.list.d/*" || echo "[${GREEN}●${NC}]Target has been removed: /etc/apt/sources.list.d/*"
}

function check-cidr() {
  kubectl get node > /dev/null 2>&1
  [ $? != 0 ] && echo -e "[${RED}●${NC}] This node not join cluster" && exit
  echo -e "${YELLOW}POD-CIDR: ${RED}`kubectl cluster-info dump -o yaml | grep -m 1 cluster-cidr | cut -d '=' -f 2`${NC}"
  echo -e "${YELLOW}SVC-CIDR: ${RED}`kubectl cluster-info dump -o yaml | grep -m 1 service-cluster | cut -d '=' -f 2`${NC}" 
}

function check-tains() {
  kubectl get node > /dev/null 2>&1
  [ $? != 0 ] && echo -e "[${RED}●${NC}] This node not join cluster" && exit
  for kube_node in $(kubectl get nodes | awk '{ print $1 }' | tail -n +2);
    do
      role=$(kubectl describe node $kube_node | grep 'Roles' | awk '{ print $2 }')
      echo -en "${YELLOW}${kube_node}: ${RED}${role}"
      echo ${role} | grep "control-plane" &> /dev/null
      [ $? == 0 ] && echo -e "${NC}\t|" $(kubectl describe node ${kube_node} | grep Taint)
      echo ${role} | grep "worker" &> /dev/null
      [ $? == 0 ] && echo -e "${NC}\t\t|" $(kubectl describe node ${kube_node} | grep Taint)
    done
}

function check-etcd-member() {
  kubectl get node > /dev/null 2>&1
  [ $? != 0 ] && echo -e "[${RED}●${NC}] This node not join cluster" && exit
  etcd_pod=$(kubectl get pods -n kube-system | grep 'etcd' | awk '{ print $1 }' | head -n 1)
  etcd_endpoints=$(echo ${etcd_pod} | cut -d '-' -f 2)
  kubectl exec -it ${etcd_pod} -n kube-system -- etcdctl --endpoints ${NETID}.${etcd_endpoints}:2379 --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key --cacert=/etc/kubernetes/pki/etcd/ca.crt member list
}

function node-check() {
  [ -z ${2} ] && echo -e "${RED}Please input parameter [ <hosts> | <hosts> <name> | <hosts> <port> | <NETID> <Start> <End> <Port> ]${NC}\n" && exit
  #hosts check
  if [ "${2}" == "hosts" ]
    then
      [ -z ${3} ] && port=22
      [ "${3}" == "name" ] && port=22 || port=${3}
      #[ -z ${3} ] && echo -e "${RED}Please input port number. [ node-check hosts <Port> ]${NC}\n" && exit

      node_install_list=$(cat /etc/hosts | grep -v '#' | grep -E '\-m|\-w|kube-vip' | grep "${NETID}" | awk '{ print $1 }')
      echo -e "${YELLOW}Node-checker running...${NC}"
      for install_list in ${node_install_list}
        do
          [ -z ${3} ] && port=22
          nc -w 2 -z ${install_list} ${port} &> /dev/null
          port_status=$(echo $?)
          if [ "${3}" == "name" ]
            then
              [ -z ${3} ] && port=22
              [ "${port_status}" == "0" ] && ssh -o ConnectTimeout=1 -o BatchMode=yes ${install_list} 'hostname' 2>&1 | grep '@' &> /dev/null
              [ $? == 0 ] && hostname="NO SSH-KEY" || hostname=$(ssh -o ConnectTimeout=1 -o BatchMode=yes ${install_list} 'hostname' 2> /dev/null)
              [ "${hostname}" != "NO SSH-KEY" ] && ssh -o ConnectTimeout=1 -o BatchMode=yes ${install_list} 'hostname' 2>&1 | grep 'fingerprint' &> /dev/null
              [ $? == 0 ] && hostname="WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!"
              [ "${port_status}" == "0" ] && echo -e " [${GREEN}●${NC}] ${install_list} | ${YELLOW}${port}${NC} Port Pass\t| Hostname: ${hostname}" || echo -e " [${RED}●${NC}] ${install_list} | ${YELLOW}${port}${NC} Port Not Pass\t| Hostname: --"
            else
              [ -z ${3} ] && port=22
              [ "${port_status}" == "0" ] && echo -e " [${GREEN}●${NC}] ${install_list} | ${YELLOW}${port}${NC} Port Pass" || echo -e " [${RED}●${NC}] ${install_list} | ${YELLOW}${port}${NC} Port Not Pass"
          fi
        done
    #Check non-join nodes
    elif [ "${2}" == "non-join" ]
      then
        nc -z -w 1 `hostname` 10250 > /dev/null 2>&1
        [ $? == 0 ] && cluster_list=$(kubectl get nodes | tail -n +2 | awk '{ print $1 }' | tr -s '\n' '|' | sed '$ s/.$//') || echo -e "${RED}This node is not active!${NC}\n" && exit
        echo -e "${YELLOW}non join node list${NC}"
        [ "${cluster_list}" != "" ] && echo -e " > All nodes are joined" || echo -e "`cat /etc/hosts | grep -vE '#|ip6|k8s.org' | grep "${NETID}" | awk '{ print $2 }' | grep -vE ${cluster_list} | tr -s '\n' ' '`\n"
    else
      #[ "${2}" != "${NETID}" ] && echo -e "${RED}Please input port number. [ hosts <Port> or <NETID> <Start> <End> <Port> ]${NC}\n" && exit
      declare -i start=${3} end=${4} port=${5}; net=${2}; install_list=0
      echo -e "${YELLOW}Node-checker running...${NC}"
      for ((start;start<=end; start=start+1))
        do
          install_list=$(echo "${net}.${start}")
          nc -w 1 -z ${install_list} ${port} &> /dev/null
          port_status=$(echo $?)
          if [ "${6}" == "name" ]
            then
              [ "${port_status}" == "0" ] && ssh -o ConnectTimeout=1 -o BatchMode=yes ${install_list} 'hostname' 2>&1 | grep '@' &> /dev/null
              [ $? == 0 ] && hostname="NO SSH-KEY" || hostname=$(ssh -o ConnectTimeout=1 -o BatchMode=yes ${install_list} 'hostname' 2> /dev/null)
              [ "${hostname}" != "NO SSH-KEY" ] && ssh -o ConnectTimeout=1 -o BatchMode=yes ${install_list} 'hostname' 2>&1 | grep 'fingerprint' &> /dev/null
              [ $? == 0 ] && hostname="WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!"
              [ "${port_status}" == "0" ] && echo -e " [${GREEN}●${NC}] ${install_list} | ${YELLOW}${port}${NC} Port Pass\t| Hostname: ${hostname}" || echo -e " [${RED}●${NC}] ${install_list} | ${YELLOW}${port}${NC} Port Not Pass\t| Hostname: --"
            else
              [ "${port_status}" == "0" ] && echo -e " [${GREEN}●${NC}] ${install_list} | ${YELLOW}${port}${NC} Port Pass" || echo -e " [${RED}●${NC}] ${install_list} | ${YELLOW}${port}${NC} Port Not Pass"
          fi
        done
  fi
  echo
}

# Program >>>
echo
case ${1} in

sys-info) #Show host basic information.
  sys-info
;;

sys-var) #Check script variables.
  sys-variable
;;

sys-conf) #Configure file & directory.

  #Set localhost hostname in hosts
  cat /etc/hosts | grep '127.0.0.1' | grep ${HOSTNAME} &> /dev/null
  [ $? != 0 ] &&  sudo sed -i "s|127.0.0.1   |127.0.0.1   ${HOSTNAME} |g" /etc/hosts
  echo -en " [${GREEN}●${NC}] /etc/hosts: "
  cat /etc/hosts | grep '127.0.0.1' | grep ${HOSTNAME}

  [ "${#}" == "2" ] && [ "${2}" == "hosts" ] && status=1 || status=0
  [ "${status}" == "1" ] && node-selector hosts && status=1
  
  for install_list in ${cp_nodes} ${wk_nodes}
    do
      echo -e "${YELLOW}${install_list} system configure${NC}"
      [ "${status}" == "1" ] && ssh ${install_list} 'kdm sys-conf'
    done
  
  [ "${status}" == "1" ] && exit
  #setup ssh
  os-detection
  cat /etc/ssh/ssh_config | grep 'StrictHostKeyChecking no'
  [ $? != 0 ] && echo 'StrictHostKeyChecking no' | sudo tee -a /etc/ssh/ssh_config

  [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && sudo -S sed -i "s/# %wheel\tALL=(ALL)\tNOPASSWD: ALL/%wheel\tALL=(ALL)\tNOPASSWD: ALL/g" /etc/sudoers
  [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && sudo -S sed -i "s/# %wheel\tALL=(ALL)\tNOPASSWD: ALL/%wheel\tALL=(ALL)\tNOPASSWD: ALL/g" /etc/sudoers
  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && sudo -S sed -i "s/%sudo\tALL=(ALL:ALL) ALL/%sudo\tALL=(ALL:ALL) NOPASSWD: ALL/g" /etc/sudoers
  
  ls ~/bin &> /dev/null
  [ $? != 0 ] && mkdir ~/bin
  ls kdm &> /dev/null
  [ $? == 0 ] && mv /home/${USER}/kdm/kdm /home/${USER}/bin/
  ls yaml &> /dev/null
  [ $? != 0 ] && mkdir yaml

  [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && sudo subscription-manager repos --enable=codeready-builder-for-rhel-8-x86_64-rpms &> /dev/null
  [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && sudo dnf update -y && sudo dnf upgrade -y
  [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && sudo dnf install -y nano tree curl git chrony
  [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && sudo systemctl start chronyd && sudo systemctl enable chronyd.service
  [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && sudo systemctl status chronyd | grep 'Active:' && sudo chronyc -a makestep
  [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && sudo timedatectl set-timezone Asia/Taipei
  
  [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && sudo dnf update -y && sudo dnf upgrade -y
  [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && sudo dnf install -y nano tree curl git chrony epel-release
  [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && sudo systemctl start chronyd && sudo systemctl enable chronyd.service
  [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && sudo systemctl status chronyd | grep 'Active:' && sudo chronyc -a makestep
  [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && sudo timedatectl set-timezone Asia/Taipei
  #[ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && sudo dnf install -y systemd-timesyncd && sudo systemctl enable --now systemd-timesyncd.service && sudo timedatectl set-ntp true && sudo timedatectl set-timezone Asia/Taipei

  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && sudo apt-get -qy update && sudo apt-get -qy upgrade
  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && sudo apt-get install -qy nano tree curl git chrony
  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && sudo systemctl start chronyd && sudo systemctl enable chronyd.service
  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && sudo systemctl status chronyd | grep 'Active:'&& sudo chronyc -a makestep
  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && sudo timedatectl set-timezone Asia/Taipei

  #turn off welcome message
  cat /etc/profile | grep 'clear'
  [ $? != 0 ] && echo "clear" | sudo tee -a /etc/profile
  touch ~/.hushlogin
  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && sudo chmod -x /etc/update-motd.d/*

  #Set /etc/hosts
  cat /etc/hosts | grep '127.0.0.1' | grep ${HOSTNAME} &> /dev/null
  [ $? != 0 ] && sudo sed -i "s|127.0.0.1   |127.0.0.1   ${HOSTNAME} |g" /etc/hosts

  echo "/etc/hosts:"
  echo -en "${GREEN}"
  cat /etc/hosts | grep '127.0.0.1' | grep ${HOSTNAME}
  echo -en "${NC}"
;;

sys-check) #Check node basic status.
  sys-check ${@}
;;

sys-date) #Check system time-zone.
  node-selector ${@}
  for install_list in ${cp_nodes} ${wk_nodes}
    do
      echo -en "${YELLOW}${install_list} system time: ${NC}"
      ssh ${install_list} 'date +"%Y-%m-%d %Z %H:%M:%S"'
    done
;;

set-ssh-key) #Let ssh login without password. [ host | renew ]
  if [ "${2}" == "local" ]
    then
      sudo rm -r .ssh/*
      ssh-keygen -t rsa -N '' -f ~/.ssh/id_rsa <<< y
      ssh-copy-id ${USER}@localhost
    elif [ "${2}" == "renew" ]
      then
        sudo rm -r .ssh/*
        ssh-keygen -t rsa -N '' -f ~/.ssh/id_rsa <<< y
        ssh-copy-id ${USER}@localhost
        for install_list in ${ALL_NODES_EX_LOCALHOST}
          do
            scp -r .ssh ${install_list}:
          done
      else
        echo -e "${YELLOW}Please input parameter [ local | renew ]${NC}"
  fi
;;

set-hosts) #Setup hosts. [ hosts <m> <Start> <End> <w> <Start> <End> [ Detect NETID just input xxx xxx ] ]
  #setup /etc/hosts
  declare -i mstart=${3} mend=${4} wstart=${6} wend=${7} number=1
  m=${2} w=${5}
  if [ ${#} != 7 ]
    then
      echo -e "Please input parameter.\n"
      echo -e "hosts: setup hosts [ <m> <start> <end> <w> <start> <end> ]\n"; exit
    else

  sudo sed -i "/${NETID}/d" /etc/hosts

  for ((mstart;mstart<=mend;mstart=mstart+1))
    do
sudo bash -c "cat << EOF >> /etc/hosts
${NETID}.${mstart} ${mstart}-${m}${number}
EOF"
  number=$((number+1))
    done;

number=1

  for ((wstart;wstart<=wend;wstart=wstart+1))
    do
sudo bash -c "cat << EOF >> /etc/hosts
${NETID}.${wstart} ${wstart}-${w}${number}
EOF"
  number=$((number+1))
    done;

  echo -e "=hosts=\n"; cat /etc/hosts
  fi

  echo -e "\n= Prepare power off to duplicate VM node."
  interrupt; echo "poweroff node..."; sleep 1.5
  sudo poweroff
;;

set-ip) #Setup IP Address. [ set-ip <IP/NETMASK> [ Detect NETID just input xxx/XX ] ]
  if [ ${#} != 2 ]
    then
      echo -e "${RED}Please input parameter after ${YELLOW}\"set-ip\"${NC} [ set-ip <IP/NETMASK> [ Detect NETID just input xxx/XX ] ]\n" && exit
    else

#Rocky 8 NetworkManager setting
[ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && sudo bash -c "cat << EOF > /etc/sysconfig/network-scripts/ifcfg-${KUBE_INTERFACE}
TYPE=Ethernet
PROXY_METHOD=none
BROWSER_ONLY=no
BOOTPROTO=none
DEFROUTE=yes
IPV4_FAILURE_FATAL=no
IPV6INIT=no
IPV6_DEFROUTE=yes
IPV6_FAILURE_FATAL=no
NAME=${KUBE_INTERFACE}
UUID=${NETWORK_UUID}
DEVICE=${KUBE_INTERFACE}
ONBOOT=yes
IPADDR=${NETID}.
PREFIX=24
GATEWAY=${GATEWAY}
DNS1=8.8.8.8
EOF" && echo -e "Network-scripts setting\n" && sudo cat /etc/sysconfig/network-scripts/ifcfg-${KUBE_INTERFACE}

#RHEL 9 & Rocky 9 NetworkManager setting
[ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && uuid=$(sudo cat /etc/NetworkManager/system-connections/${KUBE_INTERFACE}.nmconnection | grep 'uuid' | cut -d '=' -f 2)
[ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && timestamp=$(sudo cat /etc/NetworkManager/system-connections/${KUBE_INTERFACE}.nmconnection | grep 'timestamp' | cut -d '=' -f 2)
[ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && sudo bash -c "cat << EOF > /etc/NetworkManager/system-connections/${KUBE_INTERFACE}.nmconnection
[connection]
id=${KUBE_INTERFACE}
uuid=${uuid}
type=ethernet
autoconnect-priority=-999
interface-name=${KUBE_INTERFACE}
timestamp=${timestamp}

[ethernet]
mac-address=""

[ipv4]
address1=${NETID}.${2}/24,${GATEWAY}
dns=8.8.8.8;
method=manual

[ipv6]
addr-gen-mode=eui64
method=disabled

[proxy]
EOF" && echo -e "NetworkManager setting\n" && sudo cat /etc/NetworkManager/system-connections/${KUBE_INTERFACE}.nmconnection

#Ubuntu NetworkManager setting
[ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && sudo bash -c "cat << EOF > /etc/netplan/00-installer-config.yaml
network:
  version: 2
  ethernets:
    ${KUBE_INTERFACE}:
      dhcp4: no
      dhcp6: no
      addresses: [${NETID}.${2}]
      routes:
      - to: default
        via: ${GATEWAY}
      nameservers:
        addresses: [8.8.8.8]
EOF" && echo -e "netplane setting\n" && cat /etc/netplan/00-installer-config.yaml; echo

  fi
;;

set-hostname) #Setup hostname. [ hostname [ name ] ]
  [ -z ${2} ] && echo -e "${RED}Please input parameter after ${YELLOW}\"set-hostname\"${NC} [ <hostname> ]\n" && exit || echo "$2" | sudo tee /etc/hostname &> /dev/null

  echo -en "[${GREEN}●${NC}]Set hostname to: "
  cat /etc/hostname && echo
  interrupt
  echo "reboot node..." && sleep 1.5 && sudo reboot
;;

set-ver) #Set kube*、cri-o package version.
  [ -z ${2} ] && echo -e "${RED}Please input parameter after ${YELLOW}\"set-ver\" [ latest | sub ]${NC}\n" && exit
  echo "${2}" | grep -vE 'latest|sub' &> /dev/null
  [ $? == 0 ] && echo -e "${RED}Please input parameter after ${YELLOW}\"set-ver\" [ latest | sub ]${NC}\n" && exit

  [ -z ${3} ] && [ "${2}" == "latest" ] && echo -e "${RED}Please input parameter after ${YELLOW}\"set-ver ${2}\" [0-9.0-99]${NC}\n" && exit
  [ -z ${3} ] && [ "${2}" == "sub" ] && echo -e "${RED}Please input parameter after ${YELLOW}\"set-ver ${2}\" [0-9.0-99.0-9]${NC}\n" && exit

  status=0
  [ "${2}" == "sub" ] && echo "${3}" | sed 's|^[0-9].[0-9][0-9].[0-9]||g' | grep '^$' &> /dev/null && status=1
  [ "${2}" == "sub" ] && [ "${status}" == "0" ] && echo -e "${RED}Please input parameter after ${YELLOW}\"set-ver ${2}\" [0-9.0-99.0-9]${NC}\n" && exit

  [ "${2}" == "latest" ] && echo "${3}" | sed 's|^[0-9].[0-9][0-9]||g' | grep '^$' &> /dev/null && status=1
  [ "${2}" == "latest" ] && [ "${status}" == "0" ] && echo -e "${RED}Please input parameter after ${YELLOW}\"set-ver ${2}\" [0-9.0-99]${NC}\n" && exit

  v1=$(echo ${3} | cut -d '.' -f 1-2)
  v2=$(echo ${3} | cut -d '.' -f 3)
  echo ${3} | cut -d '.' -f 3 | grep [0-9] &> /dev/null
  [ $? != 0 ] && v2=0

  echo -en "${YELLOW}"
  sed -i "s|export CRI_RELEASE=${CRI_RELEASE}|export CRI_RELEASE=${v1}|g" ~/bin/kdm
  sed -i "s|export CRI_SUBVER=\${CRI_RELEASE}.*|export CRI_SUBVER=\${CRI_RELEASE}.${v2}|g" ~/bin/kdm
  sed -i "s|export KUBE_RELEASE=${KUBE_RELEASE}|export KUBE_RELEASE=${v1}|g" ~/bin/kdm
  sed -i "s|export KUBE_SUBVER=\${KUBE_RELEASE}.*|export KUBE_SUBVER=\${KUBE_RELEASE}.${v2}|g" ~/bin/kdm
  sed -i "s|^export VER_SWITCH=[a-z]*|export VER_SWITCH=${2}|g" ~/bin/kdm
  echo -en "${NC}"
  sys-variable
;;

set-selinux) #Setting SELinux mod [ set | apply ]
[ -z ${2} ] && echo -e "${RED}Please input parameter after ${YELLOW}\"set-selinux\" [ set | apply ]${NC}\n" && exit
  if [ "${2}" == "set" ]
    then
      [ -z ${3} ] && echo -e "${RED}Please input parameter after ${YELLOW}\"set\" [ disable | permissive | enforcing ]${NC}\n" && exit
      echo "${3}" | grep -vE 'disable|permissive|enforcing' &> /dev/null
      [ $? == 0 ] && echo -e "${RED}Please input parameter after ${YELLOW}\"set\" [ disable | permissive | enforcing ]${NC}\n" && exit

      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && sudo sed -i "/^export\ SELINUX_MODE=/c\export\ SELINUX_MODE=${3}" ~/bin/kdm
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && sudo sed -i "/^export SELINUX_MODE=/c\export SELINUX_MODE=${3}" ~/bin/kdm
    
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && echo -e "${YELLOW}${install_list}${NC}" && cat ~/bin/kdm | grep '^export\ SELINUX_MODE='
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && echo -e "${YELLOW}${install_list}${NC}" && cat ~/bin/kdm | grep '^export\ SELINUX_MODE='
  elif [ "${2}" == "apply" ]
    then
      node-selector hosts
      for install_list in ${wk_nodes} ${cp_nodes}
        do
          echo "${CRIO_OS_VERSION}" | grep -E "RHEL_8|CentOS_8_Stream" &> /dev/null
          [ $? == 0 ] && status=1 || status=0
          echo -e "${install_list}"

          cat ~/bin/kdm | grep '^export\ SELINUX_MODE=' | grep -E 'permissive|enforcing' &> /dev/null
          [ $? == 0 ] && [ "${status}" == "1" ] && ssh ${install_list} sudo setenforce ${SELINUX_MODE}
          
          [ "${status}" == "1" ] && ssh ${install_list} "sudo sed -i "/^SELINUX=/c\SELINUX=${SELINUX_MODE}" /etc/selinux/config"
          [ "${status}" == "1" ] && ssh ${install_list} cat /etc/selinux/config | grep '^SELINUX='
        done
  fi
;;

sync-ssh) #scp .ssh to every nodes.
  rm ~/.ssh/known_hosts
  node-selector hosts
  for install_list in ${cp_nodes} ${wk_nodes}
    do
      echo -en "${YELLOW}Send to ${install_list}${NC}"
      scp -r .ssh ${install_list}: 2> /dev/null
    done
;;

sync-kdm) #scp kdm to every nodes.
  node-selector hosts
  for install_list in ${cp_nodes} ${wk_nodes}
    do
      ssh ${install_list} "ls ~/bin &> /dev/null"
      [ $? != 0 ] && ssh ${install_list} "mkdir ~/bin &> /dev/null"
      echo -en "${YELLOW}Send to ${install_list}${NC}"
      scp bin/kdm ${install_list}:bin/ 2> /dev/null
    done
;;

sync-yaml) #scp yaml to every nodes.
  node-selector hosts
  for install_list in ${cp_nodes}
    do
      echo -en "${YELLOW}Send to ${install_list}${NC}"
      scp -r yaml ${install_list}: 2> /dev/null
    done
;;

pkg-ver) #Check package repositories.
  [ -z ${2} ] && node-message ${@} && exit
  node-selector ${@}
  for install_list in ${cp_nodes} ${wk_nodes}
    do
      echo -e "${YELLOW}${install_list} | package repositories check${NC}"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && echo -e "${GREEN}Package enabled repositories:${NC}"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo dnf repolist --enabled -q"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && echo -e "${GREEN}Package enabled repositories:${NC}"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo dnf repolist --enabled -q"
      for plist in ${PACKAGE_LIST}
        do
          echo -e "${GREEN}${plist} pkg-version:${NC}"
          [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "echo ${plist} | grep -v 'kube' &> /dev/null && sudo dnf provides ${plist} 2> /dev/null | grep 'Provide' | head -n 5 | cut -d '=' -f 2 | sed 's/^.//'"
          [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "echo ${plist} | grep 'kube' &> /dev/null && sudo dnf provides ${plist} --disableexcludes=kubernetes 2> /dev/null | grep 'Provide' | grep ${CRI_RELEASE} | cut -d '=' -f 2 | sed ':a;N;s/\n/ |/g;ta' | sed 's/^.//'"
          [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "echo ${plist} | grep -v 'kube' &> /dev/null && sudo dnf provides ${plist} 2> /dev/null | grep 'Provide' | head -n 5 | cut -d '=' -f 2 | sed 's/^.//'"
          [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "echo ${plist} | grep 'kube' &> /dev/null && sudo dnf provides ${plist} --disableexcludes=kubernetes 2> /dev/null | grep 'Provide' | grep ${CRI_RELEASE} | cut -d '=' -f 2 | sed ':a;N;s/\n/ |/g;ta' | sed 's/^.//'"
          [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo apt-cache madison ${plist} | head -n 5"
        done; echo
  done
;;

pkg-repo) #Setup package repositories. [ add | rm ]
  [ -z ${2} ] && echo -e "${RED}Please input parameter. [ add | rm ]${NC}\n" && exit
  [ -z ${3} ] && node-message ${@} && exit

  node-selector ${@}

  message="${RED}Modify packages repository on nodes: ${YELLOW}${cp_nodes} ${wk_nodes}${NC}"
  interrupt ${message}

  if [ "${2}" == "add" ]
    then
      echo -e "${YELLOW}Prepare to add package repositories.${NC}"
      for install_list in ${cp_nodes} ${wk_nodes}
        do
          echo -e "${YELLOW}${install_list} | repositories procedure${NC}"
          pkg-repo-add && echo
        done
    elif [ "${2}" == "rm" ]
      then
        echo -e "${YELLOW}Prepare to remove package repositories.${NC}"
        for install_list in ${cp_nodes} ${wk_nodes}
          do
            [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "ls /etc/yum.repos.d/devel:kubic* > /dev/null 2>&1" && ssh ${install_list} "sudo rm /etc/yum.repos.d/devel:kubic*"
            [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo rm /etc/yum.repos.d/kubernetes* > /dev/null 2>&1"
            [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo dnf -y update --refresh" &> /dev/null
            [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && echo -e " [${GREEN}●${NC}] ${install_list} package repositories has been removed"
            [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "ls /etc/yum.repos.d/devel:kubic* > /dev/null 2>&1" && ssh ${install_list} "sudo rm /etc/yum.repos.d/devel:kubic*"
            [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo rm /etc/yum.repos.d/kubernetes* > /dev/null 2>&1"
            [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo dnf -y update --refresh" &> /dev/null
            [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && echo -e "${GREEN}${install_list} package repositories has been removed${NC}"
            [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "ls /etc/apt/sources.list.d/* > /dev/null 2>&1" && ssh ${install_list} "sudo rm /etc/apt/sources.list.d/*"
            [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo apt-get -y update" &> /dev/null
            [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && echo -e "${GREEN}${install_list} package repositories has been removed${NC}"
          done
  fi
;;

pkg-install) #Install basic package & setup environment.
  [ -z ${2} ] && node-message ${@} && exit

  check_list=${@}
  node-selector ${@}

  message="${RED}Install packages on nodes: ${YELLOW}${cp_nodes} ${wk_nodes}${NC}"
  interrupt ${message}; clear
  
  for install_list in ${cp_nodes} ${wk_nodes}
    do
      ssh ${install_list} 'hostname' &> /dev/null 2>&1
      [ $? != 0 ] && echo -e " [${RED}●${NC}] This node not available\n" && continue
      echo -e "${YELLOW}${install_list} | package install procedure${NC}"
      #swapoff
      ssh ${install_list} "sudo swapoff -a" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && swap=1 && swap_list=$(echo ${install_list} | cut -d '-' -f 2-3 | sed 's|-|--|g')
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "cat /etc/fstab | grep "/dev/mapper/rhel_rhel8--${swap_list}-swap"" &> /dev/null && swap=0
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && echo ${swap} | grep '1' &> /dev/null && ssh ${install_list} "sudo sed -i '/swap/d' /etc/fstab"

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && swap=1
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "cat /etc/fstab | grep '#/dev/mapper/rl-swap'" &> /dev/null && swap=0
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && echo ${swap} | grep '1' &> /dev/null && ssh ${install_list} "sudo sed -i 's|/dev/mapper/rl-swap|#/dev/mapper/rl-swap|g' /etc/fstab"
      
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && swap=1
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "ls -al /swap.img" &> /dev/null && ssh ${install_list} "sudo rm /swap.img" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "cat /etc/fstab | grep '#/swap.img'" &> /dev/null && swap=0
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && echo ${swap} | grep '1' &> /dev/null && ssh ${install_list} "sudo sed -i 's|/swap.img|#/swap.img|g' /etc/fstab" &> /dev/null
      
      ssh ${install_list} "sudo swapon --show | grep '/dev'" &> /dev/null
      [ $? != 0 ] && echo -e " [${GREEN}●${NC}] System\t| swap disabled" || echo -e " [${RED}●${NC}] System\t| swap not disable"

      #firewalld setup
      #[ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo dnf install -y iproute-tc &> /dev/null"

      # kubelet API | kube-scheduler | kube-controller-manager | NodePort Services | apply changes
      #[ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo firewall-cmd --permanent --add-port=6443/tcp &> /dev/null"
      #[ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo firewall-cmd --permanent --add-port=2379-2380/tcp &> /dev/null"
      #[ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo firewall-cmd --permanent --add-port=10250/tcp &> /dev/null"
      #[ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo firewall-cmd --permanent --add-port=10251/tcp &> /dev/null"
      #[ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo firewall-cmd --permanent --add-port=10252/tcp &> /dev/null"
      #[ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo firewall-cmd --reload &> /dev/null"

      #firewalld setup
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} 'sudo systemctl status firewalld | grep "active (running)"' &> /dev/null && status=1
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && echo ${status} | grep '1' &>/dev/null && ssh ${install_list} "sudo systemctl ${FIREWALLD_ENABLE} firewalld --now" &> /dev/null && echo -e " [${GREEN}●${NC}] System\t| firewalld disabled [ need reboot ]"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} 'sudo systemctl status firewalld | grep "active (running)"' &> /dev/null && status=1
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && echo ${status} | grep '1' &>/dev/null && ssh ${install_list} "sudo systemctl ${FIREWALLD_ENABLE} firewalld --now" &> /dev/null && echo -e " [${GREEN}●${NC}] System\t| firewalld disabled [ need reboot ]"
      #[ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} 'sudo systemctl status firewalld | grep "inactive (dead)"' &> /dev/null &&  echo -e " [${YELLOW}●${NC}] firewalld not disable" 

      #SELinux setting
      status=0
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo setenforce 0" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo sed -i "/^SELINUX=/c\SELINUX=${SELINUX_MODE}" /etc/selinux/config"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo nmcli connection modify ${KUBE_INTERFACE} ipv6.method ignore"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo sestatus | grep 'SELinux status:' | grep 'disabled'" &> /dev/null && echo -e " [${GREEN}●${NC}] System\t| SELinux disabled" && status=1
      [ ${status} == 0 ] && [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo sestatus | grep 'SELinux status:' | grep 'enabled'" &> /dev/null && se_status=$(ssh ${install_list} sudo sestatus | grep 'Current mode:' | awk '{ print $3 }') && echo -e " [${YELLOW}●${NC}] System\t| SELinux mode: ${YELLOW}${se_status}${NC}"

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo setenforce 0" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo sed -i "/^SELINUX=/c\SELINUX=${SELINUX_MODE}" /etc/selinux/config"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo nmcli connection modify ${KUBE_INTERFACE} ipv6.method ignore"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo sestatus | grep 'SELinux status:' | grep 'disabled'" &> /dev/null && echo -e " [${GREEN}●${NC}] System\t| SELinux disabled"
      [ ${status} == 0 ] && [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo sestatus | grep 'SELinux status:' | grep 'enabled'" &> /dev/null && se_status=$(ssh ${install_list} sudo sestatus | grep 'Current mode:' | awk '{ print $3 }') && echo -e " [${YELLOW}●${NC}] System\t| SELinux mode: ${YELLOW}${se_status}${NC}"

      #modules setup
      modules=1
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo modprobe br_netfilter" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo modprobe overlay" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "cat /etc/modules-load.d/crio.conf | grep -E 'overlay|br_netfilter'" &> /dev/null && modules=0
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && echo "${modules}" | grep '1' &> /dev/null && ssh ${install_list} "echo "overlay" | sudo tee -a /etc/modules-load.d/crio.conf" &> /dev/null && ssh ${install_list} "echo "br_netfilter" | sudo tee -a /etc/modules-load.d/crio.conf" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "cat /etc/modules-load.d/crio.conf | grep -E 'overlay|br_netfilter'" &> /dev/null && echo -e " [${GREEN}●${NC}] System\t| modules ${YELLOW}br_netfilter | overlay${NC} enabled"

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo modprobe br_netfilter" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo modprobe overlay" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "cat /etc/modules-load.d/crio.conf | grep -E 'overlay|br_netfilter'" &> /dev/null && modules=0
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && echo "${modules}" | grep '1' &> /dev/null && ssh ${install_list} "echo "overlay" | sudo tee -a /etc/modules-load.d/crio.conf" &> /dev/null && ssh ${install_list} "echo "br_netfilter" | sudo tee -a /etc/modules-load.d/crio.conf" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "cat /etc/modules-load.d/crio.conf | grep -E 'overlay|br_netfilter'" &> /dev/null && echo -e " [${GREEN}●${NC}] System\t| modules ${YELLOW}br_netfilter | overlay${NC} enabled"
            
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo modprobe br_netfilter" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo modprobe overlay" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "cat /etc/modules | grep -E 'overlay|br_netfilter'" &> /dev/null && modules=0
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && echo "${modules}" | grep '1' &> /dev/null && ssh ${install_list} "echo "overlay" | sudo tee -a /etc/modules" &> /dev/null && ssh ${install_list} "echo "br_netfilter" | sudo tee -a /etc/modules" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "cat /etc/modules | grep -E 'overlay|br_netfilter'" &> /dev/null && echo -e " [${GREEN}●${NC}] System\t| modules ${YELLOW}br_netfilter | overlay${NC} enabled"

      #ipv4_forward setup
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo sed -i 's|#net.ipv4.ip_forward=1|net.ipv4.ip_forward = 1|g' /etc/sysctl.conf" &> /dev/null
      ssh ${install_list} "cat /etc/sysctl.conf | grep 'net.ipv4.ip_forward = 1'" &> /dev/null
      [ $? != 0 ] && ssh ${install_list} "echo "net.ipv4.ip_forward = 1" | sudo tee -a /etc/sysctl.conf" &> /dev/null
      ssh ${install_list} "cat /etc/sysctl.conf | grep 'net.bridge.bridge-nf-call-iptables = 1'" &> /dev/null
      [ $? != 0 ] && ssh ${install_list} "echo "net.bridge.bridge-nf-call-iptables = 1" | sudo tee -a /etc/sysctl.conf" &> /dev/null
      ssh ${install_list} "cat /etc/sysctl.conf | grep 'net.ipv4.conf.default.rp_filter = 1'" &> /dev/null
      [ $? != 0 ] && ssh ${install_list} "echo "net.ipv4.conf.default.rp_filter = 1" | sudo tee -a /etc/sysctl.conf" &> /dev/null
      ssh ${install_list} "cat /etc/sysctl.conf | grep 'net.ipv4.conf.all.rp_filter = 1'" &> /dev/null
      [ $? != 0 ] && ssh ${install_list} "echo "net.ipv4.conf.all.rp_filter = 1" | sudo tee -a /etc/sysctl.conf" &> /dev/null
      ssh ${install_list} "sudo sysctl -p /etc/sysctl.conf" &> /dev/null
      echo -e " [${GREEN}●${NC}] System\t| ipv4_forward enabled"

      #disable ipv6
      ssh ${install_list} "cat /etc/sysctl.conf | grep 'net.ipv6.conf.all.disable_ipv6 = 1'" &> /dev/null
      [ $? != 0 ] && ssh ${install_list} "echo "net.ipv6.conf.all.disable_ipv6 = 1" | sudo tee -a /etc/sysctl.conf" &> /dev/null
      ssh ${install_list} "cat /etc/sysctl.conf | grep 'net.ipv6.conf.default.disable_ipv6 = 1'" &> /dev/null
      [ $? != 0 ] && ssh ${install_list} "echo "net.ipv6.conf.default.disable_ipv6 = 1" | sudo tee -a /etc/sysctl.conf" &> /dev/null
      ssh ${install_list} "sudo sysctl --system 2> /dev/null | grep 'net.ipv4.ip_forward'" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && echo -e " [${GREEN}●${NC}] System\t| ipv6 disabled"

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} 'sed "s|GRUB_CMDLINE_LINUX=\"\"|GRUB_CMDLINE_LINUX=\"ipv6.disable=1\"|g" /etc/default/grub | sudo tee /etc/default/grub' &> /dev/null
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo update-grub" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && echo -e " [${GREEN}●${NC}] System\t| ipv6 disabled"

      #Add crio、kubernetes package repositories
      pkg-repo-add
      os-detection

      #install cri-o
      status=0
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && CRI_PROVIDES=$(sudo dnf provides cri-o 2> /dev/null | grep 'Provide' | head -n 5 | cut -d '=' -f 2 | grep ${CRI_RELEASE} | head -n 1 | sed 's/^.//')

      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && [ "${VER_SWITCH}" == "sub" ] && ssh ${install_list} "sudo dnf install -y cri-o-${CRI_SUBVER}-* crun cri-tools" > /dev/null 2>&1 && status=1
      [ "${status}" == "0" ] && ssh ${install_list} "sudo dnf install -y cri-o-${CRI_PROVIDES} crun" > /dev/null 2>&1 && status=1
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && [ "${VER_SWITCH}" == "latest" ] && ssh ${install_list} "sudo dnf install -y cri-o-${CRI_RELEASE}.* crun cri-tools" > /dev/null 2>&1

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && [ "${VER_SWITCH}" == "sub" ] && ssh ${install_list} "sudo dnf install -y cri-o-${CRI_SUBVER}-* crun cri-tools" > /dev/null 2>&1 && status=1
      [ "${status}" == "0" ] && ssh ${install_list} "sudo dnf install -y cri-o-${CRI_PROVIDES} crun" > /dev/null 2>&1 && status=1
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && [ "${VER_SWITCH}" == "latest" ] && ssh ${install_list} "sudo dnf install -y cri-o-${CRI_RELEASE}.* crun cri-tools" > /dev/null 2>&1
      
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo apt-get install -qy -o Dpkg::Options::="--force-confold" cri-o=${CRI_SUBVER}~* crun cri-tools" &> /dev/null && status=1
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo systemctl daemon-reload" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo apt-mark hold" &> /dev/null

      ssh ${install_list} "sudo sed -i '/'1100:200'/d' /etc/cni/net.d/100-crio-bridge.conflist" &> /dev/null
      ssh ${install_list} "sudo sed -i '/\"dst\": \"::\/0\"/d' /etc/cni/net.d/100-crio-bridge.conflist" &> /dev/null
      ssh ${install_list} "sudo sed -i 's|{ \"dst\": \"0.0.0.0/0\" },|{ \"dst\": \"0.0.0.0/0\" }|g' /etc/cni/net.d/100-crio-bridge.conflist" &> /dev/null
      ssh ${install_list} "sudo sed -i 's|\[{ \"subnet\": \"10.85.0.0/16\" }\],|\[{ \"subnet\": \"10.85.0.0/16\" }\]|g' /etc/cni/net.d/100-crio-bridge.conflist" &> /dev/null
      crio-install-check ${install_list}

      #setup /etc/crio/crio.conf
      ssh ${install_list} cat /etc/crio/crio.conf 2> /dev/null | grep -A 3 "\[crio.runtime\]" | grep "conmon_cgroup = \"pod\"" &> /dev/null
      [ $? != 0 ] && ssh ${install_list} "sudo sed -i 's/\[crio.runtime\]/\[crio.runtime\]\nconmon_cgroup = \"pod\"\ncgroup_manager = \"systemd\"\ndefault_runtime = \"crun\"/g' /etc/crio/crio.conf" &> /dev/null
      ssh ${install_list} cat /etc/crio/crio.conf 2> /dev/null | grep -A 3 "\[crio.runtime.runtimes.crun\]" | grep "runtime_path = \"/usr/local/bin/crun\"" &> /dev/null #/usr/bin/crun
      [ $? != 0 ] && ssh ${install_list} "sudo sed -i 's/# \[crio.runtime.runtimes.runc\]/\[crio.runtime.runtimes.crun\]\nruntime_path = \"\/usr\/bin\/crun\"\nruntime_type = \"oci\"\nruntime_root = \"\"/g' /etc/crio/crio.conf" &> /dev/null
      ssh ${install_list} cat /etc/crio/crio.conf 2> /dev/null | grep -A 2 "\[crio.network\]" | grep "network_dir = \"/etc/cni/net.d/\"" &> /dev/null
      [ $? != 0 ] && ssh ${install_list} "sudo sed -i 's/\[crio.network\]/\[crio.network\]\nnetwork_dir = \"\/etc\/cni\/net.d\/\"\nplugin_dir = \"\/opt\/cni\/bin\"/g' /etc/crio/crio.conf" &> /dev/null
      ssh ${install_list} cat /etc/crio/crio.conf  > /dev/null 2>&1
      [ $? == 0 ] && echo -e " [${GREEN}●${NC}] Package\t| crio.conf configured" || echo -e " [${YELLOW}●${NC}] Package\t| crio.conf not exist"

      #Setup image repository registries
      target='#\ unqualified-search-registries\ =\ \[\"example.com\"\]'
      replace='unqualified-search-registries = \[\"docker.io\", \"quay.io\"\]'
      sed_context="sudo sed -i 's/${target}/${replace}/g' /etc/containers/registries.conf"
      
      ssh ${install_list} cat /etc/containers/registries.conf | grep "${replace}" &> /dev/null
      [ $? != 0 ] && ssh ${install_list} "${sed_context}"

      #Setup image repository policy
      ssh ${install_list} 'sudo bash -c "cat << \EOF > /etc/containers/policy.json
{
    \"default\": [
        {
            \"type\": \"insecureAcceptAnything\"
        }
    ],
    \"transports\":
        {
            \"docker-daemon\":
                {
                    \"\": [{\"type\":\"insecureAcceptAnything\"}]
                }
        }
}
EOF"' &> /dev/null && echo -e " [${GREEN}●${NC}] Package\t| policy.json updated"

      #Kubernetes setup
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo apt-get install -qy apt-transport-https --yes" &> /dev/null

      cri_current_ver=$(crio version 2>&1 | grep "^Version" | awk '{ print $2 }')
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && sudo dnf provides kubectl --disableexcludes=kubernetes | grep 'Provide' | grep ${CRI_RELEASE} | cut -d '=' -f 2 | grep ${cri_current_ver} &> /dev/null
      [ $? == 0 ] && KUBE_SUBVER=${cri_current_ver}

      #install podman
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo dnf install -y podman" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo dnf install -y podman" &> /dev/null

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "echo "deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/${CRIO_OS_VERSION}/ /" | sudo tee /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "curl -fsSL https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable/${CRIO_OS_VERSION}/Release.key | gpg --dearmor | sudo tee /etc/apt/trusted.gpg.d/devel_kubic_libcontainers_stable.gpg" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo apt-get -qy update" &> /dev/null
      #[ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo apt-get install -qy containers-common" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo apt-get install -qy podman" &> /dev/null
      podman-install-check ${install_list}

      echo ${install_list} | grep 'w' &> /dev/null
      [ $? == 0 ] && install="1" || install="0"
      if [ "${install}" == "1" ]
        then
          #install kube-package
          [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo dnf versionlock delete kubeadm kubelet kubectl" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo dnf install -y kubernetes-cni" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo dnf install -y kubelet-${KUBE_SUBVER}-* kubeadm-${KUBE_SUBVER}-* kubectl-${KUBE_SUBVER}-* --disableexcludes=kubernetes" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo dnf versionlock add kubelet kubeadm kubectl" &> /dev/null

          [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo dnf versionlock delete kubeadm kubelet kubectl" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo dnf install -y kubernetes-cni" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo dnf install -y kubelet-${KUBE_SUBVER}-* kubeadm-${KUBE_SUBVER}-* kubectl-${KUBE_SUBVER}-* --disableexcludes=kubernetes" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo dnf versionlock add kubelet kubeadm kubectl" &> /dev/null

          [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo apt-mark unhold kubeadm kubelet kubectl" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo apt-get install -qy kubernetes-cni" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo apt-get install -qy kubeadm=${KUBE_SUBVER}-* kubelet=${KUBE_SUBVER}-* kubectl=${KUBE_SUBVER}-*" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo systemctl daemon-reload" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo apt-mark hold kubeadm kubelet kubectl" &> /dev/null

          kubelet-install-check ${install_list}
          kubeadm-install-check ${install_list}
          kubectl-instal-check ${install_list}

          #enable crio、kubelet
          daemon-enable ${install_list}
      fi

      echo ${install_list} | grep 'm' &> /dev/null
      [ $? == 0 ] && install="1" || install="0"
      if [ "${install}" == "1" ]
        then
          #install helm
          [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "bash <(wget -q -o /dev/null -O - get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3)" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "bash <(wget -q -o /dev/null -O - get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3)" &> /dev/null

          [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo apt-get -qy update" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo apt-get install -qy helm" &> /dev/null
          [ $? == 0 ] && echo -e " [${GREEN}●${NC}] Package\t| helm installed" || echo -e " [${RED}●${NC}] Package\t| helm not installed"

          #install kube-package
          curl -s https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg | grep '<title>' | grep 'Error' &> /dev/null
          [ $? == 0 ] && echo -e " [${RED}●${NC}] Google server rpm-pkg-key.gpg is missing"
          [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo dnf install -y kubelet-${KUBE_SUBVER}-* kubeadm-${KUBE_SUBVER}-* kubectl-${KUBE_SUBVER}-* --disableexcludes=kubernetes" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo dnf versionlock add kubelet kubeadm kubectl" &> /dev/null

          [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo dnf install -y kubelet-${KUBE_SUBVER}-* kubeadm-${KUBE_SUBVER}-* kubectl-${KUBE_SUBVER}-* --disableexcludes=kubernetes" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo dnf versionlock add kubelet kubeadm kubectl" &> /dev/null

          [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo apt-mark unhold kubeadm kubelet kubectl" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo apt-get install -qy kubernetes-cni" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo apt-get install -qy -o Dpkg::Options::="--force-confold" kubeadm=${KUBE_SUBVER}-* kubelet=${KUBE_SUBVER}-* kubectl=${KUBE_SUBVER}-*" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo apt-mark hold kubeadm kubelet kubectl" &> /dev/null

          kubelet-install-check ${install_list}
          kubeadm-install-check ${install_list}
          kubectl-instal-check ${install_list}

          #install k9s
          ssh ${install_list} "ls -al ~/bin/k9s" &> /dev/null
          [ $? == 0 ] && echo -e " [${GREEN}●${NC}] Package\t| k9s installed" && daemon-enable ${install_list} && echo && continue || curl --max-time 5 -fsSLq https://webinstall.dev/api/installers/k9s@stable.sh &> /dev/null && ssh ${install_list} "curl -sS https://webinstall.dev/k9s | bash" &> /dev/null
          #k9s path setup
          ssh ${install_list} "mv ~/.local/bin/k9s ~/bin/" &> /dev/null
          ssh ${install_list} "cat /etc/environment | grep "/home/${USER}/bin" &> /dev/null" &> /dev/null
          [ $? != 0 ] && ssh ${install_list} "cat /etc/environment | tr -s ':' '\n' | sed 's/\/snap\/bin\"/\/snap\/bin\n\/home\/${USER}\/bin\"/g' | tr -s '\n' ':' | sed '$ s/.$//' | sudo tee /etc/environment &> /dev/null" &> /dev/null
          ssh ${install_list} "cat /etc/profile | grep 'export EDITOR=nano' &> /dev/null" &> /dev/null
          [ $? != 0 ] && ssh ${install_list} "echo "export EDITOR=nano" | sudo tee -a /etc/profile" &> /dev/null
          ssh ${install_list} "cat /etc/profile | grep 'export K9S_EDITOR=nano' &> /dev/null" &> /dev/null
          [ $? != 0 ] && ssh ${install_list} "echo "export K9S_EDITOR=nano" | sudo tee -a /etc/profile" &> /dev/null
          ssh ${install_list} "rm -r ~/Downloads/" &> /dev/null

          ssh ${install_list} "ls -al ~/bin/k9s" &> /dev/null
          [ $? == 0 ] && echo -e " [${GREEN}●${NC}] Package\t| k9s installed" || echo -e " [${RED}●${NC}] k9s not install"
          
          #enable crio、kubelet
          daemon-enable ${install_list}
      fi
    done
  echo && echo -e "${YELLOW}Package Check list${NS}"
  pkg-check ${check_list} && echo
;;

pkg-rm) #Remove basic package & setup environment.
  [ -z ${2} ] && node-message && exit

  node-selector ${@}

  message="${RED}Please confirm this command will destruction node:${YELLOW} ${cp_nodes} ${wk_nodes}!${NC}"
  interrupt ${message}

  echo -n "As you wish"; echo -n "."; sleep 0.5; echo -n "."; sleep 0.5; echo "."; sleep 0.5

  for clist in ${cp_nodes}
    do
      echo -e "\n${YELLOW}${clist} | package removing${NC}"
      ssh ${clist} "which k9s" &> /dev/null
      [ $? == 0 ] && ssh ${clist} "rm ~/bin/k9s"
      echo -en "${GREEN}"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${clist} "sudo dnf versionlock delete cri-o kubectl kubeadm kubelet podman"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${clist} "sudo systemctl disable --now cri-o"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${clist} "sudo systemctl disable --now kubelet"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${clist} "sudo dnf remove -y kubectl kubeadm kubelet"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${clist} "sudo dnf remove -y podman"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${clist} "sudo dnf remove -y cri-o cri-tools*"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${clist} "which crio &> /dev/null"
      [ $? == 0 ] && [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${clist} "sudo rm /usr/local/bin/crio"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${clist} 'sudo rm `which helm`' 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${clist} "sudo dnf autoremove -y"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${clist} "sudo systemctl daemon-reload"

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${clist} "sudo dnf versionlock delete cri-o kubectl kubeadm kubelet podman"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${clist} "sudo systemctl disable --now crio"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${clist} "sudo systemctl disable --now kubelet"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${clist} "sudo dnf remove -y kubectl kubeadm kubelet"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${clist} "sudo dnf remove -y podman"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${clist} "sudo dnf remove -y cri-o cri-tools*"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${clist} "which crio &> /dev/null"
      [ $? == 0 ] && [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${clist} "sudo rm /usr/local/bin/crio"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${clist} 'sudo rm `which helm`' 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${clist} "sudo dnf autoremove -y"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${clist} "sudo systemctl daemon-reload"

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${clist} "sudo apt-mark unhold kubeadm kubelet kubectl"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${clist} "sudo systemctl disable --now crio"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${clist} "sudo systemctl disable --now kubelet"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${clist} "sudo apt-get purge -qy --allow-change-held-packages kubectl kubeadm kubelet kubernetes-cni"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${clist} "sudo apt-get purge -qy --allow-change-held-packages cri-o cri-tools cri-o-runc"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${clist} "which crio &> /dev/null"
      [ $? == 0 ] && [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${clist} "sudo rm /usr/local/bin/crio"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${clist} "sudo apt-get purge -qy helm podman"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${clist} "sudo apt-get autoremove -qy"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${clist} "sudo systemctl daemon-reload"
      echo -en "${NC}"
    done

  for wlist in ${wk_nodes}
    do
      echo -e "\n${YELLOW}${wlist} | package removing${NC}"
      echo -en "${GREEN}"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf versionlock delete cri-o kubectl kubeadm kubelet podman"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo systemctl disable --now cri-o"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo systemctl disable --now kubelet"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf remove -y kubectl kubeadm kubelet"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf remove -y podman"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf remove -y cri-o cri-tools*"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "which crio &> /dev/null"
      [ $? == 0 ] && [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo rm /usr/local/bin/crio"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} 'sudo rm `which helm`' 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf autoremove -y"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo systemctl daemon-reload"

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf versionlock delete cri-o kubectl kubeadm kubelet podman"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo systemctl disable --now cri-o"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo systemctl disable --now kubelet"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf remove -y kubectl kubeadm kubelet"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf remove -y podman"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf remove -y cri-o cri-tools*"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "which crio &> /dev/null"
      [ $? == 0 ] && [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo rm /usr/local/bin/crio"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} 'sudo rm `which helm`' 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf autoremove -y"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo systemctl daemon-reload"

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-mark unhold kubeadm kubelet"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo systemctl disable --now crio"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo systemctl disable --now kubelet"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-get purge -qy --allow-change-held-packages kubectl kubeadm kubelet kubernetes-cni"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-get purge -qy --allow-change-held-packages cri-o cri-tools cri-o-runc podman"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "which crio &> /dev/null"
      [ $? == 0 ] && [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo rm /usr/local/bin/crio"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-get autoremove -qy podman"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo systemctl daemon-reload"
      echo -en "${NC}"
    done
  node-power reboot ${@}
;;

pkg-check) #Check node package status.
  pkg-check ${@}
;;

k9s-install) #Install k9s.
  for clist in ${CP_NODES}
    do
      #install k9s
      ssh ${clist} "ls -al ~/bin/k9s" &> /dev/null
      [ $? == 0 ] && echo -e " [${GREEN}●${NC}] ${clist} ${YELLOW}k9s${NC} already installed." && continue || ssh ${clist} "curl -sS https://webinstall.dev/k9s | timeout 20 bash" &> /dev/null
      #k9s path setup
      ssh ${clist} "mv ~/.local/bin/k9s ~/bin/" &> /dev/null
      ssh ${clist} "cat /etc/environment | grep "/home/${USER}/bin" &> /dev/null" &> /dev/null
      [ $? != 0 ] && ssh ${clist} "cat /etc/environment | tr -s ':' '\n' | sed 's/\/snap\/bin\"/\/snap\/bin\n\/home\/${USER}\/bin\"/g' | tr -s '\n' ':' | sed '$ s/.$//' | sudo tee /etc/environment &> /dev/null" &> /dev/null
      ssh ${clist} "cat /etc/profile | grep 'export EDITOR=nano' &> /dev/null" &> /dev/null
      [ $? != 0 ] && ssh ${clist} "echo "export EDITOR=nano" | sudo tee -a /etc/profile" &> /dev/null
      ssh ${clist} "cat /etc/profile | grep 'export K9S_EDITOR=nano' &> /dev/null" &> /dev/null
      [ $? != 0 ] && ssh ${clist} "echo "export K9S_EDITOR=nano" | sudo tee -a /etc/profile" &> /dev/null
      ssh ${clist} "rm -r ~/Downloads/" &> /dev/null
      ssh ${clist} "ls -al ~/bin/k9s" &> /dev/null
      [ $? == 0 ] && echo -e " [${GREEN}●${NC}] ${clist} k9s installed"
    done; echo
;;

k9s-rm) #Delete k9s.
  for clist in ${CP_NODES}
    do
      #delete k9s
      ssh ${clist} "rm ~/bin/k9s" &> /dev/null
      [ $? == 0 ] && echo -e " [${GREEN}●${NC}] ${clist} k9s removed" || echo -e " [${RED}●${NC}] ${clist} k9s not detected"
    done; echo
;;

daemon-enable)
  [ -z ${2} ] && node-message ${@} && exit

  check_list=${@}
  node-selector ${@}

  message="${RED}Install packages on nodes: ${YELLOW}${cp_nodes} ${wk_nodes}${NC}"
  interrupt ${message}; clear

  for install_list in ${wk_nodes} ${cp_nodes}
    do
      echo -e "${YELLOW}${install_list} | daemon status${NC}"
      daemon-enable ${install_list}
      echo
    done
;;

cp-init) #Init first control-plane node & deploy CNI. [ calico | flannel ]
  #KUBE_VIP setup
  [ ${#} != 2 ] && echo -e "${RED}Please input parameter after ${YELLOW}\"cp-init\" \n > [ calico | flannel ]${NC}\n" && exit
  echo "${2}" | grep -E 'calico|flannel' &> /dev/null
  [ $? != 0 ] && echo -e "${RED}Please input parameter after ${YELLOW}\"cp-init\" \n > [ calico | flannel ]${NC}\n" && exit

  message="${RED}Please confirm this command will initialize kubernetes via ${YELLOW}`hostname`.${NC}"
  interrupt ${message}

  ls /etc/kubernetes/manifests &> /dev/null 
  [ $? != 0 ] && sudo mkdir -p /etc/kubernetes/manifests
  wget -O - https://raw.githubusercontent.com/kube-vip/kube-vip/main/docs/manifests/v0.4.1/kube-vip-arp.yaml | sed "s|eth0|${KUBE_INTERFACE}|g" | sed "s|192.168.0.1|${KUBE_VIP}|g" | sed "s|imagePullPolicy\: Always|imagePullPolicy\: IfNotPresent|g" | sudo tee /etc/kubernetes/manifests/kube-vip-arp.yaml
  ls yaml &> /dev/null
  [ $? != 0 ] && mkdir yaml
  sudo cp /etc/kubernetes/manifests/kube-vip-arp.yaml yaml/
  sudo chown bigred:bigred yaml/kube-vip-arp.yaml
  
  KUBEADM_VER=$(kubeadm version -o yaml | grep "gitVersion:" | head -n 1 | awk '{ print $2 }' | sed 's|v||g')
  [ "${KUBE_INIT_VER}" != "${KUBEADM_VER}" ] && KUBE_INIT_VER=$(kubeadm version -o yaml | grep "gitVersion:" | head -n 1 | awk '{ print $2 }' | sed 's|v||g')

  # Kubernetes setup
  # calico service & pod network
  [ "${2}" == "calico" ] && export POD_CIDR=10.85.0.0/16
  [ "${2}" == "calico" ] && export SVC_CIDR=10.96.0.0/12
  [ "${2}" == "calico" ] && sudo kubeadm init --image-repository=${KUBE_REGISTRY} --control-plane-endpoint=${KUBE_VIP}:6443 --pod-network-cidr=${POD_CIDR} --service-cidr=${SVC_CIDR} --service-dns-domain=k8s.org --cri-socket=/var/run/crio/crio.sock --upload-certs --kubernetes-version=${KUBE_INIT_VER} --v=5
  [ $? != 0 ] && [ "${2}" == "calico" ] && message="${RED}\nkubeadm init failure!${NC}" && interrupt ${message}
  [ "${2}" == "calico" ] && mkdir -p ${HOME}/.kube && sudo cp -i /etc/kubernetes/admin.conf ${HOME}/.kube/config && sudo chown $(id -u):$(id -g) ${HOME}/.kube/config
  [ "${2}" == "calico" ] && ls ${HOME}/.kube/config &> /dev/null
  #helm calico network
  [ "${2}" == "calico" ] && helm repo add projectcalico https://projectcalico.docs.tigera.io/charts
  [ "${2}" == "calico" ] && kubectl create namespace tigera-operator
  [ "${2}" == "calico" ] && helm install calico projectcalico/tigera-operator --version v3.24.1 --namespace tigera-operator
  #[ $? != 0 ] && echo -e "kubeadm init failure.\n" && exit

  # flannel service & pod network
  [ "${2}" == "flannel" ] && export POD_CIDR=10.244.0.0/16
  [ "${2}" == "flannel" ] && export SVC_CIDR=10.98.0.0/24
  [ "${2}" == "flannel" ] && sudo kubeadm init --image-repository=${KUBE_REGISTRY} --control-plane-endpoint=${KUBE_VIP}:6443 --pod-network-cidr=${POD_CIDR} --service-cidr=${SVC_CIDR} --service-dns-domain=k8s.org --cri-socket=/var/run/crio/crio.sock --upload-certs --kubernetes-version=${KUBE_INIT_VER} --v=5
  [ $? != 0 ] && [ "${2}" == "flannel" ] && message="${RED}\nkubeadm init failure!${NC}" && interrupt ${message}
  [ "${2}" == "flannel" ] && mkdir -p ${HOME}/.kube && sudo cp -i /etc/kubernetes/admin.conf ${HOME}/.kube/config && sudo chown $(id -u):$(id -g) ${HOME}/.kube/config
  [ "${2}" == "flannel" ] && ls ${HOME}/.kube/config &> /dev/null
  [ "${2}" == "flannel" ] && kubectl apply -f https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/kube-flannel.yml
  #[ $? != 0 ] && echo -e "kubeadm init failure.\n" && exit
  echo -en "${GREEN}"

  #taint setup
  KUBE_CURRENT_VER=$(kubectl get nodes | grep "control-plane" | awk '{ print $5 }' | head -n 1)
  kubectl taint node `hostname` node-role.kubernetes.io/control-plane:NoSchedule-
  echo "${KUBE_CURRENT_VER}" | grep -E '1.25|1.26' &> /dev/null
  [ $? != 0 ] && kubectl taint node `hostname` node-role.kubernetes.io/master:NoSchedule-
  echo -en "${NC}"
  echo && k9s -c pods -A
;;

cp-join) # Let control-plane nodes join cluster. [ <hosts> | <node> ]
  [ -z ${2} ] && cp-node-message ${@} && exit

  node-selector ${@}

  if [ "${2}" == "hosts" ]
    then
      cluster_list=$(kubectl get nodes | tail -n +2 | awk '{ print $1 }' | tr -s '\n' '|' | sed '$ s/.$//')
      cp_nodes=$(echo -e "`cat /etc/hosts | grep -vE '#|ip6|k8s.org' | grep "${NETID}" | awk '{ print $2 }' | grep -vE ${cluster_list}| tr -s ' ' '\n' | grep "\-m" | tr -s '\n' ' '`\n")
      echo ${cp_nodes} | grep -n '^$' &> /dev/null && cp_nodes="none "
    else
      shift
      list="${@}"
      cp_nodes=$(echo "${list}" | tr -s ' ' '\n' | grep "\-m" | tr -s '\n' ' ')
  fi
  message="${RED}Please confirm this command will let ${YELLOW}${cp_nodes}${RED}join cluster!${NC}"
  interrupt ${message}
  [ "${cp_nodes}" == "none " ] && echo -e "${RED}Command canceled${NC}\n" && exit

  ls yaml &> /dev/null
  [ $? != 0 ] && mkdir yaml && cp /etc/kubernetes/manifests/kube-vip-arp.yaml yaml/

  certs=$(sudo kubeadm init phase upload-certs --upload-certs | tail -n 1)
  export JOIN=$(echo "sudo `kubeadm token create --print-join-command 2>/dev/null`")
  for clist in ${cp_nodes}
    do
      echo -e "${YELLOW}${clist} | join procedure${NC}"
      ssh ${clist} "ls yaml &> /dev/null"
      [ $? != 0 ] && ssh ${clist} "mkdir yaml"
      scp yaml/kube-vip-arp.yaml ${clist}:yaml/
      ssh ${clist} "${JOIN} --control-plane --certificate-key ${certs} --v=5"
      [ $? != 0 ] && message="${RED}\nkubeadm join failure!${NC}" && interrupt ${message}
      echo -en "${GREEN}"

      #taint setup
      kubectl taint node ${clist} node-role.kubernetes.io/control-plane:NoSchedule-
      KUBE_CURRENT_VER=$(kubectl get nodes | grep "control-plane" | awk '{ print $5 }' | head -n 1)
      echo "${KUBE_CURRENT_VER}" | grep -E '1.25|1.26' &> /dev/null
      [ $? != 0 ] && kubectl taint node `hostname` node-role.kubernetes.io/master:NoSchedule-

      echo -en "${NC}"
      ssh ${clist} "ls /etc/kubernetes/manifests" &> /dev/null
      [ $? != 0 ] && ssh ${clist} "sudo mkdir -p /etc/kubernetes/manifests"
      ssh ${clist} "sudo cp yaml/kube-vip-arp.yaml /etc/kubernetes/manifests/kube-vip-arp.yaml"
      ssh ${clist} "mkdir -p ${HOME}/.kube"
      scp .kube/config ${clist}:.kube/
    done; echo && k9s -c pods -A
;;

wk-join) #Let worker nodes join cluster. [ <hosts> | <node> ]
  [ -z ${2} ] && wk-node-message ${@} && exit
  if [ "${2}" == "hosts" ]
    then
      cluster_list=$(kubectl get nodes | tail -n +2 | awk '{ print $1 }' | tr -s '\n' '|' | sed '$ s/.$//')
      wk_nodes=$(echo -e "`cat /etc/hosts | grep -vE '#|ip6|k8s.org' | grep "${NETID}" | awk '{ print $2 }' | grep -vE ${cluster_list}| tr -s ' ' '\n' | grep "\-w" | tr -s '\n' ' '`\n")
      echo ${wk_nodes} | grep -n '^$' &> /dev/null && wk_nodes="none "
    else
      shift
      list="${@}"
      wk_nodes=$(echo "${list}" | tr -s ' ' '\n' | grep "\-w" | tr -s '\n' ' ')
  fi

  message="${RED}Please confirm this command will let ${YELLOW}${wk_nodes}${RED}join cluster!${NC}"
  interrupt ${message}
  [ "${wk_nodes}" == "none " ] && echo -e "${RED}Command canceled${NC}\n" && exit

  export JOIN=$(echo "sudo `kubeadm token create --print-join-command 2>/dev/null`")
  for wlist in ${wk_nodes}
    do
      echo -e "${YELLOW}${wlist} | join procedure${NC}"
      ssh ${wlist} "${JOIN} --v=5"
      echo -en "${GREEN}"
      kubectl label node ${wlist} node-role.kubernetes.io/worker=
      echo -en "${NC}"
    done; echo && k9s -c pods -A
;;

cni-deploy) #Deploy kubernetes CNI. [ calico | flannel ]
  message="${RED}Please confirm there is no CNI running on kubernetes.${NC}"
  interrupt ${message}
  if [ -z ${2} ]
    then
      echo; echo -e "Please input cni project. [ calico | flannel ]\n"
    elif [ ${2} == "calico" ]
      then
        #helm calico network
        helm repo add projectcalico https://projectcalico.docs.tigera.io/charts
        kubectl create namespace tigera-operator
        helm install calico projectcalico/tigera-operator --version v3.24.1 --namespace tigera-operator
        k9s -n calico-system
    elif [ ${2} == "flannel" ]
      then
        #flannel network
        kubectl apply -f https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/kube-flannel.yml
        k9s -n kube-system
  fi
;;

cni-rm) #Delete kubernetes CNI. [ calico | flannel ]
  if [ -z ${2} ]
    then
      echo; echo -e "Please input cni project. [calico、flannel]\n"
    elif [ ${2} == "calico" ]
      then
        #helm calico network
        helm delete calico -n tigera-operator
        kubectl delete namespace tigera-operator
        helm repo remove projectcalico
    elif [ ${2} == "flannel" ]
      then
        #flannel network
        kubectl delete -f https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/kube-flannel.yml
        for install_list in ${CP_NODES} ${WK_NODES}
          do
            ssh ${install_list} "sudo rm /etc/cni/net.d/*flannel*"
          done
  fi
;;

dns-rollout) #Rollout coredns & calico-api-server. [ if pod present ]
  #rollout coredns/calico-apiserver
  kubectl rollout restart deployment/coredns -n kube-system &> /dev/null
  while true
    do
      kubectl get pods -n kube-system | grep 'coredns' | awk '{ print $3 }' | grep -v 'Running' &> /dev/null
      [ $? != 0 ] && break
    done
    echo -e " [${GREEN}●${NC}] coredns rollout"

  kubectl get ns | grep 'calico-apiserver' &> /dev/null
  [ $? == 0 ] && kubectl rollout restart deployment/calico-apiserver -n calico-apiserver &> /dev/null || exit

  while true
    do
      kubectl get pods -n calico-apiserver | grep 'calico-apiserver' | awk '{ print $3 }' | grep -v 'Running' &> /dev/null
      [ $? != 0 ] && break
    done
    echo -e " [${GREEN}●${NC}] calico-apiserver rollout"
    echo
;;

csi-deploy) #Deploy kubernetes CSI. [ local-path | rook-ceph ]
  if [ -z ${2} ]
    then
      echo -e "Please input csi project. [ local-path | rook-ceph ]\n"
    elif [ ${2} == "local-path" ]
      then
          #local-path-storage
          kubectl apply -f https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/local-path-storage.yaml
          k9s -n local-path-storage
    elif [ ${2} == "rook-ceph" ]
      then
        which git &> /dev/null
        [ $? != 0 ] && echo "install git" && sudo dnf install -y git && clear
        #helm repo add rook-release https://charts.rook.io/release
        ls yaml/rook/ &> /dev/null
        [ $? != 0 ] && mkdir yaml/rook/
        ls rook/ &> /dev/null
        [ $? == 0 ] && sudo rm -r ~/rook && git clone --single-branch --branch release-1.10 -b ${ROOK_TAG} https://github.com/rook/rook.git || git clone --single-branch --branch release-1.10 -b ${ROOK_TAG} https://github.com/rook/rook.git
        #copy
        cp ~/rook/deploy/examples/crds.yaml ~/yaml/rook/
        cp ~/rook/deploy/examples/common.yaml ~/yaml/rook/
        cp ~/rook/deploy/examples/operator.yaml ~/yaml/rook/
        cp ~/rook/deploy/examples/cluster.yaml ~/yaml/rook/
        cp ~/rook/deploy/examples/pool.yaml ~/yaml/rook/
        cp ~/rook/deploy/examples/toolbox.yaml ~/yaml/rook

        cp ~/rook/deploy/examples/csi/rbd/pvc.yaml ~/yaml/rook

        cp ~/rook/deploy/examples/csi/cephfs/storageclass.yaml ~/yaml/rook/storageclass-fs.yaml
        cp ~/rook/deploy/examples/csi/cephfs/pvc.yaml ~/yaml/rook/pvc-fs.yaml

        #if SELinux enabled, must be set this variable to true
        status=0
        [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && getenforce | grep -E 'Permissive|Enforcing' &> /dev/null
        [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && getenforce | grep -E 'Permissive|Enforcing' &> /dev/null
        [ $? == 0 ] && sed -i '/ROOK_HOSTPATH_REQUIRES_PRIVILEGED/{n;s/false/true/;}' ~/yaml/rook/operator.yaml
        
        [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && cat ~/yaml/rook/operator.yaml | grep -A 1 'ROOK_HOSTPATH_REQUIRES_PRIVILEGED' | grep 'value: "true"' &> /dev/null && status=1 || status=0
        [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && cat ~/yaml/rook/operator.yaml | grep -A 1 'ROOK_HOSTPATH_REQUIRES_PRIVILEGED' | grep 'value: "true"' &> /dev/null && status=1 || status=0
        [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && status=1
        [ "${status}" == "0" ] && echo -e " [${RED}●${NC}] ~/yaml/rook/operator.yaml setting is Incorrect. " && exit
        
        #apply yaml
        echo -e "${YELLOW}crds applied${NC}"
        kubectl apply -f ~/yaml/rook/crds.yaml; sleep 2
        echo -e "${YELLOW}common applied${NC}"
        kubectl apply -f ~/yaml/rook/common.yaml; sleep 2
        echo -e "${YELLOW}operator applied${NC}"
        kubectl apply -f ~/yaml/rook/operator.yaml; sleep 2
        echo -e "${YELLOW}cluster applied${NC}"
        kubectl apply -f ~/yaml/rook/cluster.yaml; sleep 2
        echo -e "${YELLOW}pool applied${NC}"
        kubectl apply -f ~/yaml/rook/pool.yaml; sleep 2
        echo -e "${YELLOW}toolbox applied${NC}"
        kubectl apply -f ~/yaml/rook/toolbox.yaml; sleep 2
        
        echo -e "${YELLOW}storageclass-fs applied${NC}"
        kubectl apply -f ~/yaml/rook/storageclass-fs.yaml; sleep 2
        
        echo -e "${YELLOW}deshboard ingress applied${NC}"
        kubectl apply -f https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/ceph-deshboard.yaml
        
        echo -e "\n${YELLOW}rook-ceph deployed, please wait OSDs deploy.${NC}"
        sleep 3
        k9s -c pods -n ${NAME_SPACE_8}
  fi
;;

csi-rm) #Delete kubernetes CSI. [ local-path | rook-ceph ]
  if [ -z ${2} ]
    then
      echo -e "Please input csi project. [ local-path | rook-ceph ]\n"
    elif [ ${2} == "local-path" ]
      then
        message="${RED}Please confirm this command will destruction CSI ${YELLOW}${2} ${RED}!${NC}"
        interrupt ${message}
        #local-path-storage
        kubectl delete -f https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/local-path-storage.yaml
        [ $? == 0 ] && echo "local-path-storage deleted."
    elif [ ${2} == "rook-ceph" ]
      then
        list=$(kubectl api-resources --verbs=list --namespaced -o name | xargs -n 1 kubectl get --show-kind --ignore-not-found -n rook-ceph | grep -v '^[0-9]' | grep -v '^[A-Z]' | awk '{ print $1 }')
        for i in ${list}
          do
            kubectl -n rook-ceph patch ${i} -p '{"metadata":{"finalizers": []}}' --type=merge
          done
        message="${RED}Please confirm this command will destruction CSI ${YELLOW}${2} ${RED}!${NC}"
        interrupt ${message}
        kubectl -n ${NAME_SPACE_8} patch cephcluster rook-ceph --type merge -p '{"spec":{"cleanupPolicy":{"confirmation":"yes-really-destroy-data"}}}'
        kubectl delete CephBlockPool/replicapool -n ${NAME_SPACE_8}
        kubectl delete -f ~/yaml/rook/storageclass-fs.yaml
        kubectl -n ${NAME_SPACE_8} delete cephcluster rook-ceph

        kubectl delete -f https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/ceph-deshboard.yaml
        kubectl delete -f ~/yaml/rook/toolbox.yaml; sleep 2
        kubectl delete -f ~/yaml/rook/operator.yaml; sleep 2
        kubectl delete -f ~/yaml/rook/common.yaml; sleep 2
        kubectl delete -f ~/yaml/rook/crds.yaml; sleep 2
        kubectl delete namespace rook-ceph
        kdm csi-rook wipe-data hosts /dev/sdb
  fi
;;

csi-rook) #Check rook status or DataDir. [ status | dashboard-pw | data-check | lvm-status | wipe-data | disk-check ]
  if [ "$2" == "" ]
    then
      echo -e "${YELLOW}Please input parameter [ status | dashboard-pw | data-check | lvm-status | wipe-data | disk-check ]${NC}"
  elif [ "$2" == "status" ]
    then
      #rook version
      kubectl get ns | grep 'rook-ceph' &> /dev/null
      [ $? != 0 ] && echo -e " [${RED}●${NC}] rook-ceph not detected\n" && exit

      ROOK_GIT_VER=$(kubectl -n ${NAME_SPACE_8} get jobs -o jsonpath='{range .items[*]}{.metadata.name}{"  \tsucceeded: "}{.status.succeeded}{"      \trook-version="}{.metadata.labels.rook-version}{"\n"}{end}' | awk '{ print $4 }' | cut -d '=' -f 2 | grep "^v" | head -n 1)
      POD_NAME=$(kubectl -n ${NAME_SPACE_8} get pod -o custom-columns=name:.metadata.name --no-headers | grep rook-ceph-mon-b)
      CEPH_IMAGE=$(kubectl -n ${NAME_SPACE_8} get pod ${POD_NAME} -o jsonpath='{.spec.containers[0].image}')
      kubectl -n ${NAME_SPACE_8} get pod -l "app=rook-ceph-tools" -o jsonpath='{.items[0].metadata.name}' > /dev/null 2>&1
      [ $? == 0 ] && CEPH_VER=$(echo -e "`kubectl -n ${NAME_SPACE_8} exec -it $(kubectl -n ${NAME_SPACE_8} get pod -l "app=rook-ceph-tools" -o jsonpath='{.items[0].metadata.name}') -- ceph --version | awk '{ print $3 }'`\n")
      
      echo -e "Rook-ceph git release: ${ROOK_GIT_VER}\nceph version: ${CEPH_VER} | image: ${CEPH_IMAGE}\n"
      
      #rook status
      [ $? == 0 ] && kubectl -n ${NAME_SPACE_8} exec -it $(kubectl -n ${NAME_SPACE_8} get pod -l "app=rook-ceph-tools" -o jsonpath='{.items[0].metadata.name}') -- ceph -s || echo -e "- rook-ceph not detected\n"
      kubectl -n ${NAME_SPACE_8} get pod -l "app=rook-ceph-tools" -o jsonpath='{.items[0].metadata.name}' > /dev/null 2>&1
      [ $? == 0 ] && kubectl -n ${NAME_SPACE_8} exec -it $(kubectl -n ${NAME_SPACE_8} get pod -l "app=rook-ceph-tools" -o jsonpath='{.items[0].metadata.name}') -- ceph osd status || echo -e "- rook-ceph not detected\n"
  elif [ "$2" == "fix-mon" ]
    then
      kubectl get ConfigMap rook-config-override -n ${NAME_SPACE_8} -o yaml | sed 's/""/| /g' | sed 's/config: | /config: |\n    [global]\n    mon clock drift allowed = 0.5/g' > yaml/rook/rook-config-override.yaml
      kubectl replace -f yaml/rook/rook-config-override.yaml --force
      kubectl delete pods -n ${NAME_SPACE_8} $(kubectl get pods -n ${NAME_SPACE_8} -o custom-columns=NAME:.metadata.name --no-headers | grep 'mon')
  elif [ "$2" == "dashboard-pw" ]
    then
      kubectl -n ${NAME_SPACE_8} get pod -l "app=rook-ceph-tools" -o jsonpath='{.items[0].metadata.name}' > /dev/null 2>&1
      [ $? == 0 ] && echo -e "`kubectl -n ${NAME_SPACE_8} get secret rook-ceph-dashboard-password -o jsonpath="{['data']['password']}" | base64 --decode`\n" || echo -e "- rook-ceph not detected\n"
  elif [ "$2" == "data-check" ]
    then
      for install_list in ${CP_NODES} ${WK_NODES};
        do
          echo "${install_list} | Rook DataDir checking"
          ssh ${install_list} ls /var/lib/rook &> /dev/null
          [ $? == 0 ] && echo -e "Directory exist\n" || echo -e "- Directory not exist\n"
        done
  elif [ "$2" == "lvm-status" ]
    then
      for wlist in ${CP_NODES} ${WK_NODES};
        do
          echo "${wlist} | Node lvm-status"
          ssh ${wlist} sudo pvscan
          #[ $? == 0 ] && echo "rook-ceph signature has wiped" || echo "- rook-ceph signature not found"
          echo
        done
  elif [ "$2" == "wipe-data" ]
    then
      node-selector ${@}
      message="${RED}Please confirm this command will override disk on ${wk_nodes}!${NC}"
      interrupt ${message}
      echo -e "${YELLOW}Rook data wipe procedure${NC}"
      
      for wlist in ${wk_nodes}
        do
          disk_list=$(ssh ${wlist} sudo fdisk -l | grep '^Disk' | grep 'sd' | awk '{ print $2 }' | sed 's/://g;s/\/dev\///g' | tr -s '\n' ' ' | sed 's/.$//' | sed 's/sd/\/dev\/sd/g')
          for ceph_list in ${disk_list}
            do
              taget=""
              ssh ${wlist} sudo wipefs ${ceph_list} | grep 'ceph_bluestore' &> /dev/null
              [ $? == 0 ] && taget="/dev/"$(ssh ${wlist} sudo wipefs ${ceph_list} | grep 'ceph_bluestore' | awk '{ print $1 }') && break || continue
            done
          echo -e "${YELLOW}${wlist} data wipe procedure${NC}"
          ssh ${wlist} sudo wipefs -a ${taget} &> /dev/null
          [ $? == 0 ] && echo -e " [${GREEN}●${NC}] ${taget} signature has been wiped" || echo -e " [${RED}●${NC}] ${CEPH_DISK} signature not found"
          #Zap the disk to a fresh, usable state (zap-all is important, b/c MBR has to be clean)
          ssh ${wlist} sudo sgdisk --zap-all ${taget} &> /dev/null
          [ $? == 0 ] && echo -e " [${GREEN}●${NC}] ${taget} GPT data structures destroyed!" || echo -e " [${RED}●${NC}] ${CEPH_DISK} GPT data structures not changed!"
          #Wipe a large portion of the beginning of the disk to remove more LVM metadata that may be present
          ssh ${wlist} sudo dd if=/dev/zero of="${taget}" bs=1M count=100 oflag=direct,dsync &> /dev/null
          [ $? == 0 ] && echo -e " [${GREEN}●${NC}] ${taget} has been overwrite by /dev/zero" || echo -e " [${RED}●${NC}] ${CEPH_DISK} not overwrite!"
          #SSDs may be better cleaned with blkdiscard instead of dd
          ssh ${wlist} sudo blkdiscard ${taget} &> /dev/null
          #Inform the OS of partition table changes
          ssh ${wlist} sudo partprobe ${taget} &> /dev/null
          ssh ${wlist} sudo rm -r /var/lib/rook/ &> /dev/null
          [ $? == 0 ] && echo -e " [${GREEN}●${NC}] Data directory has been cleanup" || echo -e " [${RED}●${NC}] Data directory not found"
        done

      for clist in ${cp_nodes};
        do
          echo -e "${YELLOW}${clist} data wipe procedure${NC}"
          ssh ${clist} sudo rm -r /var/lib/rook/ &> /dev/null
          [ $? == 0 ] && echo -e " [${GREEN}●${NC}] ${clist} Directory has been cleanup" || echo -e " [${RED}●${NC}] ${clist} Data directory not found"
        done
  elif [ "$2" == "disk-check" ]
    then
      node-selector ${@}
      echo -e "${YELLOW}Check worker disk resource for rook-ceph${NC}"

      for wlist in ${wk_nodes}
        do
          disk_list=$(ssh ${wlist} sudo fdisk -l | grep '^Disk' | grep 'sd' | awk '{ print $2 }' | sed 's/://g;s/\/dev\///g' | tr -s '\n' ' ' | sed 's/.$//' | sed 's/sd/\/dev\/sd/g')
          for ceph_list in ${disk_list}
            do
              taget=""
              ssh ${wlist} sudo wipefs ${ceph_list} | grep 'ceph_bluestore' &> /dev/null
              [ $? == 0 ] && taget="/dev/"$(ssh ${wlist} sudo wipefs ${ceph_list} | grep 'ceph_bluestore' | awk '{ print $1 }') && break || continue
            done
          echo "${wlist}: ${taget}"
        done
  fi
  echo
;;

controller-deploy) #Deploy basic service. [ metallb & nginx-ingress | Detect NETID just input xxx xxx ]
  if [ -z ${2} ]
    then
      echo -e "Please input parameter.\n"
      echo -e "controller: Setup basic service. [ metallb & ingress ] [ Automatic select networkID, package <Start> <End> ]\n"

  elif [ -z ${3} ]
    then
      echo; echo -e "Please input parameter.\n"
      echo -e "controller: Setup basic service. [ metallb & ingress ] [ Automatic select networkID, package <Start> <End> ]\n"

    else
      for install_list in ${CP_NODES} ${WK_NODES}
        do
          ssh ${install_list} cat /etc/hosts | grep "${NETID}.${2}"
          [ $? != 0 ] && ssh ${install_list} "echo "${NETID}.${2} quay.k8s.org jenkins.k8s.org gf.k8s.org kg.k8s.org" | sudo tee -a /etc/hosts"
        done
      #metallb-system
      kubectl apply -f https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/metallb-namespace.yaml
      kubectl apply -f https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/metallb.yaml
      curl -s https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/metallb-ConfigMap.yaml | sed "s/NETID/${NETID}/g" | sed "s/START/${2}/g" | sed "s/END/${3}/g" | kubectl apply -f - 
      echo "metallb deployed!"

      #ingress-nginx
      kubectl apply -f https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/ingress-deploy.yaml
      echo "ingress-nginx deployed!"
      k9s -c pods -A
  fi
;;

controller-rm) #Delete basic service. [ metallb & nginx-ingress ]
  #ingress-nginx
  kubectl delete -f https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/ingress-deploy.yaml
  #metallb-system
  curl -s https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/metallb-ConfigMap.yaml | sed "s/NETID/${NETID}/g" | sed "s/START/${2}/g" | sed "s/END/${3}/g" | kubectl delete -f -
  kubectl delete -f https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/metallb.yaml
  kubectl delete -f https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/metallb-namespace.yaml
;;

metrics-deploy) #Deploy metrics-server.
  #HA Version via helm
  helm repo add metrics-server https://kubernetes-sigs.github.io/metrics-server/
  helm install metrics-server metrics-server/metrics-server --set 'args={--kubelet-insecure-tls}' --version 3.8.2 --namespace kube-system
  kubectl scale deploy/metrics-server --replicas=2 -n kube-system
;;

metrics-rm) #Delete metrics-server.
  helm delete metrics-server -n kube-system
  helm repo remove metrics-server
;;

prometheus-deploy) #Deploy prometheus.
  #追加並更新 helm repository
  helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
  helm repo update

  #部署 operator 並驗證
  helm install kube-prometheus-stack prometheus-community/kube-prometheus-stack --namespace monitoring --create-namespace
;;

prometheus-rm) #Delete prometheus.
  helm delete kube-prometheus-stack -n monitoring
  helm repo remove prometheus-community
  helm repo update
;;

jenkins-deploy) #Deploy jenkins on kubernetes.
  kubectl create ns ${NAME_SPACE_4}
  kubectl create secret generic kubeconfig --from-file=/home/bigred/.kube/config -n ${NAME_SPACE_4}
  #kubectl apply -f https://web.flymks.com/cicd/v1/jenkins.yaml
  curl -s https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/jenkins.yaml | sed 's/<image-name>/docker.io\/jenkins\/jenkins/g' | kubectl apply -f -
  k9s -c pods -n ${NAME_SPACE_4}
  kubectl get pods -n ${NAME_SPACE_4} | tail -n +2 | awk '{ print $3 }' | grep -v 'Running' &> /dev/null
  [ $? != 0 ] && echo -e "${YELLOW}Jenkins deployed!${NC}" || echo -e "${RED}Jenkins not deploy!${NC}"
;;

jenkins-rm) #Delete jenkins on kubernetes.
  kubectl delete -f https://web.flymks.com/cicd/v1/jenkins.yaml
  kubectl delete ns ${NAME_SPACE_4}
  kubectl delete secret generic kubeconfig --from-file=/home/bigred/.kube/config -n jenkins
;;

quay-deploy) #Deploy project-quay on kubernetes.
  #quay
  kubectl create ns ${NAME_SPACE_5}
  #kubectl apply -f https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/quay.yaml
  curl -s https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/quay.yaml | sed "s/<storageclass>/${STORAGE_CLASS}/g" | kubectl apply -f -
  k9s -c pods -n ${NAME_SPACE_5}
  kubectl get pods -n ${NAME_SPACE_5} | tail -n +2 | awk '{ print $3 }' | grep -v 'Running' &> /dev/null
  [ $? != 0 ] && echo -e "${YELLOW}Project Quay deployed!${NC}" || echo -e "${RED}Project Quay not deploy!${NC}"
;;

quay-rm) #Delete project-quay on kubernetes.
  kubectl delete -f https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/quay.yaml
  kubectl delete ns ${NAME_SPACE_5}
;;

grafana-deploy) #Deploy grafana on kubernetes.
  #gf
  kubectl create ns ${NAME_SPACE_6}
  #kubectl apply -f https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/grafana.yaml
  curl -s https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/grafana.yaml | sed "s/<storageclass>/${STORAGE_CLASS}/g" | kubectl apply -f -
  k9s -c pods -n ${NAME_SPACE_6}
  kubectl get pods -n ${NAME_SPACE_6} | tail -n +2 | awk '{ print $3 }' | grep -v 'Running' &> /dev/null
  [ $? != 0 ] && echo -e "${YELLOW}Grafana deployed!${NC}" || echo -e "${RED}Grafana not deploy!${NC}"
;;

grafana-rm) #Delete grafana on kubernetes.
  #grafana
  kubectl delete -f https://web.flymks.com/grafana/v1/grafana.yaml
  kubectl delete ns ${NAME_SPACE_6}
;;

landlord-deploy) #Deploy landlord on kubernetes.
  #ns & configmap
  kubectl create ns landlord
  kubectl create -n landlord configmap kuser-conf --from-file /home/bigred/.kube/config

  #PVC
  curl -s https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/Landlord/2-landlord-PVC.yaml | sed "s/<storageclass>/${STORAGE_CLASS}/g" | kubectl apply -f -
  echo "landlord PVC deployed!"; echo

  #service
  curl -s https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/Landlord/1-landlord-service.yaml | kubectl apply -f -
  k9s -c svc -n ${NAME_SPACE_7}
  kubectl get svc -n ${NAME_SPACE_7} | tail -n +2 | tr -s ' ' | cut -d ' ' -f 2 | grep -vE 'LoadBalancer|ClusterIP' &> /dev/null

  #gateway
  curl -s https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/Landlord/3-landlord-gateway.yaml | kubectl apply -f -
  k9s -c pods -n ${NAME_SPACE_7}
  kubectl get pods -n ${NAME_SPACE_7} | tail -n +2 | awk '{ print $3 }' | grep -v 'Running' &> /dev/null
  [ $? != 0 ] && echo -e "${YELLOW}gateway deployed!${NC}" || echo -e "${RED}gateway not deploy!${NC}"

  #kuser
  curl -s https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/Landlord/4-landlord-kuser.yaml | kubectl apply -f -
  k9s -c pods -n ${NAME_SPACE_7}
  kubectl get pods -n ${NAME_SPACE_7} | tail -n +2 | awk '{ print $3 }' | grep -v 'Running' &> /dev/null
  [ $? != 0 ] && echo -e "${YELLOW}kuser deployed!${NC}" || echo -e "${RED}kuser not deploy!${NC}"

  #logger
  curl -s https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/Landlord/5-landlord-logger.yaml | kubectl apply -f -
  k9s -c pods -n ${NAME_SPACE_7}
  kubectl get pods -n ${NAME_SPACE_7} | tail -n +2 | awk '{ print $3 }' | grep -v 'Running' &> /dev/null
  [ $? != 0 ] && echo -e "${YELLOW}logger deployed!${NC}" || echo -e "${RED}logger not deploy!${NC}"

  #mariadb
  curl -s https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/Landlord/6-landlord-mariadb.yaml | kubectl apply -f -
  k9s -c pods -n ${NAME_SPACE_7}
  kubectl get pods -n ${NAME_SPACE_7} | tail -n +2 | awk '{ print $3 }' | grep -v 'Running' &> /dev/null
  [ $? != 0 ] && echo -e "${YELLOW}mariadb deployed!${NC}" || echo -e "${RED}mariadb not deploy!${NC}"

  #tenant
  curl -s https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/Landlord/7-landlord-tenant.yaml | sed "s/<storageclass>/${STORAGE_CLASS}/g" | kubectl apply -f -
  k9s -c pods -n ${NAME_SPACE_7}
  kubectl get pods -n ${NAME_SPACE_7} | tail -n +2 | awk '{ print $3 }' | grep -v 'Running' &> /dev/null
  [ $? != 0 ] && echo -e "${YELLOW}tenant deployed!${NC}" || echo -e "${RED}tenant not deploy!${NC}"
;;

landlord-rm) #Delete landlorsd on kubernetes.
  #tenant
  curl -s https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/Landlord/7-landlord-tenant.yaml | sed "s/<storageclass>/${STORAGE_CLASS}/g" | kubectl delete -f -
  #mariadb
  curl -s https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/Landlord/6-landlord-mariadb.yaml | kubectl delete -f -
  #logger
  curl -s https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/Landlord/5-landlord-logger.yaml | kubectl delete -f -
  #kuser
  curl -s https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/Landlord/4-landlord-kuser.yaml | kubectl delete -f -
  #gateway
  curl -s https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/Landlord/3-landlord-gateway.yaml | kubectl delete -f -
  #PVC
  curl -s https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/Landlord/2-landlord-PVC.yaml | sed "s/<storageclass>/${STORAGE_CLASS}/g" | kubectl delete -f -
  #service
  curl -s https://raw.githubusercontent.com/Bookman-W/Kubernetes-yaml/main/Landlord/1-landlord-service.yaml | kubectl delete -f -
  #configmap & namespace
  kubectl delete -n ${NAME_SPACE_7} configmap kuser-conf
  kubectl delete ns ${NAME_SPACE_7}
;;

nodes) #Check all nodes status.
  nc -z -w 1 ${IP} 10250 > /dev/null 2>&1
  [ $? == 0 ] && k9s -c nodes || echo -e " [${YELLOW}●${NC}] This node not activate."
;;

pods) #Check all pods status.
  nc -z -w 1 ${IP} 10250 > /dev/null 2>&1
  [ $? == 0 ] && k9s -c pods -A || echo -e " [${YELLOW}●${NC}] This node not activate."
;;

images) #Check cluster images.
  [ -z ${2} ] && node-message ${@} && exit
  node-selector ${@}
  for install_list in ${cp_nodes} ${wk_nodes}
    do
      echo -en "${YELLOW}${install_list} | images list${NC} | quantity: "
      ssh ${install_list} sudo podman images | grep -v 'REPOSITORY' | wc -l
      ssh ${install_list} 'sudo podman images'
      echo
    done
;;

image-send) #save >> scp >> load target image to every worker node [ <image-name> <name.tar> ]
  image=$(echo ${2} | cut -d ":" -f 1)
  sudo podman images | grep "${image}"
  [ $? != 0 ] && sudo podman pull ${2} || echo "Image is already exists."
  sudo podman save ${2} > ~/${3} 2> /dev/null
  for install_list in ${ALL_NODES_EX_LOCALHOST}
    do
      scp ~/${3} ${install_list}:
      ssh ${install_list} "sudo podman rmi ${2} 2> /dev/null"
      ssh ${install_list} "sudo podman load < ~/${3} 2> /dev/null"
      ssh ${install_list} "rm ~/${3}"
    done
  rm ./${3}
;;

image-rm) #Remove dangling images on cluster.
  [ -z ${2} ] && node-message ${@} && exit
  node-selector ${@}
  message="${RED}Please confirm this command will delete unuse images on node:${YELLOW} ${cp_nodes} ${wk_nodes}${RED}!${NC}"
  interrupt ${message}
  for install_list in ${cp_nodes} ${wk_nodes}
    do
      ssh ${install_list} 'sudo podman image prune -f'
      ssh ${install_list} 'sudo podman rmi -a &> /dev/null'
      echo -en "${YELLOW}${install_list} | in-use images list${NC} | quantity: "
      ssh ${install_list} sudo podman images | grep -v 'REPOSITORY' | wc -l
      ssh ${install_list} 'sudo podman images'
      echo
    done
;;

helm-repo) #Check helm repository.
  [ -z ${2} ] && echo -e "${RED}Please input parameter after ${YELLOW}\"helm-repo\" \n > [ update | check ]${NC}\n" && exit
  node-selector hosts
  [ "${2}" == "update" ] && helm-repo-update
  [ "${2}" == "check" ] && helm-repo-check
  [ "${2}" == "add" ] && helm-repo-add
;;

cluster-info) #Check kubernetes cluster info.
  if [ "${2}" == "cidr" ]
    then
      check-cidr
  elif [ "${2}" == "taints" ]
    then
      check-tains
  elif [ "${2}" == "etcd" ]
    then
      check-etcd-member
  elif [ "${2}" == "all" ]
    then
      kubectl get node > /dev/null 2>&1
      [ $? != 0 ] && echo -e "[${RED}●${NC}] This node not join cluster" && exit
      check-cidr
      check-tains
      check-etcd-member
    else
      echo -e "${RED}Please input parameter after \"taints\" \n ${YELLOW}> [ cidr | taints | etcd | all ]${NC}"
  fi
  echo
;;

cluster-upgrade) #Upgrade cluster [ upgrade kubeadm、kubectl、kubelet、crio ]
  [ -z ${2} ] && node-selector hosts || node-selector ${@}

  #Exclude non-join nodes
  exclude-non-join

  message="${RED}Please confirm this command will upgrade nodes to ${KUBE_INIT_VER}: ${YELLOW}${cp_nodes} ${wk_nodes}!${NC}"
  interrupt ${message}

  first_control_plane=`hostname`
  other_control_plane=$(echo "${cp_nodes} ${wk_nodes}" | tr -s ' ' '\n' | sed "/`hostname`/d" | grep '\-m' | tr -s '\n' ' ')
  export CURRENT_VER=$(kubectl get nodes | grep `hostname` | awk '{ print $ 5}')

  for checklist in ${first_control_plane} ${other_control_plane} ${wk_nodes}
    do
      CHECK_VER=$(kubectl get nodes | grep ${checklist} | awk '{ print $ 5}')
      echo "${CHECK_VER}" | grep ${KUBE_INIT_VER} &> /dev/null
      [ $? == 0 ] && status=0 || status=1
      [ "${status}" == "0" ] && echo -e "${YELLOW}${checklist} version is already been ${RED}${KUBE_INIT_VER}${NC}"
      [ "${status}" == "1" ] && echo -e "${GREEN}${checklist} Upgrade version checked: ${RED}${CHECK_VER} >> ${KUBE_INIT_VER}${NC}"
    done
  [ "${status}" == "0" ] && echo && exit

  #[ -z ${2} ] && kdm pkg-repo add hosts || kdm pkg-repo add ${cp_nodes} ${wk_nodes}
  kdm pkg-repo add ${cp_nodes} ${wk_nodes}
  os-detection

  message="${RED}Start upgrade procedure?${NC}"
  interrupt ${message}

  for FCP in ${first_control_plane}
    do
      if [ "${KUBE_INIT_VER}" == "${CURRENT_VER}" ]
        then
          echo -e "${YELLOW}Cluster upgrade procedure${NC}"
          echo ${cp_nodes} ${wk_nodes} | grep `hostname` &> /dev/null
          [ $? == 0 ] && echo -e "${YELLOW} - ${first_control_plane} version is already been ${RED}${KUBE_INIT_VER}${NC}"
          continue
      fi
      echo -e "${YELLOW}${FCP} | upgrade procedure${NC}"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${FCP} "sudo dnf versionlock delete kubeadm"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${FCP} "sudo dnf install -y kubeadm-${KUBE_SUBVER} --disableexcludes=kubernetes" 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${FCP} "sudo dnf versionlock add kubeadm"

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${FCP} "sudo dnf versionlock delete kubeadm"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${FCP} "sudo dnf install -y kubeadm-${KUBE_SUBVER} --disableexcludes=kubernetes" 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${FCP} "sudo dnf versionlock add kubeadm"

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${FCP} "sudo apt-mark unhold kubeadm"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${FCP} "sudo apt-get install -qy kubeadm=${KUBE_SUBVER}-*"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${FCP} "sudo apt-mark hold kubeadm"

      ssh ${FCP} "sudo kubeadm upgrade plan ${KUBE_INIT_VER}"
      ssh ${FCP} "sudo kubeadm upgrade apply --force ${KUBE_INIT_VER}" #sudo kubeadm upgrade node

      kubectl drain ${FCP} --ignore-daemonsets

      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${FCP} "sudo dnf versionlock delete kubelet kubectl"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${FCP} "sudo dnf install -y kubelet-${KUBE_SUBVER} kubectl-${KUBE_SUBVER} --disableexcludes=kubernetes" 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${FCP} "sudo dnf versionlock add kubelet kubectl"

    status=0
    CRI_PROVIDES=$(sudo dnf provides cri-o 2> /dev/null | grep 'Provide' | head -n 5 | cut -d '=' -f 2 | grep ${CRI_RELEASE} | head -n 1)

      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${FCP} "sudo dnf versionlock delete cri-o"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && [ "${VER_SWITCH}" == "sub" ] && ssh ${FCP} "sudo dnf install -y cri-o-${CRI_SUBVER}-* crun" > /dev/null 2>&1 && status=1
      [ "${status}" == "0" ] && ssh ${FCP} "sudo dnf install -y cri-o-${CRI_PROVIDES} crun" > /dev/null 2>&1 && status=1
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && [ "${VER_SWITCH}" == "latest" ] && ssh ${FCP} "sudo dnf install -y cri-o-${CRI_RELEASE}.* crun" > /dev/null 2>&1
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${FCP} "sudo dnf versionlock add cri-o"

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${FCP} "sudo dnf versionlock delete kubelet kubectl"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${FCP} "sudo dnf install -y kubelet-${KUBE_SUBVER} kubectl-${KUBE_SUBVER} --disableexcludes=kubernetes" 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${FCP} "sudo dnf versionlock add kubelet kubectl"

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${FCP} "sudo dnf versionlock delete cri-o"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && [ "${VER_SWITCH}" == "sub" ] && ssh ${FCP} "sudo dnf install -y cri-o-${CRI_SUBVER}-* crun" > /dev/null 2>&1 && status=1
      [ "${status}" == "0" ] && ssh ${FCP} "sudo dnf install -y cri-o-${CRI_PROVIDES} crun" > /dev/null 2>&1 && status=1
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && [ "${VER_SWITCH}" == "latest" ] && ssh ${FCP} "sudo dnf install -y cri-o-${CRI_RELEASE}.* crun" > /dev/null 2>&1
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${FCP} "sudo dnf versionlock add cri-o"

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${FCP} "sudo apt-mark unhold kubelet kubectl"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${FCP} "sudo apt-get install -qy -o Dpkg::Options::="--force-confold" kubelet=${KUBE_SUBVER}-* kubectl=${KUBE_SUBVER}-*"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${FCP} "sudo apt-mark hold kubelet kubectl"

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${FCP} "sudo apt-mark unhold cri-o"&> /dev/null
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${FCP} "sudo apt-get install -qy -o Dpkg::Options::="--force-confold" cri-o=${CRI_SUBVER}~*" &> /dev/null && status=1
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${FCP} "sudo apt-mark hold" &> /dev/null

      ssh ${FCP} "sudo systemctl daemon-reload"
      ssh ${FCP} "sudo systemctl restart --now crio"
      ssh ${FCP} "sudo systemctl restart --now kubelet"
      
      kubectl uncordon ${FCP}
    done

  for OCP in ${other_control_plane}
    do
      OCP_VER=$(kubectl get nodes | grep "${OCP}" | awk '{ print $ 5}')
      if [ "${KUBE_INIT_VER}" == "${OCP_VER}" ]
        then
          echo -e "${YELLOW} - ${OCP} version is already been ${RED}${KUBE_INIT_VER}${NC}"
          continue
      fi
      echo -e "${YELLOW}${OCP} | upgrade procedure${NC}"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${OCP} "sudo dnf versionlock delete kubeadm"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${OCP} "sudo dnf install -y kubeadm-${KUBE_SUBVER} --disableexcludes=kubernetes" 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${OCP} "sudo dnf versionlock add kubeadm"

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${OCP} "sudo dnf versionlock delete kubeadm"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${OCP} "sudo dnf install -y kubeadm-${KUBE_SUBVER} --disableexcludes=kubernetes" 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${OCP} "sudo dnf versionlock add kubeadm"

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${OCP} "sudo apt-get update"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${OCP} "sudo apt-mark unhold kubeadm"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${OCP} "sudo apt-get install -qy kubeadm=${KUBE_SUBVER}-*"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${OCP} "sudo apt-mark hold kubeadm"

      ssh ${OCP} "sudo kubeadm upgrade plan ${KUBE_INIT_VER}"
      ssh ${OCP} "sudo kubeadm upgrade node"

      kubectl drain ${OCP} --ignore-daemonsets

      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${OCP} "sudo dnf versionlock delete kubelet kubectl"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${OCP} "sudo dnf install -y kubelet-${KUBE_SUBVER} kubectl-${KUBE_SUBVER} --disableexcludes=kubernetes" 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${OCP} "sudo dnf versionlock add kubelet kubectl"
      
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${OCP} "sudo dnf versionlock delete cri-o"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && [ "${VER_SWITCH}" == "sub" ] && ssh ${OCP} "sudo dnf install -y cri-o-${CRI_SUBVER}-* crun" > /dev/null 2>&1 && status=1
      [ "${status}" == "0" ] && ssh ${OCP} "sudo dnf install -y cri-o-${CRI_PROVIDES} crun" > /dev/null 2>&1 && status=1
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && [ "${VER_SWITCH}" == "latest" ] && ssh ${OCP} "sudo dnf install -y cri-o-${CRI_RELEASE}.* crun" > /dev/null 2>&1
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${OCP} "sudo dnf versionlock add cri-o"

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${OCP} "sudo dnf versionlock delete kubelet kubectl"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${OCP} "sudo dnf install -y kubelet-${KUBE_SUBVER} kubectl-${KUBE_SUBVER} --disableexcludes=kubernetes" 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${OCP} "sudo dnf versionlock add kubelet kubectl"
      
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${OCP} "sudo dnf versionlock delete cri-o"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && [ "${VER_SWITCH}" == "sub" ] && ssh ${OCP} "sudo dnf install -y cri-o-${CRI_SUBVER}-* crun" > /dev/null 2>&1 && status=1
      [ "${status}" == "0" ] && ssh ${OCP} "sudo dnf install -y cri-o-${CRI_PROVIDES} crun" > /dev/null 2>&1 && status=1
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && [ "${VER_SWITCH}" == "latest" ] && ssh ${OCP} "sudo dnf install -y cri-o-${CRI_RELEASE}.* crun" > /dev/null 2>&1
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${OCP} "sudo dnf versionlock add cri-o"

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${OCP} "sudo apt-mark unhold kubelet kubectl"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${OCP} "sudo apt-get install -qy -o Dpkg::Options::="--force-confold" kubelet=${KUBE_SUBVER}-* kubectl=${KUBE_SUBVER}-*"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${OCP} "sudo apt-mark hold kubelet kubectl"

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${OCP} "sudo apt-mark unhold cri-o"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${OCP} "sudo apt-get install -qy -o Dpkg::Options::="--force-confold" cri-o=${CRI_SUBVER}~*"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${OCP} "sudo apt-mark hold cri-o"

      ssh ${OCP} "sudo systemctl daemon-reload"
      ssh ${OCP} "sudo systemctl restart --now crio"
      ssh ${OCP} "sudo systemctl restart --now kubelet"
      
      kubectl uncordon ${OCP}
    done

  for wlist in ${wk_nodes}
    do
      WORKER_VER=$(kubectl get nodes | grep "${wlist}" | awk '{ print $ 5}')
      if [ "${KUBE_INIT_VER}" == "${WORKER_VER}" ]
        then
          echo -e "${YELLOW} - ${wlist} version is already been ${RED}${KUBE_INIT_VER}${NC}"
          continue
      fi
      echo -e "${YELLOW}${wlist} | upgrade procedure${NC}"

      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf versionlock delete kubeadm"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf install -y kubeadm-${KUBE_SUBVER} --disableexcludes=kubernetes" 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf versionlock add kubeadm"

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf versionlock delete kubeadm"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf install -y kubeadm-${KUBE_SUBVER} --disableexcludes=kubernetes" 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf versionlock add kubeadm"

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-get update"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-mark unhold kubeadm"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-get install -qy kubeadm=${KUBE_SUBVER}-*"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-mark hold kubeadm"
      ssh ${wlist} "sudo kubeadm upgrade node"

      kubectl drain ${wlist} --ignore-daemonsets

      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf versionlock delete kubelet kubectl"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf install -y kubelet-${KUBE_SUBVER} kubectl-${KUBE_SUBVER} --disableexcludes=kubernetes" 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf versionlock add kubelet kubectl"

      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf versionlock delete cri-o"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && [ "${VER_SWITCH}" == "sub" ] && ssh ${wlist} "sudo dnf install -y cri-o-${CRI_SUBVER}-* crun" > /dev/null 2>&1 && status=1
      [ "${status}" == "0" ] && ssh ${wlist} "sudo dnf install -y cri-o-${CRI_PROVIDES} crun" > /dev/null 2>&1 && status=1
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && [ "${VER_SWITCH}" == "latest" ] && ssh ${wlist} "sudo dnf install -y cri-o-${CRI_RELEASE}.* crun" > /dev/null 2>&1
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf versionlock add cri-o"

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf versionlock delete kubelet kubectl"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf install -y kubelet-${KUBE_SUBVER} kubectl-${KUBE_SUBVER} --disableexcludes=kubernetes" 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf versionlock add kubelet kubectl"
      
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf versionlock delete cri-o"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && [ "${VER_SWITCH}" == "sub" ] && ssh ${wlist} "sudo dnf install -y cri-o-${CRI_SUBVER}-* crun" > /dev/null 2>&1 && status=1
      [ "${status}" == "0" ] && ssh ${wlist} "sudo dnf install -y cri-o-${CRI_PROVIDES} crun" > /dev/null 2>&1 && status=1
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && [ "${VER_SWITCH}" == "latest" ] && ssh ${wlist} "sudo dnf install -y cri-o-${CRI_RELEASE}.* crun" > /dev/null 2>&1
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf versionlock add cri-o"

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-mark unhold kubelet kubectl"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-get install -qy -o Dpkg::Options::="--force-confold" kubelet=${KUBE_SUBVER}-* kubectl=${KUBE_SUBVER}-*"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-mark hold kubelet kubectl"

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-mark unhold cri-o"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-get install -qy -o Dpkg::Options::="--force-confold" cri-o=${CRI_SUBVER}~*"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-mark hold cri-o"

      ssh ${wlist} "sudo systemctl daemon-reload"
      ssh ${wlist} "sudo systemctl restart --now crio"
      ssh ${wlist} "sudo systemctl restart --now kubelet"

      kubectl uncordon ${wlist}
    done; echo
    kubectl get nodes | tail -n +2 | awk '{ print $5 }' | grep ${KUBE_INIT_VER} &> /dev/null
    [ $? == 0 ] && echo -e "${YELLOW}Cluster has been upgraded to ${RED}${KUBE_INIT_VER}${NC}\n" || echo -e "${RED}Cluster has not upgrade to ${RED}${KUBE_INIT_VER}${NC}\n"
;;

cluster-reset) #Reset kubernetes cluster.
  node-selector hosts
  kubectl get storageclass -A 2> /dev/null | grep 'rook-ceph' &> /dev/null
  [ $? == 0 ] && rook_detection=1

  start-info; echo
  echo -en "${YELLOW}StorageClass: ${NC}"
  kubectl get storageclass -A 2> /dev/null | grep -E 'rook-ceph|local-path' | awk '{ print $1 }' | sed ":a;N;s/\n/\ | /g"
  echo
  message="${RED}Please confirm this command will destruction cluster!${NC}"
  interrupt ${message}

  echo -n "As you wish"; echo -n "."; sleep 0.5; echo -n "."; sleep 0.5; echo "."; sleep 0.5
  #helm calico network
  status=0
  kubectl get nodes 2> /dev/null
  [ $? == 0 ] && status=1
  [ "${status}" == "1" ] && helm delete calico -n tigera-operator
  [ "${status}" == "1" ] && kubectl delete namespace tigera-operator
  [ "${status}" == "1" ] && helm repo remove projectcalico
  #helm metrics
  [ "${status}" == "1" ] && helm delete metrics-server -n kube-system
  [ "${status}" == "1" ] && helm repo remove metrics-server
  #delete all
  [ "${status}" == "1" ] && kubectl delete all --all --all-namespaces
  [ "${status}" == "1" ] && kubectl delete --all namespaces

  for wclist in ${wk_nodes} ${cp_nodes}
    do
      echo; echo -e "${YELLOW}${wclist} | delete process${NC}"
      ssh ${wclist} 'sudo kubeadm reset -f 2> /dev/null'
      dir-delete-list
      ssh ${wclist} "sudo systemctl restart --now crio"
      ssh ${wclist} "sudo systemctl restart --now kubelet"
      nc -z -w 1 ${IP} 10250 > /dev/null 2>&1
      [ $? == 0 ] && kubectl delete node ${wclist}
    done
  [ "${rook_detection}" == "1" ] && kdm csi-rook wipe-data hosts ${CEPH_DISK}
  [ "${rook_detection}" == "1" ] && kdm csi-rook clean-data
  echo -en "${NC}"
;;

cri-upgrade) #Update crio package.
  node-selector ${@}
  message="${RED}Please confirm this command will let${YELLOW} ${cp_nodes} ${wk_nodes} ${RED}cri-o upgrade!${NC}"
  interrupt ${message}

  for install_list in ${cp_nodes} ${wk_nodes}
  do
    kubectl drain ${install_list} --ignore-daemonsets 2> /dev/null
    #install & setup cri-o
    echo -e "\n${YELLOW}${install_list} | package upgrade procedure${NC}"
    #Add crio、kubernetes package repositories
    pkg-repo-add

    status=0
    CRI_PROVIDES=$(sudo dnf provides cri-o 2> /dev/null | grep 'Provide' | head -n 5 | cut -d '=' -f 2 | grep ${CRI_RELEASE} | head -n 1)

    [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo dnf versionlock delete cri-o" &> /dev/null
    [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && [ "${VER_SWITCH}" == "sub" ] && ssh ${install_list} "sudo dnf install -y cri-o-${CRI_SUBVER}-* crun" > /dev/null 2>&1 && status=1
    [ "${status}" == "0" ] && ssh ${install_list} "sudo dnf install -y cri-o-${CRI_PROVIDES} crun" > /dev/null 2>&1 && status=1
    [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && [ "${VER_SWITCH}" == "latest" ] && ssh ${install_list} "sudo dnf install -y cri-o-${CRI_RELEASE}.* crun" > /dev/null 2>&1
    [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${install_list} "sudo dnf versionlock add cri-o" &> /dev/null

    [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo dnf versionlock delete cri-o" &> /dev/null
    [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && [ "${VER_SWITCH}" == "sub" ] && ssh ${install_list} "sudo dnf install -y cri-o-${CRI_SUBVER}-* crun" > /dev/null 2>&1 && status=1
    [ "${status}" == "0" ] && ssh ${install_list} "sudo dnf install -y cri-o-${CRI_PROVIDES} crun" > /dev/null 2>&1 && status=1
    [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && [ "${VER_SWITCH}" == "latest" ] && ssh ${install_list} "sudo dnf install -y cri-o-${CRI_RELEASE}.* crun" > /dev/null 2>&1
    [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${install_list} "sudo dnf versionlock add cri-o" &> /dev/null
    
    [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo apt-mark unhold cri-o" &> /dev/null
    [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo apt-get install -qy -o Dpkg::Options::="--force-confold" cri-o=${CRI_SUBVER}~*" &> /dev/null && status=1
    [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${install_list} "sudo apt-mark hold" &> /dev/null

    echo "`crio-install-check ${install_list}`"
    ssh ${install_list} "sudo systemctl daemon-reload" && echo
    kubectl uncordon ${install_list}
  done
;;

cri-check) #Check CRI running pods.
  [ -z ${2} ] && node-message ${@} && exit
  node-selector ${@}
  for install_list in ${cp_nodes} ${wk_nodes}
    do
      echo -e "${YELLOW}${install_list} | check list${NC}"
      ssh ${install_list} "sudo crictl ps -a"; echo
    done
;;

cri-clean) #Remove CRI running pods.
  [ -z ${2} ] && node-message ${@} && exit
  node-selector ${@}
  message="${RED}Please confirm this command will delete all container via crio on node:${YELLOW} ${cp_nodes} ${wk_nodes}${NC}"
  interrupt ${message}
  for install_list in ${cp_nodes} ${wk_nodes}
    do
      echo "${install_list} | check list"
      cri_list=$(ssh ${install_list} sudo crictl ps -a | tail -n +2 | awk '{ print $9 }' | tr -s '\n' ' ')
      for list in ${cri_list}
        do
          ssh ${install_list} "sudo crictl stopp ${list}" &> /dev/null
          ssh ${install_list} "sudo crictl rmp ${list}" &> /dev/null
        done
      ssh ${install_list} "sudo crictl ps -a"
      echo
    done
;;

node-check) #Check nodes port | hostname. [ <hosts> | <hosts> <name> | <hosts> <port> | <NETID> <Start> <End> <Port> ]
  while [ 1 ]
    do
      clear
      node-check $@ && sleep 3
    done
;;

node-reset) #Reset hosts | specify nodes. [ node-reset <node> ]
  [ -z ${2} ] && node-message ${@} && exit
  node-selector ${@}
  message="${RED}Please confirm this command will destruction node:${YELLOW} ${cp_nodes} ${wk_nodes}${RED}!${NC}"
  interrupt ${message}

  echo -n "As you wish"; echo -n "."; sleep 0.5; echo -n "."; sleep 0.5; echo "."; sleep 0.5

  for clist in ${cp_nodes}
    do
      status=0
      etcd_pod=$(kubectl get pods -n kube-system 2> /dev/null | grep 'etcd' | awk '{ print $1 }' | head -n 1)
      etcd_endpoints=$(echo ${etcd_pod} | cut -d '-' -f 2)
      echo -e "${YELLOW}${clist} | delete process${NC}"
      kubectl get nodes 2> /dev/null | grep "${clist}" &> /dev/null
      [ $? == 0 ] && kubectl delete node ${clist} && status=1
      [ "${status}" == "1" ] && remove_id=$(kubectl exec -it ${etcd_pod} -n kube-system -- etcdctl --endpoints ${NETID}.${etcd_endpoints}:2379 --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key --cacert=/etc/kubernetes/pki/etcd/ca.crt member list | grep "${clist}" | cut -d ',' -f 1 2> /dev/null)
      [ "${status}" == "1" ] && kubectl exec -it ${etcd_pod} -n kube-system -- etcdctl --endpoints ${NETID}.${etcd_endpoints}:2379 --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key --cacert=/etc/kubernetes/pki/etcd/ca.crt member remove ${remove_id} 2> /dev/null
      ssh ${clist} 'sudo kubeadm reset -f'
      dir-delete-list

      ssh ${clist} "sudo systemctl enable --now crio"
      ssh ${clist} "sudo systemctl enable --now kubelet"
    done; echo

  for wlist in ${wk_nodes}
    do
      status=0
      echo -e "${YELLOW}${wlist} | delete process${NC}"
      kubectl get nodes | grep "${wlist}" &> /dev/null
      [ $? == 0 ] && kubectl delete node ${wlist} && status=1
      ssh ${wlist} 'sudo kubeadm reset -f'
      dir-delete-list

      ssh ${wlist} "sudo systemctl enable --now crio"
      ssh ${wlist} "sudo systemctl enable --now kubelet"
    done; echo

  node-power reboot ${@}
;;

node-power) #Reboot/Poweroff hosts | specify node. [ <node> ]
  node-power ${@}
;;
deploy) #Automatic deploy kubernetes cluster. [ kdm deploy calico/flannel hosts 160 169 local-path/rook-ceph ]
  #kdm deploy calico hosts 180 189 rook-ceph
  kdm cp-init ${2}
  kdm cp-join ${3}
  kdm wk-join ${3}
  kdm dns-rollout
  kdm controller-deploy ${4} ${5}
  kdm metrics-deploy
  kdm csi-deploy ${6}
;;

help) #Show script parameters information.
  ls ~/kdm/kdm &> /dev/null
  [ $? == 0 ] && stage=0
  ls ~/bin/kdm &> /dev/null
  [ $? == 0 ] && stage=1
  [ ${stage} == 0 ] && path="kdm/kdm"
  [ ${stage} == 1 ] && path="bin/kdm"

  list=" > sys-| > set-| > sync-| > pkg-| > k9s-"
  number=$(cat ~/${path} | grep "[a-z])" | sed '/\$/d;/echo/d' | sed 's/)/:/g' | sed 's/^/ > /' | sed 's/#//g' | grep -E "${list}" | wc -l)
  echo -e "${RED}sys-setup | ${number}${NC}"
  
  echo -en "${YELLOW}"
  cat ~/${path} | grep "[a-z])" | sed '/\$/d;/echo/d' | sed 's/)/:/g' | sed 's/^/ > /' | sed 's/#//g' | grep -E "${list}"; echo
  echo -en "${NC}"

  list=" > cp-| > wk-| > cni-| > csi-| > dns-"
  number=$(cat ~/${path} | grep "[a-z])" | sed '/\$/d;/echo/d' | sed 's/)/:/g' | sed 's/^/ > /' | sed 's/#//g' | grep -E "${list}" | wc -l)
  echo -e "${RED}Kubernetes-deploy | ${number}${NC}"
  echo "  └─cp-init >> cp-join >> wk-join >> dns-rollout >> controller-deploy >> metrics-deploy >> csi-deploy"
  
  echo -en "${YELLOW}"
  cat ~/${path} | grep "[a-z])" | sed '/\$/d;/echo/d' | sed 's/)/:/g' | sed 's/^/ > /' | sed 's/#//g' | grep -E "${list}"; echo
  echo -en "${NC}"

  list=" > nodes:| > node-| > pods:| > images:| > image-| > helm-| > cluster-| > cri-| > help:"
  number=$(cat ~/${path} | grep "[a-z])" | sed '/\$/d;/echo/d' | sed 's/)/:/g' | sed 's/^/ > /' | sed 's/#//g' | grep -E "${list}" | wc -l)
  echo -e "${RED}Kubernetes-functions | $((${number}+2))${NC}"
  service_list=$(cat ~/${path} | grep "[a-z])" | sed '/\$/d;/echo/d' | sed 's/)//g' | grep '\-deploy' | grep -vE 'cni|csi' | sed 's/-deploy//g' | tr -s '#' '\n' | grep -v '^D' | sed ":a;N;s/\n/| /g;ta")
  echo -en "${YELLOW}"
  echo -e " > <project-name>-deploy: Deploy Kubenetes projects.\n  ${NC}└─ [ ${service_list} ]${YELLOW}"
  echo -e " > <project-name>-rm: Delete Kubenetes projects.\n  ${NC}└─ [ ${service_list} ]${YELLOW}"
  
  cat ~/${path} | grep "[a-z])" | sed '/\$/d;/echo/d' | sed 's/)/:/g' | sed 's/^/ > /' | sed 's/#//g' | grep -E "${list}"; echo
  echo -en "${NC}"
;;

parm-check) #List all script parameter.
  ls ~/kdm/kdm &> /dev/null
  [ $? == 0 ] && stage=0
  ls ~/bin/kdm &> /dev/null
  [ $? == 0 ] && stage=1
  [ ${stage} == 0 ] && path="kdm/kdm"
  [ ${stage} == 1 ] && path="bin/kdm"
  echo -e "${YELLOW}Parameters check list${NC}"
  cat ${path} | grep "[a-z])" | sed '/\$/d;/echo/d' | sed 's/)/:/g' | sed 's/^/ > /' | sed 's/#//g'; echo
;;

code)
  node-selector ${@}
  shift && shift
  for install_list in ${cp_nodes} ${wk_nodes}
    do
      echo -e "${YELLOW}${install_list} | Result${NC}"
      ssh -o ConnectTimeout=1 -o BatchMode=yes ${install_list} 'hostname' &> /dev/null
      [ $? != 0 ] && echo -e "${RED}This node not activate${NC}"
      ssh -o ConnectTimeout=1 ${install_list} "${@}" 2> /dev/null
      [ $? != 0 ] && echo -e "${RED}Failed${NC}"
      echo
    done
;;

eck-setup)
  node-selector hosts
  for setup_list in ${cp_nodes} ${wk_nodes}
    do
      echo -e "${YELLOW}${setup_list} | ECK setup procedure${NC}"
      ssh ${setup_list} "cat /etc/sysctl.conf | grep 'vm.max_map_count=262144'" &> /dev/null
      [ $? != 0 ] && ssh ${setup_list} "echo "vm.max_map_count=262144" | sudo tee -a /etc/sysctl.conf &> /dev/null" && echo "vm.max_map_count is setup." || echo "Already setup."
      ssh ${setup_list} "sudo sysctl --system | grep 'vm.max_map_count = 262144'" &> /dev/null
      [ $? == 0 ] && echo "vm.max_map_count is active." || echo "vm.max_map_count is deactivate."
      echo
    done
;;

eck-rm)
node-selector hosts
  for setup_list in ${cp_nodes} ${wk_nodes}
    do
      echo -e "${YELLOW}${setup_list} | ECK remove procedure${NC}"
      ssh ${setup_list} "sudo sed -i '/vm.max_map_count=262144/d' /etc/sysctl.conf" &> /dev/null && echo "Setting remove compelet."
      ssh ${setup_list} "sudo sysctl --system | grep 'vm.max_map_count = 262144'" &> /dev/null
      [ $? != 0 ] && echo "vm.max_map_count is deactivate." || echo "vm.max_map_count is activate."
      echo
    done
;;

test)
  echo "testing"
;;

"")
  start-info
  echo
;;

*)
  echo -e "${YELLOW} \"${@}\" ${NC}is not effective parameter!"
  echo -e "${RED} Input parameter \"help\" display more information${NC}"
  echo
;;

esac