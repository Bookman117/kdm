#!/bin/bash
#Purpose: Deploy kubernetes on ubuntu server 20.04/22.04 LTS & Rocky Linux 8/9 & RHEL 8/9.
#Create-Date: 2022-08-10
# ---

# Environment presetting
function os-detection() {
  export OS_VERSION=$(cat /etc/os-release | grep 'PRETTY_NAME' | cut -d '"' -f 2)
  echo ${OS_VERSION} | grep "Rocky" &> /dev/null && status=1
  echo ${OS_VERSION} | grep "Ubuntu" &> /dev/null && status=2
  echo ${OS_VERSION} | grep "Red Hat Enterprise Linux" &> /dev/null && status=3
  if [ "${status}" == "1" ]
    then
      #Rocky 8/9 Linux
      export CRIO_OS_VERSION=CentOS_8_Stream
  elif [ "${status}" == "2" ]
    then
      #Ubuntu server
      export CRIO_OS_VERSION=xUbuntu_20.04
  elif [ "${status}" == "3" ]
    then
      export CRIO_OS_VERSION=RHEL_8
  fi
  #dnf lock os version
  #[ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "cat /etc/os-release | cut -d '"' -f 2 | sudo tee /etc/yum/vars/releasever"
}

# Setup basic network package
os-detection
install=1
[ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && which wget &> /dev/null && install=0
[ "${CRIO_OS_VERSION}" == "RHEL_8" ] && CRIO_OS_VERSION=CentOS_8_Stream && which wget &> /dev/null && install=0
[ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && [ "${install}" == "1" ] && sudo dnf update -y && sudo dnf install -y --allowerasing dnf-command\(versionlock\) jq net-tools dnsutils nc wget && clear
[ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && install=2
[ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && which route &> /dev/null && install=0
[ "${install}" == "2" ] && sudo apt-get update -qy && sudo apt-get install -qy net-tools iputils-ping dnsutils netcat && clear
os-detection
# ---

# Set variables
# Version control
export VER_SWITCH=latest
export CRI_RELEASE=1.24
export CRI_SUBVER=${CRI_RELEASE}.1
export KUBE_RELEASE=1.24
export KUBE_SUBVER=${KUBE_RELEASE}.1
export KUBE_INIT_VER=v${KUBE_SUBVER}
export ROOK_TAG=v1.10.9
export PACKAGE_LIST="cri-o kubeadm kubectl kubelet podman helm"
#disable/permissive/enforcing
export SELINUX_MODE=permissive
count=0
cat /dev/null > /tmp/buffer
while [ ${count} -le 9 ]
  do
    test="${CRI_RELEASE}.${count}"
    echo -n "${test} " >> /tmp/buffer
    count=$((${count}+1))
  done
echo "${VER_SWITCH}" | grep "latest"  &> /dev/null
[ $? == 0 ] && export CRI_ALL_VERSION=${CRI_SUBVER} || export CRI_ALL_VERSION=`cat /tmp/buffer | sed /\n/d`
# Network info
export IP=$(ip a | grep 'en' | grep 'inet' | awk '{ print $2 }' | cut -d '/' -f 1 | head -n 1)
export NETID=$(ip a | grep 'en' | grep 'inet' | awk '{ print $2 }' | cut -d '.' -f 1-3 | head -n 1)
export GATEWAY=$(route -n | tr -s " " | grep '^0.0.0.0' | cut -d " " -f 2 | grep "${NETID}")
export NETMASK=$(route -n | grep 'en' | grep -w 'U' | awk '{ print $3 }')
# Storage
export CEPH_DISK="/dev/sdb"
# Kube-VIP
export VIP_TARGET=$(($(cat /etc/hosts | grep "${NETID}" | grep '\-m1' | awk '{ print $1 }' | cut -d '.' -f 4)-1))
export KUBE_VIP="${NETID}.${VIP_TARGET}"
export KUBE_INTERFACE=$(ip a | grep -B 3 "${IP}" | grep 'ens' | head -n 1 | awk '{ print $2 }' | sed 's/://g')
echo "${OS_VERSION}" | grep 'Rocky Linux 8' &> /dev/null
[ $? == 0 ] && export NETWORK_UUID=$(cat /etc/sysconfig/network-scripts/ifcfg-${KUBE_INTERFACE} | grep 'UUID' | cut -d '=' -f 2)
# node & service
export CP_NODES=$(cat /etc/hosts | grep -vE '#|ip6' | grep "${NETID}" | awk '{ print $2 }' | grep "\-m" | tr -s '\n' ' ')
export WK_NODES=$(cat /etc/hosts | grep -vE '#|ip6' | grep "${NETID}" | awk '{ print $2 }' | grep "\-w" | tr -s '\n' ' ')
export ALL_NODES=$(cat /etc/hosts | grep -vE '#|ip6' | grep "${NETID}" | awk '{ print $2 }' | grep -E "\-m|\-w" | tr -s '\n' ' ')
export ALL_NODES_EX_LOCALHOST=$(cat /etc/hosts | grep -vE '#|ip6' | grep "${NETID}" | awk '{ print $2 }' | grep -E "\-m|\-w" | grep -v `hostname` | tr -s '\n' ' ')
# text color setting
export NC="\033[0m" # Color reset
export BLACK="\033[0;30m"
export RED="\033[0;31m"
export GREEN="\033[0;32m"
export YELLOW="\033[0;33m"
export BLUE="\033[0;34m"
export PURPLE="\033[0;35m"
export CYAN="\033[0;36m"
export WHITE="\033[0;37m"
# for kubernetes project
export NAME_SPACE_0="kube-system"
export NAME_SPACE_1="local-path-storage"
export NAME_SPACE_2="metallb-system"
export NAME_SPACE_3="ingress-nginx"
export NAME_SPACE_4="jenkins"
export NAME_SPACE_5="quay"
export NAME_SPACE_6="gf" #grafana
export NAME_SPACE_7="landlord"
export NAME_SPACE_8="rook-ceph"
# kubernetes project storageclass
export STORAGE_CLASS="rook-cephfs"
#export STORAGE_CLASS="local-path"
# ---

# functions >>>
function start-info() {
  for cwlist in ${CP_NODES} ${WK_NODES}
    do
      nc -z -w 1 ${cwlist} 10250 > /dev/null 2>&1
      [ $? == 0 ] && status=1 || status=0
      [ "${status}" == "1" ] && cluster_list=$(ssh ${cwlist} kubectl get nodes 2> /dev/null | tail -n +2 | cut -d " " -f 1 | tr -s '\n' ' ') && cluster_ver=$(ssh ${cwlist} kubectl get nodes 2> /dev/null | grep '\-m1' | awk '{ print $5}') && break
      [ "${status}" == "0" ] && break
    done
  nc -z -w 1 `hostname` 10250 > /dev/null 2>&1
  [ $? != 0 ] && meassage="     | ${RED}This node not activate.${NC}"
  if [ "${status}" == "1" ]
    then
      echo -en "${GREEN}●${NC} Kubernetes deployed | ${cluster_ver}"
      echo -e "${YELLOW} [ Input parameter \"help\" display more information ]${NC}"
      echo -e "  └─ Active nodes${meassage}"
      echo ${cluster_list} | grep '\-m' &> /dev/null
      [ $? == 0 ] && echo -e "     └─ control-plane nodes   | ${GREEN}`echo ${cluster_list} | tr -s ' ' '\n' | grep '\-m' | tr -s '\n' ' '`${NC}" || echo "     └─ control-plane nodes   | --"
      echo ${cluster_list} | grep '\-w' &> /dev/null
      [ $? == 0 ] && echo -e "     └─ worker nodes          | ${GREEN}`echo ${cluster_list} | tr -s ' ' '\n' | grep '\-w' | tr -s '\n' ' '`${NC}" || echo -e "     └─ worker nodes          | --"
    else
      echo -en "${YELLOW}●${NC} Kubernetes not detected"
      echo -e "${YELLOW} [ Input parameter \"help\" display more information ]${NC}"
      echo -e "  └─ Plan list"
      echo -e "     └─ control-plane nodes   | ${YELLOW}`echo -e "${CP_NODES}"`${NC}"
      echo -e "     └─ worker nodes          | ${YELLOW}`echo ${WK_NODES}`${NC}"
  fi
}

function sys-variable () {
  source ~/bin/kdm &> /dev/null
  echo -e "${YELLOW}Variable list${NC}"
  echo -e " > VER_SWITCH: ${YELLOW}${VER_SWITCH}${NC}"
  echo -e " > OS_VERSION: ${YELLOW}${OS_VERSION}${NC}"
  echo -e " > CRIO_OS_VERSION: ${YELLOW}${CRIO_OS_VERSION}${NC}"
  echo -e " > CRI_RELEASE: ${YELLOW}${CRI_RELEASE}${NC}"
  echo -e " > CRI_SUBVER: ${YELLOW}${CRI_SUBVER}${NC}"
  echo -e " > KUBE_RELEASE: ${YELLOW}${KUBE_RELEASE}${NC}"
  echo -e " > KUBE_SUBVER: ${YELLOW}${KUBE_SUBVER}${NC}"
  echo -e " > CRI_ALL_VERSION: ${YELLOW}${CRI_ALL_VERSION}${NC}"
  echo -e " > ROOK_TAG: ${YELLOW}${ROOK_TAG}${NC}"; echo
  echo -e " > KUBE_VIP: ${YELLOW}${KUBE_VIP}${NC}"
  echo -e " > KUBE_INTERFACE: ${YELLOW}${KUBE_INTERFACE}${NC}"
  echo -e " > IP: ${YELLOW}${IP}${NC}"
  echo -e " > NETID: ${YELLOW}${NETID}${NC}"
  echo -e " > GATEWAY: ${YELLOW}${GATEWAY}${NC}"
  echo -e " > NETMASK: ${YELLOW}${NETMASK}${NC}"
  echo -e " > CP_NODES: ${YELLOW}${CP_NODES}${NC}"
  echo -e " > WK_NODES: ${YELLOW}${WK_NODES}${NC}"
}

function interrupt() {
  [ ${#} == 0 ] || echo -e "${@}"
  read -s -n1 -p "$(echo -e ${RED}Press 'N/n' to stop, other key to continue.${NC})" ans; echo -e "\n"
  case ${ans} in
  n|N)
    echo -e "${RED}Interrupted!${NC}\n"; exit
    ;;
  *)
    ;;
  esac
}

function node-message() {
  echo -e "${RED} Please input parameter after ${YELLOW}\"${@}\" ${NC}"
  echo -e "${YELLOW}  > [ <local> | for this host ]${NC}"
  echo -e "${YELLOW}  > [ <hosts> | for all nodes in /etc/hosts ]${NC}"
  echo -e "${YELLOW}  > [ <node-name> ... | for specify nodes ]${NC}\n"
}

function cp-node-message() {
  echo -e "${RED} Please input parameter after ${YELLOW}\"${@}\" ${NC}"
  echo -e "${YELLOW}  > [ <local> | for this host ]${NC}"
  echo -e "${YELLOW}  > [ <hosts> | for all control-plane nodes in /etc/hosts ]${NC}"
  echo -e "${YELLOW}  > [ <node-name> ... | for specify nodes ]${NC}\n"
}

function wk-node-message() {
  echo -e "${RED} Please input parameter after ${YELLOW}\"${@}\" ${NC}"
  echo -e "${YELLOW}  > [ <local> | for this host ]${NC}"
  echo -e "${YELLOW}  > [ <hosts> | for all worker nodes in /etc/hosts ]${NC}"
  echo -e "${YELLOW}  > [ <node-name> ... | for specify nodes ]${NC}\n"
}

function node-selector () {
  echo "${@}" | grep -wE "hosts|local" &> /dev/null
  [ $? != 0 ] && [ -z ${2} ] && node-message ${@} && exit
  list=$(echo "${CP_NODES}${WK_NODES}" | sed 's/ /|/g' | sed 's/.$//')
  parameter=${@}
  test=${1}
  while true
    do
      echo "${1}" | grep -vwE "hosts|local|${list}" &> /dev/null
      [ $? == 0 ] && shift || break
    done

  echo ${@} | sed 's/ /\n/g' | grep -vwE "${list}" &> /dev/null
  [ $? == 0 ] && status=3 || status=2
  echo ${@} | grep -w "hosts" &> /dev/null
  [ $? == 0 ] && status=0
  echo ${@} | grep -w "local" &> /dev/null
  [ $? == 0 ] && status=1

  if [ "${status}" == "0" ]
    then
      list=$(echo "${CP_NODES} ${WK_NODES}")
      cp_nodes=$(echo "${list}" | tr -s ' ' '\n' | grep "\-m" | tr -s '\n' ' ')
      wk_nodes=$(echo "${list}" | tr -s ' ' '\n' | grep "\-w" | tr -s '\n' ' ')
  elif [ "${status}" == "1" ]
    then
      list=$(hostname)
      cp_nodes=$(echo "${list}" | tr -s ' ' '\n' | grep "\-m" | tr -s '\n' ' ')
      wk_nodes=$(echo "${list}" | tr -s ' ' '\n' | grep "\-w" | tr -s '\n' ' ')
  elif [ "${status}" == "2" ]
    then
      list=${@}
      cp_nodes=$(echo "${list}" | tr -s ' ' '\n' | grep "\-m" | tr -s '\n' ' ')
      wk_nodes=$(echo "${list}" | tr -s ' ' '\n' | grep "\-w" | tr -s '\n' ' ')
  elif [ "${status}" == "3" ]
    then
      parameter=$(echo ${parameter} | sed 's/ /\n/g' | grep -v ${test} | sed ":a;N;s/\\n/ /g;ta")
      echo -e "${YELLOW} \"${parameter}\" ${NC}is not effective parameter!"
      echo -e "${RED} Please check out hostname list: ${YELLOW}${ALL_NODES}${NC},${RED}or input parameter:${NC}"
      echo -e "${YELLOW}  > [ <local> | for this host ]${NC}"
      echo -e "${YELLOW}  > [ <hosts> | for all nodes in /etc/hosts ]${NC}"
      echo -e "${YELLOW}  > [ <node-name> ... | for specify nodes ]${NC}\n" && exit
  fi
}

function exclude-non-join () {
  #Exclude non-join nodes
  which kubectl &> /dev/null
  [ $? == 0 ] && status=1 || status=0
  [ "${status}" == "0" ] && echo -e " ${YELLOW}●${NC} This node not activate.\n" && exit
  [ "${status}" == "1" ] && cp_list=$(kubectl get nodes | tail -n +2 | awk '{ print $1 }' | grep '\-m' | tr -s '\n' '|' | sed '$ s/.$//')
  [ "${status}" == "1" ] && wk_list=$(kubectl get nodes | tail -n +2 | awk '{ print $1 }' | grep '\-w' | tr -s '\n' '|' | sed '$ s/.$//')
  [ "${status}" == "1" ] && cp_nodes=$(echo ${cp_nodes} | tr -s ' ' '\n' | grep -E ${cp_list} | tr -s '\n' ' ')
  [ "${status}" == "1" ] && wk_nodes=$(echo ${wk_nodes} | tr -s ' ' '\n' | grep -E ${wk_list} | tr -s '\n' ' ')
}

function node-power () {
  echo "${@}" | grep -wE "reboot|off" &> /dev/null
  [ $? != 0 ] && echo -e "${RED}Please input parameter [ reboot | off ]${NC}\n" && exit
  echo "${@}" | grep -w "reboot" &> /dev/null && power=reboot
  echo "${@}" | grep -w "off" &> /dev/null && power=poweroff
  [ -z ${3} ] && node-message ${2} && exit
  parameter=$(echo "${@}" | sed 's/ /\n/g' | grep -vwE "reboot|off" | sed ":a;N;s/\\n/ /g;ta")
  node-selector ${parameter}

  cp_nodes=$(echo ${cp_nodes} | tr -s ' ' '\n' | tac | tr -s '\n' ' ')
  message="${RED}Continue to ${power} nodes:${YELLOW} ${wk_nodes} ${cp_nodes}${NC}"
  interrupt ${message}
  echo -e "${YELLOW}nodes ${power} procedure${NC}"
  for list in ${wk_nodes} ${cp_nodes}
    do
      echo -e " ${RED}●${NC} ${list} ${power} execute${NC}"
      sleep 3
      ssh ${list} "sudo ${power}" 2> /dev/null
    done; echo
}

function pkg-repo-add () {
  #cri-o package repository
  [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && CRIO_OS_VERSION=CentOS_8_Stream
  if [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ]
    then
      status=0
      [ "${VER_SWITCH}" == "latest" ] && curl -s https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/${CRIO_OS_VERSION}/devel:kubic:libcontainers:stable.repo | grep 'devel_kubic_libcontainers_stable' &> /dev/null && status=1
      [ "${VER_SWITCH}" == "latest" ] && echo ${status} | grep "1" &> /dev/null && ssh ${cwlist} "sudo curl -L -o /etc/yum.repos.d/devel:kubic:libcontainers:stable.repo https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/${CRIO_OS_VERSION}/devel:kubic:libcontainers:stable.repo" &> /dev/null && status=0
      [ "${VER_SWITCH}" == "latest" ] && curl -s https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/${CRI_RELEASE}/${CRIO_OS_VERSION}/devel:kubic:libcontainers:stable:cri-o:${CRI_RELEASE}.repo | grep 'devel_kubic_libcontainers_stable' &> /dev/null && status=1
      [ "${VER_SWITCH}" == "latest" ] && echo ${status} | grep "1" &> /dev/null && ssh ${cwlist} "sudo curl -L -o /etc/yum.repos.d/devel:kubic:libcontainers:stable:cri-o:${CRI_RELEASE}.repo https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/${CRI_RELEASE}/${CRIO_OS_VERSION}/devel:kubic:libcontainers:stable:cri-o:${CRI_RELEASE}.repo" &> /dev/null
      [ "${VER_SWITCH}" == "latest" ] && echo ${status} | grep "1" &> /dev/null && echo -e " ${GREEN}●${NC} ${CRI_RELEASE} cri-o repository has been added" #|| echo -e " ${YELLOW}●${NC} ${CRI_RELEASE} repository not exist"

      [ "${VER_SWITCH}" == "sub" ] && for cri_subver in ${CRI_ALL_VERSION}
        do
          status=0
          [ "${VER_SWITCH}" == "sub" ] && curl -s https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/${CRIO_OS_VERSION}/devel:kubic:libcontainers:stable.repo | grep 'devel_kubic_libcontainers_stable' &> /dev/null && status=1
          [ "${VER_SWITCH}" == "sub" ] && echo ${status} | grep "1" &> /dev/null && ssh ${cwlist} "sudo curl -L -o /etc/yum.repos.d/devel:kubic:libcontainers:stable.repo https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/${CRIO_OS_VERSION}/devel:kubic:libcontainers:stable.repo" &> /dev/null && status=0
          [ "${VER_SWITCH}" == "sub" ] && curl -s https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/${CRI_RELEASE}:/${cri_subver}/${CRIO_OS_VERSION}/devel:kubic:libcontainers:stable:cri-o:${CRI_RELEASE}:${cri_subver}.repo | grep 'devel_kubic_libcontainers_stable' &> /dev/null && status=1
          [ "${VER_SWITCH}" == "sub" ] && echo ${status} | grep "1" &> /dev/null && ssh ${cwlist} "sudo curl -L -o /etc/yum.repos.d/devel:kubic:libcontainers:stable:cri-o:${CRI_RELEASE}:${cri_subver}.repo https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/${CRI_RELEASE}:/${cri_subver}/${CRIO_OS_VERSION}/devel:kubic:libcontainers:stable:cri-o:${CRI_RELEASE}:${cri_subver}.repo" &> /dev/null
          [ "${VER_SWITCH}" == "sub" ] && echo ${status} | grep "1" &> /dev/null && echo -e " ${GREEN}●${NC} ${cri_subver} cri-o repository has been added" #|| echo -e " ${YELLOW}●${NC} ${cri_subver} repository not exist"
        done
  fi

  if [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ]
    then
      status=0
      [ "${VER_SWITCH}" == "latest" ] && curl -s https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/${CRIO_OS_VERSION}/Release.key | grep 'BEGIN PGP PUBLIC KEY BLOCK' &> /dev/null && status=1
      [ "${status}" == "1" ] && ssh ${cwlist} "echo "deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/${CRIO_OS_VERSION}/ /" | sudo tee /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list" &> /dev/null && ssh ${cwlist} "curl -L https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/${CRIO_OS_VERSION}/Release.key | sudo apt-key add - " &> /dev/null && status=0

      [ "${VER_SWITCH}" == "sub" ] && for cri_subver in ${CRI_ALL_VERSION}
        do
          [ "${VER_SWITCH}" == "sub" ] && curl -s https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/${CRI_RELEASE}:/${cri_subver}/${CRIO_OS_VERSION}/Release.key | grep 'BEGIN PGP PUBLIC KEY BLOCK' &> /dev/null && status=1
          [ "${status}" == "1" ] && ssh ${cwlist} "echo "deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/${CRI_RELEASE}:/${cri_subver}/${CRIO_OS_VERSION}/ /" | sudo tee /etc/apt/sources.list.d/devel:kubic:libcontainers:stable:cri-o:${CRI_RELEASE}:${CRI_SUBVER}.list" &> /dev/null && ssh ${cwlist} "curl -L https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/${CRI_RELEASE}:/${cri_subver}/${CRIO_OS_VERSION}/Release.key | sudo apt-key add - " &> /dev/null && status=0
        done
  fi

  #Kubernetes package repository
  [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} 'sudo bash -c "cat << \EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\$basearch
enabled=1
gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
exclude=kubelet kubeadm kubectl
EOF"' && echo -e " ${GREEN}●${NC} kubernetes.repo has been added"

  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg" &> /dev/null
  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "echo "deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list" &> /dev/null
  #helm package repository
  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "curl https://baltocdn.com/helm/signing.asc | gpg --dearmor | sudo tee /usr/share/keyrings/helm.gpg > /dev/null" &> /dev/null
  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/helm.gpg] https://baltocdn.com/helm/stable/debian/ all main" | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list" &> /dev/null
  
  #update list
  [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "sudo dnf clean all" &> /dev/null
  [ $? == 0 ] && echo -e " ${GREEN}●${NC} package cache cleanup"
  [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "sudo dnf versionlock delete cri-o kubectl kubeadm kubelet podman" &> /dev/null
  [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "sudo dnf makecache" &> /dev/null
  [ $? == 0 ] && echo -e " ${GREEN}●${NC} package cache updated"
  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "sudo apt-get -qy update" &> /dev/null
  [ $? == 0 ] && echo -e " ${GREEN}●${NC} package updated"
  #sudo rm /etc/yum.repos.d/devel:*
}

function sys-check() {
  [ -z ${2} ] && node-message ${@} && exit
  node-selector ${@}

  for cwlist in ${cp_nodes} ${wk_nodes}
    do
      echo -e "${YELLOW}${cwlist} | check list${NC}"
      nc -z -w 1 ${cwlist} 22 > /dev/null 2>&1
      [ $? != 0 ] && echo -e " ${RED}●${NC} ${cwlist} is not available\n" && continue
      #swap
      ssh ${cwlist} "sudo swapon --show | grep '/dev'" &> /dev/null
      [ $? != 0 ] && echo -e " ${GREEN}●${NC} swap disabled" || echo -e " ${YELLOW}●${NC} swap not disable"
      #modules
      sys_modules=$(ssh ${cwlist} lsmod | awk '{ print $1 }' | grep -E 'br_netfilter|overlay' | sed ":a;N;s/\n/ | /g")
      echo -e " ${GREEN}●${NC} Enable modules: ${YELLOW}[ ${sys_modules} ]${NC}"
      #SELinux
      status=0
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo sestatus | grep 'SELinux status:' | grep 'disabled'" &> /dev/null && echo -e " ${GREEN}●${NC} SELinux disabled" && status=1
      [ ${status} == 0 ] && [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo sestatus | grep 'SELinux status:' | grep 'enabled'" &> /dev/null && se_status=$(ssh ${cwlist} sudo sestatus | grep 'Current mode:' | awk '{ print $3 }') && echo -e " ${YELLOW}●${NC} SELinux mode: ${YELLOW}[ ${se_status} ]${NC}"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "sudo sestatus | grep 'SELinux status:' | grep 'disabled'" &> /dev/null && echo -e " ${GREEN}●${NC} SELinux disabled"
      [ ${status} == 0 ] && [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "sudo sestatus | grep 'SELinux status:' | grep 'enabled'" &> /dev/null && se_status=$(ssh ${cwlist} sudo sestatus | grep 'Current mode:' | awk '{ print $3 }') && echo -e " ${YELLOW}●${NC} SELinux mode: ${YELLOW}[ ${se_status} ]"
      #firewalld
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo systemctl status firewalld | grep 'active (running)'" &> /dev/null && echo -e " ${YELLOW}●${NC} firewalld not disable"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo systemctl status firewalld | grep 'inactive (dead)'" &> /dev/null && echo -e " ${GREEN}●${NC} firewalld disabled"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "sudo systemctl status firewalld | grep 'active (running)'" &> /dev/null && echo -e " ${YELLOW}●${NC} firewalld not disable"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "sudo systemctl status firewalld | grep 'inactive (dead)'" &> /dev/null && echo -e " ${GREEN}●${NC} firewalld disabled"
      #ipv4 forward
      forward=$(ssh ${cwlist} "cat /proc/sys/net/bridge/bridge-nf-call-iptables 2> /dev/null")
      [ "${forward}" == "1" ] && echo -e " ${GREEN}●${NC} ipv4_forward enabled" || echo -e " ${YELLOW}●${NC} ipv4 ip_forward not enable."
      echo
    done
}

function pkg-check() {
  [ -z ${2} ] && node-message ${@} && exit
  node-selector ${@}
  #cri-o
  crio_version="crio version | grep "^Version""
  crio_status="sudo systemctl status crio | grep 'Active'"
  crio_time="sudo systemctl status crio | grep 'Active' | cut -d ';' -f 2 | grep -v 'inactive'"
  #kubelet
  kubelet_version="kubelet --version | sed 's/v//g'"
  kubelet_status="sudo systemctl status kubelet | grep 'Active'"
  kubelet_time="sudo systemctl status kubelet | grep 'Active' | cut -d ';' -f 2 | grep -v 'inactive'"
  #kubeadm
  kubeadm_version="kubeadm version -o yaml | grep 'gitVersion' | sed 's/v//g'"
  #kubectl
  kubectl_versio="kubectl version -o yaml 2>&1 | grep -A 9 'clientVersion:' | grep 'gitVersion' | sed 's/v//g'"

  for clist in ${cp_nodes}
    do
      echo -e "${YELLOW}${clist} | check list${NC}"
      nc -z -w 1 ${clist} 22 > /dev/null 2>&1
      [ $? != 0 ] && echo -e " ${RED}●${NC} ${wlist} is not available\n" && continue
      #cri-o
      status=0
      ssh ${clist} "which crio > /dev/null 2>&1"
      [ $? != 0 ] && echo -e " ${YELLOW}●${NC} crio not install" && status=1
      #Status active
      ssh ${clist} "sudo systemctl status crio | grep "Active:" | grep "failed" > /dev/null 2>&1" && status=0
      [ $? != 0 ] && [ "${status}" == 0 ] && echo -e " ${GREEN}●${NC} crio: `ssh ${clist} ${crio_version} 2>&1 | sed '/time/d' | awk '{ print $2 }'` | `ssh ${clist} ${crio_status} | awk '{ print $2,$3 }'` | `ssh ${clist} ${crio_time} | sed 's/^.//' | grep -v 'inactive'`"
      #Status failed (if cri-o has been install)
      ssh ${clist} "sudo systemctl status crio | grep "Active:" | grep "failed" > /dev/null 2>&1" ssh ${clist} sudo systemctl status crio | grep "Loaded:" | grep -v "not-found" && status=0
      [ $? == 0 ] && [ "${status}" == 0 ] && echo -e " ${YELLOW}●${NC} crio: `ssh ${clist} ${crio_version} 2>&1 | sed '/time/d' | awk '{ print $2 }'` | `ssh ${clist} ${crio_status} | awk '{ print $2,$3,$4 }'` | `ssh ${clist} ${crio_time} | sed 's/^.//'`"
      #kubelet
      ssh ${clist} "which kubelet" &> /dev/null
      [ $? != 0 ] && echo -e " ${YELLOW}●${NC} kubelet not install" || echo -e " ${GREEN}●${NC} kubelet: `ssh ${clist} ${kubelet_version} | awk '{ print $2 }'` | `ssh ${clist} ${kubelet_status} | awk '{ print $2,$3 }'` | `ssh ${clist} ${kubelet_time} | sed 's/^.//' | grep -v 'inactive'`"
      #kubeadm
      ssh ${clist} "which kubeadm" &> /dev/null
      [ $? != 0 ] && echo -e " ${YELLOW}●${NC} kubeadm not install" || echo -e " ${GREEN}●${NC} kubeadm: `ssh ${clist} ${kubeadm_version} 2>&1 | awk '{ print $2 }' `"
      #kubectl
      ssh ${clist} "which kubectl" &> /dev/null
      [ $? != 0 ] && echo -e " ${YELLOW}●${NC} kubectl not install" || echo -e " ${GREEN}●${NC} kubectl: `ssh ${clist} ${kubectl_versio} 2>&1 | sed '/localhost:8080/d' | awk '{ print $2 }'`"
      #helm
      ssh ${clist} "which helm" &> /dev/null
      [ $? != 0 ] && echo -e " ${YELLOW}●${NC} helm not install" || echo -e " ${GREEN}●${NC} helm: `ssh ${clist} helm version | awk '{ print $1 }' | cut -d '"' -f 2 | sed 's/v//g'`"
      #podman
      ssh ${clist} "which podman" &> /dev/null
      [ $? != 0 ] && echo -e " ${YELLOW}●${NC} podman not install" || echo -e " ${GREEN}●${NC} podman: `ssh ${clist} sudo podman version | grep '^Version' | awk '{ print $2 }'`"
      #k9s
      ssh ${clist} "which k9s" &> /dev/null 
      [ $? != 0 ] && echo -e " ${YELLOW}●${NC} k9s not install" || echo -e " ${GREEN}●${NC} k9s: `ssh ${clist} k9s version -s | grep Version | awk '{ print $2 }' | sed 's/v//g'`"
      echo
    done

  for wlist in ${wk_nodes}
    do
      echo -e "${YELLOW}${wlist} | check list${NC}"
      nc -z -w 1 ${wlist} 22 > /dev/null 2>&1
      [ $? != 0 ] && echo -e " ${RED}●${NC} ${wlist} is not available\n" && continue
      #cri-o
      status=0
      ssh ${wlist} "which crio > /dev/null 2>&1"
      [ $? != 0 ] && echo -e " ${YELLOW}●${NC} crio not install" && status=1
      ssh ${wlist} "sudo systemctl status crio | grep "Active:" | grep "failed" > /dev/null 2>&1" && status=0
      [ $? != 0 ] && [ "${status}" == 0 ] && echo -e " ${GREEN}●${NC} crio: `ssh ${wlist} ${crio_version} 2>&1 | sed '/time/d' | awk '{ print $2 }'` | `ssh ${wlist} ${crio_status} | awk '{ print $2,$3 }'` | `ssh ${wlist} ${crio_time} | sed 's/^.//' | grep -v 'inactive'`"
      ssh ${wlist} "sudo systemctl status crio | grep "Active:" | grep "failed" > /dev/null 2>&1" && status=0
      [ $? == 0 ] && [ "${status}" == 0 ] && echo -e " ${YELLOW}●${NC} crio: `ssh ${wlist} ${crio_version} 2>&1 | sed '/time/d' | awk '{ print $2 }'` | `ssh ${wlist} ${crio_status} | awk '{ print $2,$3,$4 }'` | `ssh ${wlist} ${crio_time} | sed 's/^.//'`"
      #kubelet
      ssh ${wlist} "which kubelet" &> /dev/null
      [ $? != 0 ] && echo -e " ${YELLOW}●${NC} kubelet not install" || echo -e " ${GREEN}●${NC} kubelet: `ssh ${wlist} ${kubelet_version} | awk '{ print $2 }'` | `ssh ${wlist} ${kubelet_status} | awk '{ print $2,$3 }'` | `ssh ${wlist} ${kubelet_time} | sed 's/^.//'`"
      #kubeadm
      ssh ${wlist} "which kubeadm " &> /dev/null
      [ $? != 0 ] && echo -e " ${YELLOW}●${NC} kubeadm not install" || echo -e " ${GREEN}●${NC} kubeadm: `ssh ${wlist} ${kubeadm_version} 2>&1 | awk '{ print $2 }' `"
      #podman
      ssh ${wlist} "which podman" &> /dev/null
      [ $? != 0 ] && echo -e " ${YELLOW}●${NC} podman not install" || echo -e " ${GREEN}●${NC} podman: `ssh ${wlist} sudo podman version | grep '^Version' | awk '{ print $2 }'`"
      echo
    done
}

function sys-info () {
  #system information
  echo "" | sudo tee /tmp/sinfo &> /dev/null
  echo -e "[System]" | sudo tee /tmp/sinfo
  #OS information
  os_name=`cat /etc/os-release | grep 'PRETTY_NAME' | cut -d '"' -f 2`
  echo -e " OS Version: ${YELLOW}$os_name${NC}"
  echo -e " Hostname: ${YELLOW}`hostname`${NC}"
  #memory information
  m_size=$(sudo free -mh | grep Mem: | awk '{ print $2 }' | sed 's/Gi//g')
  echo -e " Memory: ${YELLOW}${m_size} GB${NC}"
  #cpu information
  cpu_name=$(sudo cat /proc/cpuinfo | grep 'model name' | head -n 1 | cut -d ':' -f2 | tr -s '-' ' ' | sed 's/(R)//g; s/(TM)//g; s/@ //g' | sed 's/^.//')
  core_number=$(sudo cat /proc/cpuinfo | grep 'model name' | wc -l)
  cpu_architecture=$(uname -m)
  echo -e " CPU: ${YELLOW}$cpu_name (core: $core_number) | ${cpu_architecture}${NC}"
  #disk information
  disk_list=$(sudo fdisk -l | grep '^Disk' | grep 'sd' | awk '{ print $2 }' | sed 's/://g;s/\/dev\///g' | tr -s '\n' ' ' | sed 's/.$//')
  echo -e " Disk list: ${YELLOW}${disk_list}${NC}"
  for disk_list in ${disk_list}
    do
      disk_capacity=$(sudo fdisk -l | grep '^Disk' | grep "${disk_list}" | awk '{ print $3 }')
      disk_usage=$(sudo du -ch / 2> /dev/null | grep 'total' | grep 'G'| awk '{ print $1 }' | tr -s 'G' ' ')
      disk_percent=$(awk "BEGIN { pc=100*${disk_usage}/${disk_capacity}; i=int(pc); print (pc-i<0.5)?i:i+1 }")
      disk_type=$(sudo fdisk -l | grep -A 1 "^Disk /dev/${disk_list}:" | grep '^Disk model' | cut -d ':' -f 2 | sed 's/^.//')
      echo -e "  > Disk name: ${YELLOW}${disk_list} | ${disk_type}${NC}"
      echo -e "  > Disk capacity: ${YELLOW}${disk_capacity} GB${NC}"
      echo -e "  > Disk usage: ${YELLOW}${disk_usage}GB | ${disk_percent} %${NC}"
      echo "  ---"
    done
  echo ""
  #network information
  echo "[Network]"
  echo -e " IP Address: ${YELLOW}${IP}${NC}"
  echo -e " Gateway: ${YELLOW}${GATEWAY}${NC}"

  for list in $(cat /etc/resolv.conf | grep '^nameserver' | awk '{ print $2 }')
    do
      echo -e " nameserver: ${YELLOW}${list}${NC}"
    done

  ping -c 1 www.hinet.net >> /dev/null
  [ "$?" == "0" ] && echo -e " Internet access: ${GREEN}Pass${NC}" || echo -e " Internet: ${RED}Not pass${NC}"
}

function kubectl-check () {
  status=0
  ssh ${1} "which kubectl" &> /dev/null
  [ $? == 0 ] && kubectl_check=$(ssh ${1} kubectl version -o yaml 2> /dev/null | grep -A 10 'clientVersion' | grep 'gitVersion' | awk '{ print $2 }') && status=1
  [ "${status}" == "1" ] && echo -e " ${GREEN}●${NC} kubectl ${kubectl_check} installed" || echo -e " ${YELLOW}●${NC} kubectl not install"
}

function kubeadm-check () {
  status=0
  ssh ${1} "which kubeadm" &> /dev/null
  [ $? == 0 ] && kubeadm_check=$(ssh ${1} kubeadm version -o yaml 2> /dev/null | grep "gitVersion" | awk '{ print $2 }') && status=1
  [ "${status}" == "1" ] && echo -e " ${GREEN}●${NC} kubeadm ${kubeadm_check} installed" || echo -e " ${YELLOW}●${NC} kubeadm not install"
}

function kubelet-check () {
  status=0
  ssh ${1} "which kubelet" &> /dev/null
  [ $? == 0 ] && kubelet_check=$(ssh ${1} kubelet --version 2> /dev/null | grep "^Kubernetes" | awk '{ print $2 }') && status=1
  [ "${status}" == "1" ] && echo -e " ${GREEN}●${NC} kubelet ${kubelet_check} installed" || echo -e " ${YELLOW}●${NC} kubelet not install"
}

function crio-check () {
  ssh ${1} "which crio &> /dev/null" &> /dev/null
  cri_check=$(ssh ${1} crio version 2> /dev/null | grep "^Version" | awk '{ print $2 }')
  crio version &> /dev/null
  [ $? == 0 ] && echo -e " ${GREEN}●${NC} crio ${cri_check} installed" || echo -e " ${YELLOW}●${NC} crio not install"
}

function podman-check () {
  ssh ${1} "which podman" &> /dev/null
  podman_check=$(ssh ${1} podman version | grep '^Version' | awk '{ print $2 }')
  [ $? == 0 ] && echo -e " ${GREEN}●${NC} podman ${podman_check} installed" || echo -e " ${YELLOW}●${NC} podman not install"
}

function daemon-enable () {
  ssh ${1} "sudo systemctl enable --now crio" &> /dev/null
  [ $? == 0 ] && echo -e " ${GREEN}●${NC} crio enabled" || echo -e " ${RED}●${NC} crio not enable"
  ssh ${1} "sudo systemctl enable --now kubelet" &> /dev/null
  [ $? == 0 ] && echo -e " ${GREEN}●${NC} kubelet enabled" || echo -e " ${RED}●${NC} kubelet not enable"
  ssh ${1} "sudo systemctl daemon-reload" &> /dev/null
  [ $? == 0 ] && echo -e " ${GREEN}●${NC} daemon has been reload" || echo -e " ${YELLOW}●${NC} daemon not reload"
}

function daemon-restart () {
  ssh ${1} "sudo systemctl restart --now crio" &> /dev/null
  [ $? == 0 ] && echo -e " ${GREEN}●${NC} crio restarted" || echo -e " ${RED}●${NC} crio not restart"
  ssh ${1} "sudo systemctl restart --now kubelet" &> /dev/null
  [ $? == 0 ] && echo -e " ${GREEN}●${NC} kubelet restarted" || echo -e " ${RED}●${NC} kubelet not restart"
  ssh ${1} "sudo systemctl daemon-reload" &> /dev/null
  [ $? == 0 ] && echo -e " ${GREEN}●${NC} daemon has been reload" || echo -e " ${YELLOW}●${NC} daemon not reload"
}

function helm-repo-add () {
  for clist in ${cp_nodes}
    do
      echo -e "${YELLOW}${clist} helm repositories${NC}"
      ssh ${clist} "helm repo add projectcalico https://projectcalico.docs.tigera.io/charts &> /dev/null" && echo -e "${YELLOW} > helm repository \"projectcalico\" added${NC}" || echo -e "${RED} > helm repository \"projectcalico\" not add${NC}"
      ssh ${clist} "helm repo add metrics-server https://kubernetes-sigs.github.io/metrics-server &> /dev/null" && echo -e "${YELLOW} > helm repository \"metrics-server\" added${NC}" || echo -e "${RED} > helm repository \"metrics-server\" not add${NC}"
      ssh ${clist} "helm repo add prometheus-community https://prometheus-community.github.io/helm-charts &> /dev/null" && echo -e "${YELLOW} > helm repository \"prometheus\" added${NC}\n" || echo -e "${RED} > helm repository \"prometheus\" not add${NC}"
    done
}

function helm-repo-check () {
  helm_repo_list=$(helm repo ls | tail -n +2 | awk '{ print $1 }' | tr -s '\n' ' ' | sed 's/.$//')
  for clist in ${cp_nodes}
    do
      echo -e "${YELLOW}${clist} helm repository list${NC}"
      for list in ${helm_repo_list}
        do
          echo -e "${YELLOW}${list}${NC}"
          ssh ${clist} "helm search repo --versions ${list} | head -n 4"
          echo
        done
    done
}

function helm-repo-update () {
  for clist in ${cp_nodes}
    do
      echo -e "${YELLOW}${clist} helm repositories update${NC}"
      ssh ${clist} "helm repo update &> /dev/null" && echo -e "${YELLOW}${cwlist} > helm repositories updated${NC}\n"
    done
}

function dir-delete-list () {
  [ "${wclist}" == "" ] && wclist="${wlist} ${clist}"

  ssh ${wclist} "ls ~/.kube" &> /dev/null
  [ $? == 0 ] && ssh ${wclist} "sudo rm -r ~/.kube" || echo "Target has been removed: ~/.kube"
  ssh ${wclist} "sudo ls /etc/systemd/system/etcd*" &> /dev/null
  [ $? == 0 ] && ssh ${wclist} "sudo rm /etc/systemd/system/etcd*" &> /dev/null || echo "Target has been removed: /etc/systemd/system/etcd*"
  empty=$(ssh ${wclist} "ls /var/log/pods/ | wc -l")
  [ ${empty} != 0 ] && ssh ${wclist} "sudo rm -r /var/log/pods/*" &> /dev/null || echo "Target has been removed: /var/log/pods/*"
  empty=$(ssh ${wclist} "sudo ls /etc/kubernetes/manifests/ | wc -l")
  [ ${empty} != 0 ] && ssh ${wclist} "sudo rm /etc/kubernetes/manifests/*" &> /dev/null || echo "Target has been removed: /etc/kubernetes/manifests/*"
  empty=$(ssh ${wclist} "sudo ls /etc/cni/net.d/ | wc -l")
  [ ${empty} != 0 ] && ssh ${wclist} "sudo rm /etc/cni/net.d/*" &> /dev/null || echo "Target has been removed: /etc/cni/net.d/*"
  empty=$(ssh ${wclist} "ls /var/lib/calico/ | wc -l")
  [ ${empty} != 0 ] && ssh ${wclist} "sudo rm /var/lib/calico/*" &> /dev/null || echo "Target has been removed: /var/lib/calico/*"
  empty=$(ssh ${wclist} "ls /var/log/containers/ | wc -l")
  [ ${empty} != 0 ] && ssh ${wclist} "sudo rm /var/log/containers/*" &> /dev/null || echo "Target has been removed: /var/log/containers/*"
  empty=$(ssh ${wclist} "ls /var/log/calico/cni/ | wc -l")
  [ ${empty} != 0 ] && ssh ${wclist} "sudo rm /var/log/calico/cni/*" &> /dev/null || echo "Target has been removed: /var/log/calico/cni/*"
  empty=$(ssh ${wclist} "sudo ls /opt/cni/bin/ | wc -l")
  [ ${empty} != 0 ] && ssh ${wclist} "sudo rm -r /opt/cni/bin/*" &> /dev/null || echo "Target has been removed: /opt/cni/bin/*"
  empty=$(ssh ${wclist} "sudo ls /var/log/crio/pods | wc -l 2> /dev/null")
  [ ${empty} != 0 ] && ssh ${wclist} "sudo rm -r /var/log/crio/pods" &> /dev/null || echo "Target has been removed: /var/log/crio/pods"
  ssh ${wclist} "sudo ls /var/lib/etcd > /dev/null 2>&1"
  [ $? == 0 ] && ssh ${wclist} "sudo rm -r /var/lib/etcd" &> /dev/null || echo "Target has been removed: /var/lib/etcd/"
  #empty=$(ssh ${wclist} "ls /etc/apt/sources.list.d/ | wc -l 2> /dev/null")
  #[ ${empty} != 0 ] && ssh ${wclist} "sudo rm /etc/apt/sources.list.d/*" || echo "Target has been removed: /etc/apt/sources.list.d/*"
}

# Program >>>
echo
case ${1} in

sys-info) #Show host basic information.
  sys-info
;;

sys-var) #Check script variables.
  sys-variable
;;

sys-conf) #Configure file & directory.
  [ "${#}" == "2" ] && [ "${2}" == "hosts" ] && status=1 || status=0
  [ "${status}" == "1" ] && node-selector hosts && status=1
  
  for cwlist in ${cp_nodes} ${wk_nodes}
    do
      echo -e "${YELLOW}${cwlist} system configure${NC}"
      [ "${status}" == "1" ] && ssh ${cwlist} 'kdm sys-conf'
    done
  
  [ "${status}" == "1" ] && exit
  #setup ssh
  os-detection
  cat /etc/ssh/ssh_config | grep 'StrictHostKeyChecking no'
  [ $? != 0 ] && echo 'StrictHostKeyChecking no' | sudo tee -a /etc/ssh/ssh_config

  [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && sudo -S sed -i "s/# %wheel\tALL=(ALL)\tNOPASSWD: ALL/%wheel\tALL=(ALL)\tNOPASSWD: ALL/g" /etc/sudoers
  [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && sudo -S sed -i "s/# %wheel\tALL=(ALL)\tNOPASSWD: ALL/%wheel\tALL=(ALL)\tNOPASSWD: ALL/g" /etc/sudoers
  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && sudo -S sed -i "s/%sudo\tALL=(ALL:ALL) ALL/%sudo\tALL=(ALL:ALL) NOPASSWD: ALL/g" /etc/sudoers
  
  ls ~/bin &> /dev/null
  [ $? != 0 ] && mkdir ~/bin
  ls kdm &> /dev/null
  [ $? == 0 ] && mv /home/bigred/kdm/kdm /home/bigred/bin/
  ls yaml &> /dev/null
  [ $? != 0 ] && mkdir yaml

  [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && sudo subscription-manager repos --enable=codeready-builder-for-rhel-8-x86_64-rpms &> /dev/null
  [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && sudo dnf update -y && sudo dnf upgrade -y
  [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && sudo dnf install -y nano tree curl git chrony
  [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && sudo systemctl start chronyd && sudo systemctl enable chronyd.service
  [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && sudo systemctl status chronyd | grep 'Active:' && sudo chronyc -a makestep
  [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && sudo timedatectl set-timezone Asia/Taipei
  
  [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && sudo dnf update -y && sudo dnf upgrade -y
  [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && sudo dnf install -y nano tree curl git chrony epel-release
  [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && sudo systemctl start chronyd && sudo systemctl enable chronyd.service
  [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && sudo systemctl status chronyd | grep 'Active:' && sudo chronyc -a makestep
  [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && sudo timedatectl set-timezone Asia/Taipei
  #[ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && sudo dnf install -y systemd-timesyncd && sudo systemctl enable --now systemd-timesyncd.service && sudo timedatectl set-ntp true && sudo timedatectl set-timezone Asia/Taipei

  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && sudo apt-get -qy update && sudo apt-get -qy upgrade
  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && sudo apt-get install -qy nano tree curl git chrony
  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && sudo systemctl start chronyd && sudo systemctl enable chronyd.service
  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && sudo systemctl status chronyd | grep 'Active:'&& sudo chronyc -a makestep
  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && sudo timedatectl set-timezone Asia/Taipei

  #turn off welcome message
  cat /etc/profile | grep 'clear'
  [ $? != 0 ] && echo "clear" | sudo tee -a /etc/profile
  touch ~/.hushlogin
  [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && sudo chmod -x /etc/update-motd.d/*

  #Set /etc/hosts
  cat /etc/hosts | grep '127.0.0.1' | grep ${HOSTNAME} &> /dev/null
  [ $? != 0 ] && sudo sed -i "s|127.0.0.1   |127.0.0.1   ${HOSTNAME} |g" /etc/hosts

  echo "/etc/hosts:"
  echo -en "${GREEN}"
  cat /etc/hosts | grep '127.0.0.1' | grep ${HOSTNAME}
  echo -en "${NC}"
;;

sys-check) #Check node basic status.
  sys-check ${@}
;;

sys-date) #Check system time-zone.
  node-selector ${@}
  for cwlist in ${cp_nodes} ${wk_nodes}
    do
      echo -en "${YELLOW}${cwlist} system time: ${NC}"
      ssh ${cwlist} 'date +"%Y-%m-%d %Z %H:%M:%S"'
    done
;;

set-ssh-key) #Let ssh login without password. [ host | renew ]
  if [ "${2}" == "local" ]
    then
      sudo rm -r .ssh/*
      ssh-keygen -t rsa -N '' -f ~/.ssh/id_rsa <<< y
      ssh-copy-id ${USER}@localhost
    elif [ "${2}" == "renew" ]
      then
        sudo rm -r .ssh/*
        ssh-keygen -t rsa -N '' -f ~/.ssh/id_rsa <<< y
        ssh-copy-id ${USER}@localhost
        for cwlist in ${ALL_NODES_EX_LOCALHOST}
          do
            scp -r .ssh ${cwlist}:
          done
      else
        echo -e "${YELLOW}Please input parameter [ local | renew ]${NC}"
  fi
;;

set-hosts) #Setup hosts. [ hosts <m> <Start> <End> <w> <Start> <End> [ Detect NETID just input xxx xxx ] ]
  #setup /etc/hosts
  declare -i mstart=${3} mend=${4} wstart=${6} wend=${7} number=1
  m=${2} w=${5}
  if [ ${#} != 7 ]
    then
      echo; echo -e "Please input parameter.\n"
      echo -e "hosts: setup hosts [ <m> <start> <end> <w> <start> <end> ]\n"; exit
    else

  sudo sed -i "/${NETID}/d" /etc/hosts

  for ((mstart;mstart<=mend;mstart=mstart+1))
    do
sudo bash -c "cat << EOF >> /etc/hosts
${NETID}.${mstart} ${mstart}-${m}${number}
EOF"
  number=$((number+1))
    done;

number=1

  for ((wstart;wstart<=wend;wstart=wstart+1))
    do
sudo bash -c "cat << EOF >> /etc/hosts
${NETID}.${wstart} ${wstart}-${w}${number}
EOF"
  number=$((number+1))
    done;

  echo -e "=hosts=\n"; cat /etc/hosts
  fi

  echo -e "\n= Prepare power off to duplicate VM node."
  interrupt; echo "poweroff node..."; sleep 1.5
  sudo poweroff
;;

set-ip) #Setup IP Address. [ set-ip <IP/NETMASK> [ Detect NETID just input xxx/XX ] ]
  if [ ${#} != 2 ]
    then
      echo -e "Please input parameter.\n"
      echo -e "ipset: Setup IP Address. [ Automatic select networkID <IP/NETMASK> ]\n"
    else

#Rocky 8 NetworkManager setting
[ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && sudo bash -c "cat << EOF > /etc/sysconfig/network-scripts/ifcfg-${KUBE_INTERFACE}
TYPE=Ethernet
PROXY_METHOD=none
BROWSER_ONLY=no
BOOTPROTO=none
DEFROUTE=yes
IPV4_FAILURE_FATAL=no
IPV6INIT=no
IPV6_DEFROUTE=yes
IPV6_FAILURE_FATAL=no
NAME=${KUBE_INTERFACE}
UUID=${NETWORK_UUID}
DEVICE=${KUBE_INTERFACE}
ONBOOT=yes
IPADDR=${NETID}.
PREFIX=24
GATEWAY=${GATEWAY}
DNS1=8.8.8.8
EOF" && echo -e "Network-scripts setting\n" && sudo cat /etc/sysconfig/network-scripts/ifcfg-${KUBE_INTERFACE}

#Rocky 9 NetworkManager setting
[ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && sudo bash -c "cat << EOF > /etc/NetworkManager/sys-connections/${KUBE_INTERFACE}.nmconnection
[connection]
id=${KUBE_INTERFACE}
uuid=""
type=ethernet
autoconnect-priority=-999
interface-name=${KUBE_INTERFACE}

[ethernet]
mac-address=""

[ipv4]
address1=${NETID}.${2},${GATEWAY}
dns=8.8.8.8;
method=manual

[ipv6]
addr-gen-mode=eui64
method=disabled

[proxy]
EOF" && echo -e "NetworkManager setting\n" && sudo cat /etc/NetworkManager/sys-connections/${KUBE_INTERFACE}.nmconnection

#Ubuntu NetworkManager setting
[ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && sudo bash -c "cat << EOF > /etc/netplan/00-installer-config.yaml
network:
  version: 2
  ethernets:
    ${KUBE_INTERFACE}:
      dhcp4: no
      dhcp6: no
      addresses: [${NETID}.${2}]
      routes:
      - to: default
        via: ${GATEWAY}
      nameservers:
        addresses: [8.8.8.8]
EOF" && echo -e "netplane setting\n" && cat /etc/netplan/00-installer-config.yaml; echo

  fi
;;

set-hostname) #Setup hostname. [ hostname [ name ] ]
  if [ ${#} != 2 ]
    then
      echo -e "Please input parameter.\n"
      echo -e "hostname: Setup hostname. [ <hostname> ]\n";exit
    else
      echo "$2" | sudo tee /etc/hostname &> /dev/null
  fi
  echo -n "Set hostname to: "
  cat /etc/hostname
  interrupt; echo "reboot node..."; sleep 1.5
  sudo reboot
;;

set-ver) #Set kube*、cri-o package version.
  [ -z ${2} ] && echo -e "${RED}Please input parameter after ${YELLOW}\"set-ver\" [ latest | sub ]${NC}\n" && exit
  echo "${2}" | grep -vE 'latest|sub' &> /dev/null
  [ $? == 0 ] && echo -e "${RED}Please input parameter after ${YELLOW}\"set-ver\" [ latest | sub ]${NC}\n" && exit

  [ -z ${3} ] && [ "${2}" == "latest" ] && echo -e "${RED}Please input parameter after ${YELLOW}\"set-ver ${2}\" [0-9.0-99]${NC}\n" && exit
  [ -z ${3} ] && [ "${2}" == "sub" ] && echo -e "${RED}Please input parameter after ${YELLOW}\"set-ver ${2}\" [0-9.0-99.0-9]${NC}\n" && exit

  status=0
  [ "${2}" == "sub" ] && echo "${3}" | sed 's|^[0-9].[0-9][0-9].[0-9]||g' | grep '^$' &> /dev/null && status=1
  [ "${2}" == "sub" ] && [ "${status}" == "0" ] && echo -e "${RED}Please input parameter after ${YELLOW}\"set-ver ${2}\" [0-9.0-99.0-9]${NC}\n" && exit

  [ "${2}" == "latest" ] && echo "${3}" | sed 's|^[0-9].[0-9][0-9]||g' | grep '^$' &> /dev/null && status=1
  [ "${2}" == "latest" ] && [ "${status}" == "0" ] && echo -e "${RED}Please input parameter after ${YELLOW}\"set-ver ${2}\" [0-9.0-99]${NC}\n" && exit

  v1=$(echo ${3} | cut -d '.' -f 1-2)
  v2=$(echo ${3} | cut -d '.' -f 3)
  echo ${3} | cut -d '.' -f 3 | grep [0-9] &> /dev/null
  [ $? != 0 ] && v2=0

  echo -en "${YELLOW}"
  sed -i "s|export CRI_RELEASE=${CRI_RELEASE}|export CRI_RELEASE=${v1}|g" ~/bin/kdm
  cat ~/bin/kdm | grep 'export CRI_RELEASE=*' | grep -v 'sed'
  sed -i "s|export CRI_SUBVER=\${CRI_RELEASE}.*|export CRI_SUBVER=\${CRI_RELEASE}.${v2}|g" ~/bin/kdm
  cat ~/bin/kdm | grep 'export CRI_SUBVER=*' | grep -v 'sed'
  sed -i "s|export KUBE_RELEASE=${KUBE_RELEASE}|export KUBE_RELEASE=${v1}|g" ~/bin/kdm
  cat ~/bin/kdm | grep 'export KUBE_RELEASE=*' | grep -v 'sed'
  sed -i "s|export KUBE_SUBVER=\${KUBE_RELEASE}.*|export KUBE_SUBVER=\${KUBE_RELEASE}.${v2}|g" ~/bin/kdm
  cat ~/bin/kdm | grep 'export KUBE_SUBVER=*' | grep -v 'sed'

  sed -i "s|^export VER_SWITCH=[a-z]*|export VER_SWITCH=${2}|g" ~/bin/kdm
  cat ~/bin/kdm | grep '^export VER_SWITCH=[a-z]*' | grep -v 'sed'
  echo -e "${NC}"
  sys-variable
;;

selinux)
  if [ "${2}" == "set-mode" ]
    then
      [ -z ${3} ] && echo -e "${RED}Please input parameter after ${YELLOW}\"set-mode\" [ disable | permissive | enforcing ]${NC}\n" && exit
      echo "${3}" | grep -vE 'disable|permissive|enforcing' &> /dev/null
      [ $? == 0 ] && echo -e "${RED}Please input parameter after ${YELLOW}\"set-mode\" [ disable | permissive | enforcing ]${NC}\n" && exit

      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && sudo sed -i "/^export\ SELINUX_MODE=/c\export\ SELINUX_MODE=${3}" ~/bin/kdm
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && sudo sed -i "/^export SELINUX_MODE=/c\export SELINUX_MODE=${3}" ~/bin/kdm
    
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && echo -e "${YELLOW}${cwlist}${NC}" && cat ~/bin/kdm | grep '^export\ SELINUX_MODE='
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && echo -e "${YELLOW}${cwlist}${NC}" && cat ~/bin/kdm | grep '^export\ SELINUX_MODE='
  elif [ "${2}" == "chmod" ]
    then
      node-selector hosts
      for cwlist in ${wk_nodes} ${cp_nodes}
        do
          echo "${CRIO_OS_VERSION}" | grep -E "RHEL_8|CentOS_8_Stream" &> /dev/null
          [ $? == 0 ] && status=1 || status=0
          echo -e "${cwlist}"

          cat ~/bin/kdm | grep '^export\ SELINUX_MODE=' | grep -E 'permissive|enforcing' &> /dev/null
          [ $? == 0 ] && [ "${status}" == "1" ] && ssh ${cwlist} sudo setenforce ${SELINUX_MODE}
          
          [ "${status}" == "1" ] && ssh ${cwlist} "sudo sed -i "/^SELINUX=/c\SELINUX=${SELINUX_MODE}" /etc/selinux/config"
          [ "${status}" == "1" ] && ssh ${cwlist} cat /etc/selinux/config | grep '^SELINUX='
        done
  fi
;;

sync-ssh) #scp .ssh to every nodes.
  node-selector hosts
  for cwlist in ${cp_nodes} ${wk_nodes}
    do
      echo -en "${YELLOW}Send to ${cwlist}${NC}"
      scp -r .ssh ${cwlist}: 2> /dev/null
    done
;;

sync-kdm) #scp kdm to every nodes.
  node-selector hosts
  for cwlist in ${cp_nodes} ${wk_nodes}
    do
      ssh ${cwlist} "ls ~/bin &> /dev/null"
      [ $? != 0 ] && ssh ${cwlist} "mkdir ~/bin &> /dev/null"
      echo -en "${YELLOW}Send to ${cwlist}${NC}"
      scp bin/kdm ${cwlist}:bin/ 2> /dev/null
    done
;;

sync-yaml) #scp yaml to every nodes.
  node-selector hosts
  for cwlist in ${cp_nodes}
    do
      echo -en "${YELLOW}Send to ${cwlist}${NC}"
      scp -r yaml ${cwlist}: 2> /dev/null
    done
;;

pkg-ver) #Check package repositories.
  [ -z ${2} ] && node-message ${@} && exit
  node-selector ${@}
  for cwlist in ${cp_nodes} ${wk_nodes}
    do
      echo -e "${YELLOW}${cwlist} | package repositories check${NC}"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && echo -e "${GREEN}Package enabled repositories:${NC}"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo dnf repolist --enabled -q"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && echo -e "${GREEN}Package enabled repositories:${NC}"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "sudo dnf repolist --enabled -q"
      for plist in ${PACKAGE_LIST}
        do
          sudo dnf provides ${plist} &> /dev/null || continue
          echo -e "${GREEN}${plist} pkg-version:${NC}"
          [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "echo ${plist} | grep -v 'kube' &> /dev/null && sudo dnf provides ${plist} 2> /dev/null | grep 'Provide' | head -n 5 | cut -d '=' -f 2 | sed 's/^.//'"
          [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "echo ${plist} | grep 'kube' &> /dev/null && sudo dnf provides ${plist} --disableexcludes=kubernetes 2> /dev/null | grep 'Provide' | grep ${CRI_RELEASE} | cut -d '=' -f 2 | sed ':a;N;s/\n/ |/g;ta' | sed 's/^.//'"
          [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "echo ${plist} | grep -v 'kube' &> /dev/null && sudo dnf provides ${plist} 2> /dev/null | grep 'Provide' | head -n 5 | cut -d '=' -f 2 | sed 's/^.//'"
          [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "echo ${plist} | grep 'kube' &> /dev/null && sudo dnf provides ${plist} --disableexcludes=kubernetes 2> /dev/null | grep 'Provide' | grep ${CRI_RELEASE} | cut -d '=' -f 2 | sed ':a;N;s/\n/ |/g;ta' | sed 's/^.//'"
          [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "sudo apt-cache madison ${plist} | head -n 5"
        done; echo
  done
;;

pkg-repo) #Setup package repositories. [ add-all | add | remove ]
  [ -z ${2} ] && echo -e "${RED}Please input parameter. [ add-all | add | remove ]${NC}\n" && exit
  [ -z ${3} ] && node-message ${@} && exit

  node-selector ${@}

  message="${RED}Modify packages repository on nodes: ${YELLOW}${cp_nodes} ${wk_nodes}${NC}"
  interrupt ${message}

  if [ "${2}" == "add" ]
    then
      echo -e "${YELLOW}Prepare to add package repositories.${NC}"
      for cwlist in ${cp_nodes} ${wk_nodes}
        do
          echo -e "${YELLOW}${cwlist} | repositories procedure${NC}"
          pkg-repo-add && echo
        done
    elif [ "${2}" == "rm" ]
      then
        echo -e "${YELLOW}Prepare to remove package repositories.${NC}"
        for cwlist in ${cp_nodes} ${wk_nodes}
          do
            [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "ls /etc/yum.repos.d/devel:kubic* > /dev/null 2>&1" && ssh ${cwlist} "sudo rm /etc/yum.repos.d/devel:kubic*"
            [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo rm /etc/yum.repos.d/kubernetes* > /dev/null 2>&1"
            [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo dnf -y update --refresh" &> /dev/null
            [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && echo -e "${GREEN}${cwlist} package repositories has been removed${NC}"
            [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "ls /etc/yum.repos.d/devel:kubic* > /dev/null 2>&1" && ssh ${cwlist} "sudo rm /etc/yum.repos.d/devel:kubic*"
            [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "sudo rm /etc/yum.repos.d/kubernetes* > /dev/null 2>&1"
            [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "sudo dnf -y update --refresh" &> /dev/null
            [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && echo -e "${GREEN}${cwlist} package repositories has been removed${NC}"
            [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "ls /etc/apt/sources.list.d/* > /dev/null 2>&1" && ssh ${cwlist} "sudo rm /etc/apt/sources.list.d/*"
            [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "sudo apt-get -y update" &> /dev/null
            [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && echo -e "${GREEN}${cwlist} package repositories has been removed${NC}"
          done
  fi
;;

pkg-install) #Install basic package & setup environment.
  [ -z ${2} ] && node-message ${@} && exit

  check_list=${@}
  node-selector ${@}

  message="${RED}Install packages on nodes: ${YELLOW}${cp_nodes} ${wk_nodes}${NC}"
  interrupt ${message}; clear
  
  for cwlist in ${cp_nodes} ${wk_nodes}
    do
      echo -e "${YELLOW}${cwlist} | package install procedure${NC}"
      #swapoff
      ssh ${cwlist} "sudo swapoff -a" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && swap=1 && swap_list=$(echo ${cwlist} | cut -d '-' -f 2-3 | sed 's|-|--|g')
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "cat /etc/fstab | grep "/dev/mapper/rhel_rhel8--${swap_list}-swap"" &> /dev/null && swap=0
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && echo ${swap} | grep '1' &> /dev/null && ssh ${cwlist} "sudo sed -i '/swap/d' /etc/fstab"

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && swap=1
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "cat /etc/fstab | grep '#/dev/mapper/rl-swap'" &> /dev/null && swap=0
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && echo ${swap} | grep '1' &> /dev/null && ssh ${cwlist} "sudo sed -i 's|/dev/mapper/rl-swap|#/dev/mapper/rl-swap|g' /etc/fstab"
      
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && swap=1
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "ls -al /swap.img" &> /dev/null && ssh ${cwlist} "sudo rm /swap.img" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "cat /etc/fstab | grep '#/swap.img'" &> /dev/null && swap=0
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "sudo sed -i 's|/swap.img|#/swap.img|g' /etc/fstab" &> /dev/null
      
      ssh ${cwlist} "sudo swapon --show | grep '/dev'" &> /dev/null
      [ $? != 0 ] && echo -e " ${GREEN}●${NC} swap disabled" || echo -e " ${YELLOW}●${NC} swap not disable"

      #firewalld setup
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo dnf install -y iproute-tc &> /dev/null"

      # kubelet API | kube-scheduler | kube-controller-manager | NodePort Services | apply changes
      #[ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo firewall-cmd --permanent --add-port=6443/tcp &> /dev/null"
      #[ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo firewall-cmd --permanent --add-port=2379-2380/tcp &> /dev/null"
      #[ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo firewall-cmd --permanent --add-port=10250/tcp &> /dev/null"
      #[ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo firewall-cmd --permanent --add-port=10251/tcp &> /dev/null"
      #[ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo firewall-cmd --permanent --add-port=10252/tcp &> /dev/null"
      #[ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo firewall-cmd --reload &> /dev/null"

      #firewalld disable
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} 'sudo systemctl status firewalld | grep "active (running)"' &> /dev/null && status=1
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && echo ${status} | grep '1' &>/dev/null && ssh ${cwlist} "sudo systemctl disable firewalld --now" &> /dev/null && echo -e " ${GREEN}●${NC} firewalld disabled [ need reboot ]"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} 'sudo systemctl status firewalld | grep "active (running)"' &> /dev/null && status=1
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && echo ${status} | grep '1' &>/dev/null && ssh ${cwlist} "sudo systemctl disable firewalld --now" &> /dev/null && echo -e " ${GREEN}●${NC} firewalld disabled [ need reboot ]"
      #[ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} 'sudo systemctl status firewalld | grep "inactive (dead)"' &> /dev/null &&  echo -e " ${YELLOW}●${NC} firewalld not disable" 

      #SELinux setting
      status=0
      sed "/^SELINUX=/c\SELINUX=${SELINUX_MODE}"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo setenforce 0" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo sed -i "/^SELINUX=/c\SELINUX=${SELINUX_MODE}" /etc/selinux/config"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo nmcli connection modify ${KUBE_INTERFACE} ipv6.method ignore"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo sestatus | grep 'SELinux status:' | grep 'disabled'" &> /dev/null && echo -e " ${GREEN}●${NC} SELinux disabled" && status=1
      [ ${status} == 0 ] && [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo sestatus | grep 'SELinux status:' | grep 'enabled'" &> /dev/null && se_status=$(ssh ${cwlist} sudo sestatus | grep 'Current mode:' | awk '{ print $3 }') && echo -e " ${YELLOW}●${NC} SELinux mode: ${YELLOW}[ ${se_status} ]${NC}"

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "sudo setenforce 0" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "sudo sed -i "/^SELINUX=/c\SELINUX=${SELINUX_MODE}" /etc/selinux/config"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "sudo nmcli connection modify ${KUBE_INTERFACE} ipv6.method ignore"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "sudo sestatus | grep 'SELinux status:' | grep 'disabled'" &> /dev/null && echo -e " ${GREEN}●${NC} SELinux disabled"
      [ ${status} == 0 ] && [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "sudo sestatus | grep 'SELinux status:' | grep 'enabled'" &> /dev/null && se_status=$(ssh ${cwlist} sudo sestatus | grep 'Current mode:' | awk '{ print $3 }') && echo -e " ${YELLOW}●${NC} SELinux mode: ${YELLOW}[ ${se_status} ]${NC}"

      #modules setup
      modules=1
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo modprobe br_netfilter" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo modprobe overlay" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "cat /etc/modules-load.d/crio.conf | grep -E 'overlay|br_netfilter'" &> /dev/null && modules=0
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && echo "${modules}" | grep '1' &> /dev/null && ssh ${cwlist} "echo "overlay" | sudo tee -a /etc/modules-load.d/crio.conf" &> /dev/null && ssh ${cwlist} "echo "br_netfilter" | sudo tee -a /etc/modules-load.d/crio.conf" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "cat /etc/modules-load.d/crio.conf | grep -E 'overlay|br_netfilter'" &> /dev/null && echo -e " ${GREEN}●${NC} modules enabled [ br_netfilter | overlay ]"

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "sudo modprobe br_netfilter" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "sudo modprobe overlay" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "cat /etc/modules-load.d/crio.conf | grep -E 'overlay|br_netfilter'" &> /dev/null && modules=0
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && echo "${modules}" | grep '1' &> /dev/null && ssh ${cwlist} "echo "overlay" | sudo tee -a /etc/modules-load.d/crio.conf" &> /dev/null && ssh ${cwlist} "echo "br_netfilter" | sudo tee -a /etc/modules-load.d/crio.conf" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "cat /etc/modules-load.d/crio.conf | grep -E 'overlay|br_netfilter'" &> /dev/null && echo -e " ${GREEN}●${NC} modules enabled [ br_netfilter | overlay ]"
            
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "sudo modprobe br_netfilter" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "sudo modprobe overlay" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "cat /etc/modules | grep -E 'overlay|br_netfilter'" &> /dev/null && modules=0
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && echo "${modules}" | grep '1' &> /dev/null && ssh ${cwlist} "echo "overlay" | sudo tee -a /etc/modules" &> /dev/null && ssh ${cwlist} "echo "br_netfilter" | sudo tee -a /etc/modules" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "cat /etc/modules | grep -E 'overlay|br_netfilter'" &> /dev/null && echo -e " ${GREEN}●${NC} modules enabled [ br_netfilter | overlay ]"

      #ipv4_forward setup
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "sudo sed -i 's|#net.ipv4.ip_forward=1|net.ipv4.ip_forward = 1|g' /etc/sysctl.conf" &> /dev/null
      ssh ${cwlist} "cat /etc/sysctl.conf | grep 'net.ipv4.ip_forward = 1'" &> /dev/null
      [ $? != 0 ] && ssh ${cwlist} "echo "net.ipv4.ip_forward = 1" | sudo tee -a /etc/sysctl.conf" &> /dev/null
      ssh ${cwlist} "cat /etc/sysctl.conf | grep 'net.bridge.bridge-nf-call-iptables = 1'" &> /dev/null
      [ $? != 0 ] && ssh ${cwlist} "echo "net.bridge.bridge-nf-call-iptables = 1" | sudo tee -a /etc/sysctl.conf" &> /dev/null
      ssh ${cwlist} "cat /etc/sysctl.conf | grep 'net.ipv4.conf.default.rp_filter = 1'" &> /dev/null
      [ $? != 0 ] && ssh ${cwlist} "echo "net.ipv4.conf.default.rp_filter = 1" | sudo tee -a /etc/sysctl.conf" &> /dev/null
      ssh ${cwlist} "cat /etc/sysctl.conf | grep 'net.ipv4.conf.all.rp_filter = 1'" &> /dev/null
      [ $? != 0 ] && ssh ${cwlist} "echo "net.ipv4.conf.all.rp_filter = 1" | sudo tee -a /etc/sysctl.conf" &> /dev/null
      ssh ${cwlist} "sudo sysctl -p /etc/sysctl.conf" &> /dev/null
      echo -e " ${GREEN}●${NC} ipv4_forward enabled"

      #disable ipv6
      ssh ${cwlist} "cat /etc/sysctl.conf | grep 'net.ipv6.conf.all.disable_ipv6 = 1'" &> /dev/null
      [ $? != 0 ] && ssh ${cwlist} "echo "net.ipv6.conf.all.disable_ipv6 = 1" | sudo tee -a /etc/sysctl.conf" &> /dev/null
      ssh ${cwlist} "cat /etc/sysctl.conf | grep 'net.ipv6.conf.default.disable_ipv6 = 1'" &> /dev/null
      [ $? != 0 ] && ssh ${cwlist} "echo "net.ipv6.conf.default.disable_ipv6 = 1" | sudo tee -a /etc/sysctl.conf" &> /dev/null
      ssh ${cwlist} "sudo sysctl --system 2> /dev/null | grep 'net.ipv4.ip_forward'" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && echo -e " ${GREEN}●${NC} ipv6 disabled"

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} 'sed "s|GRUB_CMDLINE_LINUX=\"\"|GRUB_CMDLINE_LINUX=\"ipv6.disable=1\"|g" /etc/default/grub | sudo tee /etc/default/grub' &> /dev/null
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "sudo update-grub" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && echo -e " ${GREEN}●${NC} ipv6 disabled"

      #Add crio、kubernetes package repositories
      pkg-repo-add
      os-detection

      #install cri-o
      status=0
      CRI_PROVIDES=$(sudo dnf provides cri-o 2> /dev/null | grep 'Provide' | head -n 5 | cut -d '=' -f 2 | grep ${CRI_RELEASE} | head -n 1 | sed 's/^.//')

      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && [ "${VER_SWITCH}" == "sub" ] && ssh ${cwlist} "sudo dnf install -y cri-o-${CRI_SUBVER}-* crun cri-tools" > /dev/null 2>&1 && status=1
      [ "${status}" == "0" ] && ssh ${cwlist} "sudo dnf install -y cri-o-${CRI_PROVIDES} crun" > /dev/null 2>&1 && status=1
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && [ "${VER_SWITCH}" == "latest" ] && ssh ${cwlist} "sudo dnf install -y cri-o-${CRI_RELEASE}.* crun cri-tools" > /dev/null 2>&1

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && [ "${VER_SWITCH}" == "sub" ] && ssh ${cwlist} "sudo dnf install -y cri-o-${CRI_SUBVER}-* crun cri-tools" > /dev/null 2>&1 && status=1
      [ "${status}" == "0" ] && ssh ${cwlist} "sudo dnf install -y cri-o-${CRI_PROVIDES} crun" > /dev/null 2>&1 && status=1
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && [ "${VER_SWITCH}" == "latest" ] && ssh ${cwlist} "sudo dnf install -y cri-o-${CRI_RELEASE}.* crun cri-tools" > /dev/null 2>&1
      
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "sudo apt-get install -qy cri-o=${CRI_SUBVER}~* crun cri-tools" &> /dev/null && status=1
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "sudo apt-mark hold" &> /dev/null

      ssh ${cwlist} "sudo sed -i '/'1100:200'/d' /etc/cni/net.d/100-crio-bridge.conf" &> /dev/null
      ssh ${cwlist} "sudo sed -i 's|{ \"dst\": \"0.0.0.0/0\" },|{ \"dst\": \"0.0.0.0/0\" }|g' /etc/cni/net.d/100-crio-bridge.conf" &> /dev/null
      ssh ${cwlist} "sudo sed -i 's|\[{ \"subnet\": \"10.85.0.0/16\" }\],|\[{ \"subnet\": \"10.85.0.0/16\" }\]|g' /etc/cni/net.d/100-crio-bridge.conf" &> /dev/null
      crio-check ${cwlist}

      #setup /etc/crio/crio.conf
      ssh ${cwlist} cat /etc/crio/crio.conf 2> /dev/null | grep -A 3 "\[crio.runtime\]" | grep "conmon_cgroup = \"pod\"" &> /dev/null
      [ $? != 0 ] && ssh ${cwlist} "sudo sed -i 's/\[crio.runtime\]/\[crio.runtime\]\nconmon_cgroup = \"pod\"\ncgroup_manager = \"systemd\"\ndefault_runtime = \"crun\"/g' /etc/crio/crio.conf" &> /dev/null
      ssh ${cwlist} cat /etc/crio/crio.conf 2> /dev/null | grep -A 3 "\[crio.runtime.runtimes.crun\]" | grep "runtime_path = \"/usr/local/bin/crun\"" &> /dev/null #/usr/bin/crun
      [ $? != 0 ] && ssh ${cwlist} "sudo sed -i 's/# \[crio.runtime.runtimes.runc\]/\[crio.runtime.runtimes.crun\]\nruntime_path = \"\/usr\/bin\/crun\"\nruntime_type = \"oci\"\nruntime_root = \"\"/g' /etc/crio/crio.conf" &> /dev/null
      ssh ${cwlist} cat /etc/crio/crio.conf 2> /dev/null | grep -A 2 "\[crio.network\]" | grep "network_dir = \"/etc/cni/net.d/\"" &> /dev/null
      [ $? != 0 ] && ssh ${cwlist} "sudo sed -i 's/\[crio.network\]/\[crio.network\]\nnetwork_dir = \"\/etc\/cni\/net.d\/\"\nplugin_dir = \"\/opt\/cni\/bin\"/g' /etc/crio/crio.conf" &> /dev/null
      ssh ${cwlist} cat /etc/crio/crio.conf  > /dev/null 2>&1
      [ $? == 0 ] && echo -e " ${GREEN}●${NC} crio.conf configured" || echo -e " ${YELLOW}●${NC} crio.conf not exist"

      #Setup image repository policy
      ssh ${cwlist} 'sudo bash -c "cat << \EOF > /etc/containers/policy.json
{
    \"default\": [
        {
            \"type\": \"insecureAcceptAnything\"
        }
    ],
    \"transports\":
        {
            \"docker-daemon\":
                {
                    \"\": [{\"type\":\"insecureAcceptAnything\"}]
                }
        }
}
EOF"' &> /dev/null && echo -e " ${GREEN}●${NC} policy.json updated"

      #Kubernetes setup
      ssh ${cwlist} "sudo apt-get install -qy apt-transport-https --yes" &> /dev/null

      cri_current_ver=$(crio version 2>&1 | grep "^Version" | awk '{ print $2 }')
      sudo dnf provides kubectl --disableexcludes=kubernetes | grep 'Provide' | grep ${CRI_RELEASE} | cut -d '=' -f 2 | grep ${cri_current_ver} &> /dev/null
      [ $? == 0 ] && KUBE_SUBVER=${cri_current_ver}

      echo ${cwlist} | grep 'w' &> /dev/null
      [ $? == 0 ] && install="1" || install="0"
      if [ "${install}" == "1" ]
        then
          [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo dnf install -y kubelet-${KUBE_SUBVER}-* kubeadm-${KUBE_SUBVER}-* kubectl-${KUBE_SUBVER}-* --disableexcludes=kubernetes" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo dnf versionlock add kubelet kubeadm kubectl" &> /dev/null

          [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "sudo dnf install -y kubelet-${KUBE_SUBVER}-* kubeadm-${KUBE_SUBVER}-* kubectl-${KUBE_SUBVER}-* --disableexcludes=kubernetes" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "sudo dnf versionlock add kubelet kubeadm kubectl" &> /dev/null

          [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "sudo apt-get install -qy kubeadm=${KUBE_SUBVER}-* kubelet=${KUBE_SUBVER}-* kubectl=${KUBE_SUBVER}-*" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "sudo apt-mark hold kubeadm kubelet kubectl" &> /dev/null

          kubelet-check ${cwlist}
          kubeadm-check ${cwlist}
          kubectl-check ${cwlist}
      fi

      echo ${cwlist} | grep 'm' &> /dev/null
      [ $? == 0 ] && install="1" || install="0"
      if [ "${install}" == "1" ]
        then
          #install kube-package
          curl -s https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg | grep '<title>' | grep 'Error' &> /dev/null
          [ $? == 0 ] && echo -e " ${RED}●${NC} Google server rpm-pkg-key.gpg is missing"
          [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo dnf install -y kubelet-${KUBE_SUBVER}-* kubeadm-${KUBE_SUBVER}-* kubectl-${KUBE_SUBVER}-* --disableexcludes=kubernetes" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo dnf versionlock add kubelet kubeadm kubectl" &> /dev/null

          [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "sudo dnf install -y kubelet-${KUBE_SUBVER}-* kubeadm-${KUBE_SUBVER}-* kubectl-${KUBE_SUBVER}-* --disableexcludes=kubernetes" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "sudo dnf versionlock add kubelet kubeadm kubectl" &> /dev/null

          [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "sudo apt-get install -qy kubeadm=${KUBE_SUBVER}-* kubelet=${KUBE_SUBVER}-* kubectl=${KUBE_SUBVER}-*" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "sudo apt-mark hold kubeadm kubelet kubectl" &> /dev/null

          kubelet-check ${cwlist}
          kubeadm-check ${cwlist}
          kubectl-check ${cwlist}

          #install helm
          [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "bash <(wget -q -o /dev/null -O - get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3)" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "bash <(wget -q -o /dev/null -O - get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3)" &> /dev/null

          [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "sudo apt-get -qy update" &> /dev/null
          [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "sudo apt-get install -qy helm" &> /dev/null
          echo -e " ${GREEN}●${NC} helm installed"

          #install k9s
          ssh ${cwlist} "ls -al ~/bin/k9s" &> /dev/null
          [ $? == 0 ] && echo -e " ${GREEN}●${NC} k9s installed" && echo && continue || curl --max-time 5 -fsSLq https://webinstall.dev/api/installers/k9s@stable.sh &> /dev/null && ssh ${cwlist} "curl -sS https://webinstall.dev/k9s | bash" &> /dev/null
          #k9s path setup
          ssh ${cwlist} "mv ~/.local/bin/k9s ~/bin/" &> /dev/null
          ssh ${cwlist} "cat /etc/environment | grep "/home/${USER}/bin" &> /dev/null" &> /dev/null
          [ $? != 0 ] && ssh ${cwlist} "cat /etc/environment | tr -s ':' '\n' | sed 's/\/snap\/bin\"/\/snap\/bin\n\/home\/${USER}\/bin\"/g' | tr -s '\n' ':' | sed '$ s/.$//' | sudo tee /etc/environment &> /dev/null" &> /dev/null
          ssh ${cwlist} "cat /etc/profile | grep 'export EDITOR=nano' &> /dev/null" &> /dev/null
          [ $? != 0 ] && ssh ${cwlist} "echo "export EDITOR=nano" | sudo tee -a /etc/profile" &> /dev/null
          ssh ${cwlist} "cat /etc/profile | grep 'export K9S_EDITOR=nano' &> /dev/null" &> /dev/null
          [ $? != 0 ] && ssh ${cwlist} "echo "export K9S_EDITOR=nano" | sudo tee -a /etc/profile" &> /dev/null
          ssh ${cwlist} "rm -r ~/Downloads/" &> /dev/null

          ssh ${cwlist} "ls -al ~/bin/k9s" &> /dev/null
          [ $? == 0 ] && echo -e " ${GREEN}●${NC} k9s installed" || echo -e " ${RED}●${NC} k9s not install"
      fi
      #enable crio、kubelet
      daemon-enable ${cwlist}
      #install podman
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo dnf install -y podman" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "sudo dnf install -y podman" &> /dev/null

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "echo "deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/${CRIO_OS_VERSION}/ /" | sudo tee /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "curl -fsSL https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable/${CRIO_OS_VERSION}/Release.key | gpg --dearmor | sudo tee /etc/apt/trusted.gpg.d/devel_kubic_libcontainers_stable.gpg > /dev/null" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "sudo apt-get -qy update" &> /dev/null
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "sudo apt-get install -qy podman" &> /dev/null
      podman-check ${cwlist}
      echo
    done
  echo && echo -e "${YELLOW}Package Check list${NS}"
  pkg-check ${check_list} && echo
;;

pkg-rm) #Remove basic package & setup environment.
  [ -z ${2} ] && echo -e "Please input parameter.\n[ <hosts> | for all master node in /etc/hosts ]\n[ <node-name> ... ]\n" && exit

  node-selector ${@}

  message="${RED}Please confirm this command will destruction node:${YELLOW} ${cp_nodes} ${wk_nodes}!${NC}"
  interrupt ${message}

  echo -n "As you wish"; echo -n "."; sleep 0.5; echo -n "."; sleep 0.5; echo "."; sleep 0.5

  for clist in ${cp_nodes}
    do
      echo -e "\n${YELLOW}${clist} | package removing${NC}"
      ssh ${clist} "which k9s" &> /dev/null
      [ $? == 0 ] && ssh ${clist} "rm ~/bin/k9s"
      echo -en "${GREEN}"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${clist} "sudo dnf versionlock delete cri-o kubectl kubeadm kubelet podman"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${clist} "sudo systemctl disable --now cri-o"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${clist} "sudo systemctl disable --now kubelet"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${clist} "sudo dnf remove -y kubectl kubeadm kubelet"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${clist} "sudo dnf remove -y podman"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${clist} "sudo dnf remove -y cri-o cri-tools*"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${clist} "which crio &> /dev/null"
      [ $? == 0 ] && [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${clist} "sudo rm /usr/local/bin/crio"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${clist} 'sudo rm `which helm`' 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${clist} "sudo dnf autoremove -y"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${clist} "sudo systemctl daemon-reload"

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${clist} "sudo dnf versionlock delete cri-o kubectl kubeadm kubelet podman"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${clist} "sudo systemctl disable --now crio"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${clist} "sudo systemctl disable --now kubelet"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${clist} "sudo dnf remove -y kubectl kubeadm kubelet"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${clist} "sudo dnf remove -y podman"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${clist} "sudo dnf remove -y cri-o cri-tools*"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${clist} "which crio &> /dev/null"
      [ $? == 0 ] && [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${clist} "sudo rm /usr/local/bin/crio"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${clist} 'sudo rm `which helm`' 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${clist} "sudo dnf autoremove -y"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${clist} "sudo systemctl daemon-reload"

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${clist} "sudo apt-mark unhold kubeadm kubelet kubectl"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${clist} "sudo systemctl disable --now crio"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${clist} "sudo systemctl disable --now kubelet"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${clist} "sudo apt-get purge -qy --allow-change-held-packages kubectl kubeadm kubelet kubernetes-cni"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${clist} "sudo apt-get purge -qy --allow-change-held-packages cri-o cri-tools cri-o-runc"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${clist} "which crio &> /dev/null"
      [ $? == 0 ] && [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${clist} "sudo rm /usr/local/bin/crio"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${clist} "sudo apt-get purge -qy helm podman"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${clist} "sudo apt-get autoremove -qy"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${clist} "sudo systemctl daemon-reload"
      echo -en "${NC}"
      #empty=$(ssh ${clist} "ls /etc/apt/sources.list.d/ | wc -l 2> /dev/null")
      #[ ${empty} != 0 ] && ssh ${clist} "sudo rm /etc/apt/sources.list.d/*" || echo "Target has been removed: /etc/apt/sources.list.d/*"
    done

  for wlist in ${wk_nodes}
    do
      echo -e "\n${YELLOW}${wlist} | package removing${NC}"
      echo -en "${GREEN}"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf versionlock delete cri-o kubectl kubeadm kubelet podman"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo systemctl disable --now cri-o"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo systemctl disable --now kubelet"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf remove -y kubectl kubeadm kubelet"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf remove -y podman"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf remove -y cri-o cri-tools*"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "which crio &> /dev/null"
      [ $? == 0 ] && [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo rm /usr/local/bin/crio"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} 'sudo rm `which helm`' 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf autoremove -y"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo systemctl daemon-reload"

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf versionlock delete cri-o kubectl kubeadm kubelet podman"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo systemctl disable --now cri-o"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo systemctl disable --now kubelet"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf remove -y kubectl kubeadm kubelet"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf remove -y podman"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf remove -y cri-o cri-tools*"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "which crio &> /dev/null"
      [ $? == 0 ] && [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo rm /usr/local/bin/crio"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} 'sudo rm `which helm`' 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf autoremove -y"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo systemctl daemon-reload"

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-mark unhold kubeadm kubelet"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo systemctl disable --now crio"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo systemctl disable --now kubelet"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-get purge -qy --allow-change-held-packages kubectl kubeadm kubelet kubernetes-cni"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-get purge -qy --allow-change-held-packages cri-o cri-tools cri-o-runc podman"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "which crio &> /dev/null"
      [ $? == 0 ] && [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo rm /usr/local/bin/crio"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-get autoremove -qy"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo systemctl daemon-reload"
      echo -en "${NC}"
      #empty=$(ssh ${wlist} "ls /etc/apt/sources.list.d/ | wc -l 2> /dev/null")
      #[ ${empty} != 0 ] && ssh ${wlist} "sudo rm /etc/apt/sources.list.d/*" || echo "Target has been removed: /etc/apt/sources.list.d/*"
    done
  node-power reboot ${@}
;;

pkg-check) #Check node package status.
  pkg-check ${@}
;;

k9s-install) #Install k9s.
  for clist in ${CP_NODES}
    do
      #install k9s
      ssh ${clist} "ls -al ~/bin/k9s" &> /dev/null
      [ $? == 0 ] && echo "- ${clist} | k9s has been installed." && continue || ssh ${clist} "curl -sS https://webinstall.dev/k9s | timeout 20 bash" &> /dev/null
      #k9s path setup
      ssh ${clist} "mv ~/.local/bin/k9s ~/bin/" &> /dev/null
      ssh ${clist} "cat /etc/environment | grep "/home/${USER}/bin" &> /dev/null" &> /dev/null
      [ $? != 0 ] && ssh ${clist} "cat /etc/environment | tr -s ':' '\n' | sed 's/\/snap\/bin\"/\/snap\/bin\n\/home\/${USER}\/bin\"/g' | tr -s '\n' ':' | sed '$ s/.$//' | sudo tee /etc/environment &> /dev/null" &> /dev/null
      ssh ${clist} "cat /etc/profile | grep 'export EDITOR=nano' &> /dev/null" &> /dev/null
      [ $? != 0 ] && ssh ${clist} "echo "export EDITOR=nano" | sudo tee -a /etc/profile" &> /dev/null
      ssh ${clist} "cat /etc/profile | grep 'export K9S_EDITOR=nano' &> /dev/null" &> /dev/null
      [ $? != 0 ] && ssh ${clist} "echo "export K9S_EDITOR=nano" | sudo tee -a /etc/profile" &> /dev/null
      ssh ${clist} "rm -r ~/Downloads/" &> /dev/null
      ssh ${clist} "ls -al ~/bin/k9s" &> /dev/null
      [ $? == 0 ] && echo "${clist} | k9s installed"
    done; echo
;;

k9s-rm) #Delete k9s.
  for clist in ${CP_NODES}
    do
      #delete k9s
      ssh ${clist} "rm bin/k9s"
      echo "${clist} | k9s deleted"
    done; echo
;;

daemon-restart)
  [ -z ${2} ] && node-message ${@} && exit

  check_list=${@}
  node-selector ${@}

  message="${RED}Install packages on nodes: ${YELLOW}${cp_nodes} ${wk_nodes}${NC}"
  interrupt ${message}; clear

  for cwlist in ${wk_nodes} ${cp_nodes}
    do
      echo -e "${YELLOW}${cwlist} | daemon status${NC}"
      daemon-restart ${cwlist}
      echo
    done
;;

cp-init) #Init first control-plane node & deploy CNI. [ calico | flannel ]
  #KUBE_VIP setup
  [ ${#} != 2 ] && echo -e "${RED}Please input parameter after ${YELLOW}\"cp-init\" \n > [ calico | flannel ]${NC}\n" && exit
  echo "${2}" | grep -E 'calico|flannel' &> /dev/null
  [ $? != 0 ] && echo -e "${RED}Please input parameter after ${YELLOW}\"cp-init\" \n > [ calico | flannel ]${NC}\n" && exit

  message="${RED}Please confirm this command will initialize kubernetes via ${YELLOW}`hostname`.${NC}"
  interrupt ${message}

  ls /etc/kubernetes/manifests &> /dev/null 
  [ $? != 0 ] && sudo mkdir -p /etc/kubernetes/manifests
  wget -O - https://raw.githubusercontent.com/kube-vip/kube-vip/main/docs/manifests/v0.4.1/kube-vip-arp.yaml | sed "s|eth0|${KUBE_INTERFACE}|g" | sed "s|192.168.0.1|${KUBE_VIP}|g" | sed "s|imagePullPolicy\: Always|imagePullPolicy\: IfNotPresent|g" | sudo tee /etc/kubernetes/manifests/kube-vip-arp.yaml
  ls yaml &> /dev/null
  [ $? != 0 ] && mkdir yaml
  sudo cp /etc/kubernetes/manifests/kube-vip-arp.yaml yaml/
  sudo chown bigred:bigred yaml/kube-vip-arp.yaml
  
  KUBEADM_VER=$(kubeadm version -o yaml | grep "gitVersion:" | head -n 1 | awk '{ print $2 }' | sed 's|v||g')
  [ "${KUBE_INIT_VER}" != "${KUBEADM_VER}" ] && KUBE_INIT_VER=$(kubeadm version -o yaml | grep "gitVersion:" | head -n 1 | awk '{ print $2 }' | sed 's|v||g')

  # Kubernetes setup
  # calico service & pod network
  [ "${2}" == "calico" ] && export POD_CIDR=10.85.0.0/16
  [ "${2}" == "calico" ] && export SVC_CIDR=10.96.0.0/12
  #--image-repository=k8s.gcr.io
  [ "${2}" == "calico" ] && sudo kubeadm init --control-plane-endpoint=${KUBE_VIP}:6443 --pod-network-cidr=${POD_CIDR} --service-cidr=${SVC_CIDR} --service-dns-domain=k8s.org --cri-socket=/var/run/crio/crio.sock --upload-certs --kubernetes-version=${KUBE_INIT_VER} --v=5
  [ $? != 0 ] && [ "${2}" == "calico" ] && message="${RED}\nkubeadm init failure!${NC}" && interrupt ${message}
  [ "${2}" == "calico" ] && mkdir -p ${HOME}/.kube && sudo cp -i /etc/kubernetes/admin.conf ${HOME}/.kube/config && sudo chown $(id -u):$(id -g) ${HOME}/.kube/config
  [ "${2}" == "calico" ] && ls ${HOME}/.kube/config &> /dev/null
  #helm calico network
  [ "${2}" == "calico" ] && helm repo add projectcalico https://projectcalico.docs.tigera.io/charts
  [ "${2}" == "calico" ] && kubectl create namespace tigera-operator
  [ "${2}" == "calico" ] && helm install calico projectcalico/tigera-operator --version v3.24.1 --namespace tigera-operator
  #[ $? != 0 ] && echo -e "kubeadm init failure.\n" && exit

  # flannel service & pod network
  [ "${2}" == "flannel" ] && export POD_CIDR=10.244.0.0/16
  [ "${2}" == "flannel" ] && export SVC_CIDR=10.98.0.0/24
  #--image-repository=k8s.gcr.io
  [ "${2}" == "flannel" ] && sudo kubeadm init --control-plane-endpoint=${KUBE_VIP}:6443 --pod-network-cidr=${POD_CIDR} --service-cidr=${SVC_CIDR} --service-dns-domain=k8s.org --cri-socket=/var/run/crio/crio.sock --upload-certs --kubernetes-version=${KUBE_INIT_VER} --v=5
  [ $? != 0 ] && [ "${2}" == "flannel" ] && message="${RED}\nkubeadm init failure!${NC}" && interrupt ${message}
  [ "${2}" == "flannel" ] && mkdir -p ${HOME}/.kube && sudo cp -i /etc/kubernetes/admin.conf ${HOME}/.kube/config && sudo chown $(id -u):$(id -g) ${HOME}/.kube/config
  [ "${2}" == "flannel" ] && ls ${HOME}/.kube/config &> /dev/null
  [ "${2}" == "flannel" ] && kubectl apply -f https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/kube-flannel.yml
  #[ $? != 0 ] && echo -e "kubeadm init failure.\n" && exit
  echo -en "${GREEN}"

  #taint setup
  KUBE_CURRENT_VER=$(kubectl get nodes | grep "control-plane" | awk '{ print $5 }' | head -n 1)
  kubectl taint node `hostname` node-role.kubernetes.io/control-plane:NoSchedule-
  echo "${KUBE_CURRENT_VER}" | grep -E '1.25|1.26' &> /dev/null
  [ $? != 0 ] && kubectl taint node `hostname` node-role.kubernetes.io/master:NoSchedule-
  echo -en "${NC}"
  echo && k9s -c pods -A
;;

cp-join) # Let control-plane nodes join cluster. [ <hosts> | <node-name> ... ]
  [ -z ${2} ] && cp-node-message ${@} && exit

  node-selector ${@}

  if [ "${2}" == "hosts" ]
    then
      cluster_list=$(kubectl get nodes | tail -n +2 | awk '{ print $1 }' | tr -s '\n' '|' | sed '$ s/.$//')
      cp_nodes=$(echo -e "`cat /etc/hosts | grep -vE '#|ip6|k8s.org' | grep "${NETID}" | awk '{ print $2 }' | grep -vE ${cluster_list}| tr -s ' ' '\n' | grep "\-m" | tr -s '\n' ' '`\n")
      echo ${cp_nodes} | grep -n '^$' &> /dev/null && cp_nodes="none "
    else
      shift
      list="${@}"
      cp_nodes=$(echo "${list}" | tr -s ' ' '\n' | grep "\-m" | tr -s '\n' ' ')
  fi
  message="${RED}Please confirm this command will let ${YELLOW}${cp_nodes}${RED}join cluster!${NC}"
  interrupt ${message}
  [ "${cp_nodes}" == "none " ] && echo -e "${RED}Command canceled${NC}\n" && exit

  ls yaml &> /dev/null
  [ $? != 0 ] && mkdir yaml && cp /etc/kubernetes/manifests/kube-vip-arp.yaml yaml/

  certs=$(sudo kubeadm init phase upload-certs --upload-certs | tail -n 1)
  export JOIN=$(echo "sudo `kubeadm token create --print-join-command 2>/dev/null`")
  for clist in ${cp_nodes}
    do
      echo -e "${YELLOW}${clist} | join procedure${NC}"
      ssh ${clist} "ls yaml &> /dev/null"
      [ $? != 0 ] && ssh ${clist} "mkdir yaml"
      scp yaml/kube-vip-arp.yaml ${clist}:yaml/
      ssh ${clist} "${JOIN} --control-plane --certificate-key ${certs} --v=5"
      [ $? != 0 ] && message="${RED}\nkubeadm join failure!${NC}" && interrupt ${message}
      echo -en "${GREEN}"

      #taint setup
      kubectl taint node ${clist} node-role.kubernetes.io/control-plane:NoSchedule-
      KUBE_CURRENT_VER=$(kubectl get nodes | grep "control-plane" | awk '{ print $5 }' | head -n 1)
      echo "${KUBE_CURRENT_VER}" | grep -E '1.25|1.26' &> /dev/null
      [ $? != 0 ] && kubectl taint node `hostname` node-role.kubernetes.io/master:NoSchedule-

      echo -en "${NC}"
      ssh ${clist} "ls /etc/kubernetes/manifests" &> /dev/null
      [ $? != 0 ] && ssh ${clist} "sudo mkdir -p /etc/kubernetes/manifests"
      ssh ${clist} "sudo cp yaml/kube-vip-arp.yaml /etc/kubernetes/manifests/kube-vip-arp.yaml"
      ssh ${clist} "mkdir -p ${HOME}/.kube"
      scp .kube/config ${clist}:.kube/
    done; echo && k9s -c pods -A
;;

wk-join) #Let worker nodes join cluster. [ <hosts> | <node-name> ... ]
  [ -z ${2} ] && wk-node-message ${@} && exit
  if [ "${2}" == "hosts" ]
    then
      cluster_list=$(kubectl get nodes | tail -n +2 | awk '{ print $1 }' | tr -s '\n' '|' | sed '$ s/.$//')
      wk_nodes=$(echo -e "`cat /etc/hosts | grep -vE '#|ip6|k8s.org' | grep "${NETID}" | awk '{ print $2 }' | grep -vE ${cluster_list}| tr -s ' ' '\n' | grep "\-w" | tr -s '\n' ' '`\n")
      echo ${wk_nodes} | grep -n '^$' &> /dev/null && wk_nodes="none "
    else
      shift
      list="${@}"
      wk_nodes=$(echo "${list}" | tr -s ' ' '\n' | grep "\-m" | tr -s '\n' ' ')
  fi

  message="${RED}Please confirm this command will let ${YELLOW}${wk_nodes}${RED}join cluster!${NC}"
  interrupt ${message}
  [ "${wk_nodes}" == "none " ] && echo -e "${RED}Command canceled${NC}\n" && exit

  export JOIN=$(echo "sudo `kubeadm token create --print-join-command 2>/dev/null`")
  for wlist in ${wk_nodes}
    do
      echo -e "${YELLOW}${wlist} | join procedure${NC}"
      ssh ${wlist} "$JOIN --v=5"
      echo -en "${GREEN}"
      kubectl label node ${wlist} node-role.kubernetes.io/worker=
      echo -en "${NC}"
    done; echo && k9s -c pods -A
;;

cni-deploy) #Deploy kubernetes CNI. [ calico | flannel ]
  message="${RED}Please confirm there is no CNI running on kubernetes.${NC}"
  interrupt ${message}
  if [ -z ${2} ]
    then
      echo; echo -e "Please input cni project. [ calico | flannel ]\n"
    elif [ ${2} == "calico" ]
      then
        #helm calico network
        helm repo add projectcalico https://projectcalico.docs.tigera.io/charts
        kubectl create namespace tigera-operator
        helm install calico projectcalico/tigera-operator --version v3.24.1 --namespace tigera-operator
        k9s -n calico-system
    elif [ ${2} == "flannel" ]
      then
        #flannel network
        kubectl apply -f https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/kube-flannel.yml
        k9s -n kube-system
  fi
;;

cni-rm) #Delete kubernetes CNI. [ calico | flannel ]
  if [ -z ${2} ]
    then
      echo; echo -e "Please input cni project. [calico、flannel]\n"
    elif [ ${2} == "calico" ]
      then
        #helm calico network
        helm delete calico -n tigera-operator
        kubectl delete namespace tigera-operator
        helm repo remove projectcalico
    elif [ ${2} == "flannel" ]
      then
        #flannel network
        kubectl delete -f https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/kube-flannel.yml
        for cwlist in ${CP_NODES} ${WK_NODES}
          do
            ssh ${cwlist} "sudo rm /etc/cni/net.d/*flannel*"
          done
  fi
;;

dns-rollout) #Rollout coredns & calico-api-server. [ if pod present ]
  #rollout coredns/calico-apiserver
  kubectl rollout restart deployment/coredns -n kube-system &> /dev/null
  while true
    do
      kubectl get pods -n kube-system | grep 'coredns' | awk '{ print $3 }' | grep -v 'Running' &> /dev/null
      [ $? != 0 ] && break
    done
    echo -e " ${GREEN}●${NC} coredns rollout"

  kubectl get ns | grep 'calico-apiserver' &> /dev/null
  [ $? == 0 ] && kubectl rollout restart deployment/calico-apiserver -n calico-apiserver &> /dev/null || exit

  while true
    do
      kubectl get pods -n calico-apiserver | grep 'calico-apiserver' | awk '{ print $3 }' | grep -v 'Running' &> /dev/null
      [ $? != 0 ] && break
    done
    echo -e " ${GREEN}●${NC} calico-apiserver rollout"
;;

csi-deploy) #Deploy kubernetes CSI. [ local-path | rook-ceph ]
  if [ -z ${2} ]
    then
      echo -e "Please input csi project. [ local-path | rook-ceph ]\n"
    elif [ ${2} == "local-path" ]
      then
          #local-path-storage
          kubectl apply -f https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/local-path-storage.yaml
          while true
            do 
              kubectl get pods -n ${NAME_SPACE_1} | tail -n +2 | awk '{ print $3 }' | grep -v 'Running' &> /dev/null
              [ $? != 0 ] && break || clear
              kubectl get pods -n ${NAME_SPACE_1} | tail -n +2 | awk '{ print $2 }' | grep -v '1/1' &> /dev/null
              [ $? != 0 ] && break || clear
              echo -n "local-path-storage deploying"
              echo -n ".";sleep 0.5
              echo -n ".";sleep 0.5
              echo -n ".";sleep 0.5
              clear
            continue
            done
          echo "local-path-storage deployed!"; echo
    elif [ ${2} == "rook-ceph" ]
      then
        which git &> /dev/null
        [ $? != 0 ] && echo "install git" && sudo dnf install -y git && clear
        #helm repo add rook-release https://charts.rook.io/release
        ls yaml/rook/ &> /dev/null
        [ $? != 0 ] && mkdir yaml/rook/
        ls rook/ &> /dev/null
        [ $? == 0 ] && sudo rm -r ~/rook && git clone --single-branch --branch release-1.10 -b ${ROOK_TAG} https://github.com/rook/rook.git || git clone --single-branch --branch release-1.10 -b ${ROOK_TAG} https://github.com/rook/rook.git
        #copy
        cp ~/rook/deploy/examples/crds.yaml ~/yaml/rook/
        cp ~/rook/deploy/examples/common.yaml ~/yaml/rook/
        cp ~/rook/deploy/examples/operator.yaml ~/yaml/rook/
        cp ~/rook/deploy/examples/cluster.yaml ~/yaml/rook/
        cp ~/rook/deploy/examples/pool.yaml ~/yaml/rook/
        cp ~/rook/deploy/examples/toolbox.yaml ~/yaml/rook

        cp ~/rook/deploy/examples/csi/rbd/storageclass.yaml ~/yaml/rook/storageclass-block.yaml
        cp ~/rook/deploy/examples/csi/rbd/pvc.yaml ~/yaml/rook
        cp ~/rook/deploy/examples/filesystem.yaml ~/yaml/rook

        cp ~/rook/deploy/examples/csi/cephfs/storageclass.yaml ~/yaml/rook/storageclass-fs.yaml
        cp ~/rook/deploy/examples/csi/cephfs/pvc.yaml ~/yaml/rook/pvc-fs.yaml

        #if SELinux enabled, must be set this variable to true
        getenforce | grep -E 'Permissive|Enforcing' &> /dev/null
        [ $? == 0 ] && sed -i '/ROOK_HOSTPATH_REQUIRES_PRIVILEGED/{n;s/false/true/;}' ~/yaml/rook/operator.yaml
        cat ~/yaml/rook/operator.yaml | grep -A 1 'ROOK_HOSTPATH_REQUIRES_PRIVILEGED' | grep 'value: "true"' &> /dev/null
        [ $? != 0 ] && echo "~/yaml/rook/operator.yaml setting is Incorrect. " && exit
        
        #create
        echo -e "${YELLOW}crds applied${NC}"
        kubectl apply -f ~/yaml/rook/crds.yaml; sleep 2
        echo -e "${YELLOW}common applied${NC}"
        kubectl apply -f ~/yaml/rook/common.yaml; sleep 2
        echo -e "${YELLOW}operator applied${NC}"
        kubectl apply -f ~/yaml/rook/operator.yaml; sleep 2
        echo -e "${YELLOW}cluster applied${NC}"
        kubectl apply -f ~/yaml/rook/cluster.yaml; sleep 2
        echo -e "${YELLOW}pool applied${NC}"
        kubectl apply -f ~/yaml/rook/pool.yaml; sleep 2
        echo -e "${YELLOW}toolbox applied${NC}"
        kubectl apply -f ~/yaml/rook/toolbox.yaml; sleep 2

        echo -e "${YELLOW}storageclass-block applied${NC}"
        kubectl apply -f ~/yaml/rook/storageclass-block.yaml; sleep 2
        
        echo -e "${YELLOW}filesystem applied${NC}"
        kubectl apply -f ~/yaml/rook/filesystem.yaml; sleep 2
        
        echo -e "${YELLOW}storageclass-fs applied${NC}"
        kubectl apply -f ~/yaml/rook/storageclass-fs.yaml; sleep 2
        
        echo -e "${YELLOW}deshboard ingress applied${NC}"
        kubectl apply -f https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/ceph-deshboard.yaml
        
        echo -e "\n${YELLOW}rook-ceph deployed, please wait OSDs deploy.${NC}"
        sleep 3
        k9s -c pods -n ${NAME_SPACE_8}
  fi
;;

csi-rm) #Delete kubernetes CSI. [ local-path | rook-ceph ]
  if [ -z ${2} ]
    then
      echo -e "Please input csi project. [ local-path | rook-ceph ]\n"
    elif [ ${2} == "local-path" ]
      then
        message="${RED}Please confirm this command will destruction CSI ${YELLOW}${2} ${RED}!${NC}"
        interrupt ${message}
        #local-path-storage
        kubectl delete -f https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/local-path-storage.yaml
        while true
          do 
            kubectl get pods -n ${NAME_SPACE_1} | tail -n +2 | awk '{ print $3 }' | grep 'Terminating' &> /dev/null
            [ $? != 0 ] && break || clear
            echo -n "local-path-storage deleting"
            echo -n ".";sleep 0.5
            echo -n ".";sleep 0.5
            echo -n ".";sleep 0.5
            clear
          continue
          done
        echo "local-path-storage deleted."; echo
    elif [ ${2} == "rook-ceph" ]
      then
        message="${RED}Please confirm this command will destruction CSI ${YELLOW}${2} ${RED}!${NC}"
        interrupt ${message}
        kubectl -n ${NAME_SPACE_8} patch cephcluster rook-ceph --type merge -p '{"spec":{"cleanupPolicy":{"confirmation":"yes-really-destroy-data"}}}'
        kubectl delete CephBlockPool/replicapool -n ${NAME_SPACE_8}
        kubectl delete CephFilesystem/myfs -n ${NAME_SPACE_8}
        kubectl -n ${NAME_SPACE_8} delete cephcluster rook-ceph

        kubectl delete -f https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/ceph-deshboard.yaml
        kubectl delete -f ~/yaml/rook/storageclass.yaml
        kubectl delete -f ~/yaml/rook/toolbox.yaml; sleep 3
        kubectl delete -f ~/yaml/rook/operator.yaml; sleep 3
        kubectl delete -f ~/yaml/rook/common.yaml; sleep 3
        kubectl delete -f ~/yaml/rook/crds.yaml; sleep 3
        kubectl delete namespace rook-ceph
        kdm csi-rook wipe-data hosts /dev/sdb
  fi
;;

csi-rook) #Check rook status or DataDir. [ status | dashboard-pw | data-check | lvm-status | wipe-data ]
  if [ "$2" == "" ]
    then
      echo -e "${YELLOW}Please input parameter [ status | fix-mon | dashboard-pw | data-check | lvm-status | wipe-data ]${NC}"
  elif [ "$2" == "status" ]
    then
      #rook version
      ROOK_GIT_VER=$(kubectl -n ${NAME_SPACE_8} get jobs -o jsonpath='{range .items[*]}{.metadata.name}{"  \tsucceeded: "}{.status.succeeded}{"      \trook-version="}{.metadata.labels.rook-version}{"\n"}{end}' | awk '{ print $4 }' | cut -d '=' -f 2 | grep "^v" | head -n 1)
      POD_NAME=$(kubectl -n ${NAME_SPACE_8} get pod -o custom-columns=name:.metadata.name --no-headers | grep rook-ceph-mon-b)
      CEPH_IMAGE=$(kubectl -n ${NAME_SPACE_8} get pod ${POD_NAME} -o jsonpath='{.spec.containers[0].image}')
      kubectl -n ${NAME_SPACE_8} get pod -l "app=rook-ceph-tools" -o jsonpath='{.items[0].metadata.name}' > /dev/null 2>&1
      [ $? == 0 ] && CEPH_VER=$(echo -e "`kubectl -n ${NAME_SPACE_8} exec -it $(kubectl -n ${NAME_SPACE_8} get pod -l "app=rook-ceph-tools" -o jsonpath='{.items[0].metadata.name}') -- ceph --version | awk '{ print $3 }'`\n")
      
      echo -e "${RED}Rook-ceph git release: ${ROOK_GIT_VER}\nceph version: ${CEPH_VER} | image: ${CEPH_IMAGE}${GREEN}\n"
      
      #rook status
      [ $? == 0 ] && kubectl -n ${NAME_SPACE_8} exec -it $(kubectl -n ${NAME_SPACE_8} get pod -l "app=rook-ceph-tools" -o jsonpath='{.items[0].metadata.name}') -- ceph -s || echo -e "- rook-ceph not detected\n"
      echo -en "${NC}"
      echo -en "${YELLOW}"
      kubectl -n ${NAME_SPACE_8} get pod -l "app=rook-ceph-tools" -o jsonpath='{.items[0].metadata.name}' > /dev/null 2>&1
      [ $? == 0 ] && kubectl -n ${NAME_SPACE_8} exec -it $(kubectl -n ${NAME_SPACE_8} get pod -l "app=rook-ceph-tools" -o jsonpath='{.items[0].metadata.name}') -- ceph osd status || echo -e "- rook-ceph not detected\n"
      echo -en "${NC}"
  elif [ "$2" == "fix-mon" ]
    then
      kubectl get ConfigMap rook-config-override -n ${NAME_SPACE_8} -o yaml | sed 's/""/| /g' | sed 's/config: | /config: |\n    [global]\n    mon clock drift allowed = 0.5/g' > yaml/rook/rook-config-override.yaml
      kubectl replace -f yaml/rook/rook-config-override.yaml --force
      kubectl delete pods -n ${NAME_SPACE_8} $(kubectl get pods -n ${NAME_SPACE_8} -o custom-columns=NAME:.metadata.name --no-headers | grep 'mon')
  elif [ "$2" == "dashboard-pw" ]
    then
      kubectl -n ${NAME_SPACE_8} get pod -l "app=rook-ceph-tools" -o jsonpath='{.items[0].metadata.name}' > /dev/null 2>&1
      [ $? == 0 ] && echo -e "`kubectl -n ${NAME_SPACE_8} get secret rook-ceph-dashboard-password -o jsonpath="{['data']['password']}" | base64 --decode`\n" || echo -e "- rook-ceph not detected\n"
  elif [ "$2" == "data-check" ]
    then
      for cwlist in ${CP_NODES} ${WK_NODES};
        do
          echo "${cwlist} | Rook DataDir checking"
          ssh ${cwlist} ls /var/lib/rook &> /dev/null
          [ $? == 0 ] && echo -e "Directory exist\n" || echo -e "- Directory not exist\n"
        done
  elif [ "$2" == "lvm-status" ]
    then
      for wlist in ${CP_NODES} ${WK_NODES};
        do
          echo "${wlist} | Node lvm-status"
          ssh ${wlist} sudo pvscan
          #[ $? == 0 ] && echo "rook-ceph signature has wiped" || echo "- rook-ceph signature not found"
          echo
        done
  elif [ "$2" == "wipe-data" ]
    then
      node-selector ${@}
      message="${RED}Please confirm this command will destruction rook!${NC}"
      interrupt ${message}
      echo -e "${YELLOW}Rook data wipe procedure${NC}"
      for wlist in ${wk_nodes};
        do
          ssh ${wlist} sudo wipefs -a ${CEPH_DISK} &> /dev/null
          [ $? == 0 ] && echo -e "${GREEN}${wlist} ${CEPH_DISK} signature has been wiped" || echo " > ${wlist} ${CEPH_DISK} signature not found"
          ssh ${wlist} "sudo sgdisk --zap-all ${CEPH_DISK}" &> /dev/null
          [ $? == 0 ] && echo -e "${GREEN}${wlist} ${CEPH_DISK} GPT data structures destroyed!" || echo " > ${wlist} ${CEPH_DISK} GPT data structures not changed!"
          ssh ${wlist} "sudo dd if=/dev/zero of="${CEPH_DISK}" bs=1M count=100 oflag=direct,dsync" &> /dev/null
          [ $? == 0 ] && echo -e "${GREEN}${wlist} ${CEPH_DISK} has been overwrite by /dev/zero" || echo " > ${wlist} ${CEPH_DISK} not overwrite!"
          ssh ${wlist} "sudo partprobe ${CEPH_DISK}" &> /dev/null
          ssh ${wlist} "sudo blkdiscard ${CEPH_DISK}" &> /dev/null
        done

      for cwlist in ${wk_nodes} ${cp_nodes};
        do
          ssh ${cwlist} sudo rm -r /var/lib/rook/ &> /dev/null
          [ $? == 0 ] && echo " > ${cwlist} Directory has been cleanup" || echo " > ${cwlist} Directory not found"
        done
  fi
  echo
;;

controller-deploy) #Deploy basic service. [ metallb & nginx-ingress | Detect NETID just input xxx xxx ]
  if [ -z ${2} ]
    then

      echo; echo -e "Please input parameter.\n"
      echo -e "controller: Setup basic service. [ metallb & ingress ] [ Automatic select networkID, package <Start> <End> ]\n"

  elif [ -z ${3} ]
    then
      echo; echo -e "Please input parameter.\n"
      echo -e "controller: Setup basic service. [ metallb & ingress ] [ Automatic select networkID, package <Start> <End> ]\n"

    else
      for cwlist in ${CP_NODES} ${WK_NODES}
        do
          ssh ${cwlist} cat /etc/hosts | grep "${NETID}.${2}"
          [ $? != 0 ] && ssh ${cwlist} "echo "${NETID}.${2} quay.k8s.org jenkins.k8s.org gf.k8s.org kg.k8s.org" | sudo tee -a /etc/hosts"
        done
      #metallb-system
      kubectl apply -f https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/metallb-namespace.yaml
      kubectl apply -f https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/metallb.yaml
      curl -s https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/metallb-ConfigMap.yaml | sed "s/NETID/${NETID}/g" | sed "s/START/${2}/g" | sed "s/END/${3}/g" | kubectl apply -f - 
      while true
        do  
          kubectl get pods -n ${NAME_SPACE_2} | tail -n +2 | awk '{ print $3 }' | grep -v 'Running' &> /dev/null
          [ $? != 0 ] && break || clear
          kubectl get pods -n ${NAME_SPACE_2} | tail -n +2 | awk '{ print $2 }' | grep -v '1/1' &> /dev/null
          [ $? != 0 ] && break || clear
          echo -n "metallb deploying"
          echo -n ".";sleep 0.5
          echo -n ".";sleep 0.5
          echo -n ".";sleep 0.5
          clear
          continue
        done
        echo "metallb deployed!"; echo

      #ingress-nginx
      kubectl apply -f https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/ingress-deploy.yaml
      while true
        do
          kubectl get pods -n ${NAME_SPACE_3} | tail -n +2 | awk '{ print $3 }' | grep -vE 'Running|Completed' &> /dev/null
          [ $? != 0 ] && break || clear
          echo -n "ingress-nginx deploying"
          echo -n ".";sleep 0.5
          echo -n ".";sleep 0.5
          echo -n ".";sleep 0.5
          clear
          continue
        done
      echo "ingress-nginx deployed!"; echo

  fi
;;

controller-rm) #Delete basic service. [ metallb & nginx-ingress ]
  #ingress-nginx
  kubectl delete -f https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/ingress-deploy.yaml
  #metallb-system
  curl -s https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/metallb-ConfigMap.yaml | sed "s/NETID/${NETID}/g" | sed "s/START/${2}/g" | sed "s/END/${3}/g" | kubectl delete -f -
  kubectl delete -f https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/metallb.yaml
  kubectl delete -f https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/metallb-namespace.yaml
;;

metrics-deploy) #Deploy metrics-server.
  #HA Version via helm
  helm repo add metrics-server https://kubernetes-sigs.github.io/metrics-server/
  helm install metrics-server metrics-server/metrics-server --set 'args={--kubelet-insecure-tls}' --version 3.8.2 --namespace kube-system
  kubectl scale deploy/metrics-server --replicas=2 -n kube-system
  #Single node via yaml
  #wget -O - https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml | tee yaml/metrics.yaml &> /dev/null
  #HA Version via yaml
  #wget -O - https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/high-availability.yaml | tee yaml/metrics.yaml &> /dev/null
  #sed -i 's|        \- \-\-metric-resolution=15s|        - --metric-resolution=15s\n        - --kubelet-insecure-tls|g' yaml/metrics.yaml
  #kubectl apply -f yaml/metrics.yaml
;;

metrics-rm) #Delete metrics-server.
  helm delete metrics-server -n kube-system
  helm repo remove metrics-server
  #kubectl delete -f yaml/metrics.yaml
;;

prometheus-deploy) #Deploy prometheus.
  #追加並更新 helm repository
  helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
  helm repo update

  #部署 operator 並驗證
  helm install kube-prometheus-stack prometheus-community/kube-prometheus-stack --namespace monitoring --create-namespace
;;

prometheus-rm) #Delete prometheus.
  helm delete kube-prometheus-stack -n monitoring
  helm repo remove prometheus-community
  helm repo update
;;

jenkins-deploy) #Deploy jenkins on kubernetes.
  kubectl create ns ${NAME_SPACE_4}
  kubectl create secret generic kubeconfig --from-file=/home/bigred/.kube/config -n ${NAME_SPACE_4}
  #kubectl apply -f https://web.flymks.com/cicd/v1/jenkins.yaml
  curl -s https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/jenkins.yaml | sed 's/<image-name>/docker.io\/jenkins\/jenkins/g' | kubectl apply -f -
  k9s -c pods -n ${NAME_SPACE_4}
  kubectl get pods -n ${NAME_SPACE_4} | tail -n +2 | awk '{ print $3 }' | grep -v 'Running' &> /dev/null
  [ $? != 0 ] && echo -e "${YELLOW}Jenkins deployed!${NC}" || echo -e "${RED}Jenkins not deploy!${NC}"
;;

jenkins-rm) #Delete jenkins on kubernetes.
  kubectl delete -f https://web.flymks.com/cicd/v1/jenkins.yaml
  kubectl delete ns ${NAME_SPACE_4}
  kubectl delete secret generic kubeconfig --from-file=/home/bigred/.kube/config -n jenkins
;;

quay-deploy) #Deploy project-quay on kubernetes.
  #quay
  kubectl create ns ${NAME_SPACE_5}
  #kubectl apply -f https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/quay.yaml
  curl -s https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/quay.yaml | sed "s/<storageclass>/${STORAGE_CLASS}/g" | kubectl apply -f -
  k9s -c pods -n ${NAME_SPACE_5}
  kubectl get pods -n ${NAME_SPACE_5} | tail -n +2 | awk '{ print $3 }' | grep -v 'Running' &> /dev/null
  [ $? != 0 ] && echo -e "${YELLOW}Project Quay deployed!${NC}" || echo -e "${RED}Project Quay not deploy!${NC}"
;;

quay-rm) #Delete project-quay on kubernetes.
  kubectl delete -f https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/quay.yaml
  kubectl delete ns ${NAME_SPACE_5}
;;

grafana-deploy) #Deploy grafana on kubernetes.
  #gf
  kubectl create ns ${NAME_SPACE_6}
  #kubectl apply -f https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/grafana.yaml
  curl -s https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/grafana.yaml | sed "s/<storageclass>/${STORAGE_CLASS}/g" | kubectl apply -f -
  k9s -c pods -n ${NAME_SPACE_6}
  kubectl get pods -n ${NAME_SPACE_6} | tail -n +2 | awk '{ print $3 }' | grep -v 'Running' &> /dev/null
  [ $? != 0 ] && echo -e "${YELLOW}Grafana deployed!${NC}" || echo -e "${RED}Grafana not deploy!${NC}"
;;

grafana-rm) #Delete grafana on kubernetes.
  #grafana
  kubectl delete -f https://web.flymks.com/grafana/v1/grafana.yaml
  kubectl delete ns ${NAME_SPACE_6}
;;

landlord-deploy) #Deploy landlord on kubernetes.
  #ns & configmap
  kubectl create ns landlord
  kubectl create -n landlord configmap kuser-conf --from-file /home/bigred/.kube/config

  #PVC
  #kubectl apply -f https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/2-landlord-PVC.yaml
  curl -s https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/2-landlord-PVC.yaml | sed "s/<storageclass>/${STORAGE_CLASS}/g" | kubectl apply -f -
  echo "landlord PVC deployed!"; echo

  #service
  #kubectl apply -f https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/1-landlord-service.yaml
  curl -s https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/1-landlord-service.yaml | kubectl apply -f -
  k9s -c svc -n ${NAME_SPACE_7}
  kubectl get svc -n ${NAME_SPACE_7} | tail -n +2 | tr -s ' ' | cut -d ' ' -f 2 | grep -vE 'LoadBalancer|ClusterIP' &> /dev/null

  #gateway
  #kubectl apply -f https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/3-landlord-gateway.yaml
  curl -s https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/3-landlord-gateway.yaml | kubectl apply -f -
  k9s -c pods -n ${NAME_SPACE_7}
  kubectl get pods -n ${NAME_SPACE_7} | tail -n +2 | awk '{ print $3 }' | grep -v 'Running' &> /dev/null
  [ $? != 0 ] && echo -e "${YELLOW}gateway deployed!${NC}" || echo -e "${RED}gateway not deploy!${NC}"

  #kuser
  #kubectl apply -f https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/4-landlord-kuser.yaml
  curl -s https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/4-landlord-kuser.yaml | kubectl apply -f -
  k9s -c pods -n ${NAME_SPACE_7}
  kubectl get pods -n ${NAME_SPACE_7} | tail -n +2 | awk '{ print $3 }' | grep -v 'Running' &> /dev/null
  [ $? != 0 ] && echo -e "${YELLOW}kuser deployed!${NC}" || echo -e "${RED}kuser not deploy!${NC}"

  #logger
  #kubectl apply -f https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/5-landlord-logger.yaml
  curl -s https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/5-landlord-logger.yaml | kubectl apply -f -
  k9s -c pods -n ${NAME_SPACE_7}
  kubectl get pods -n ${NAME_SPACE_7} | tail -n +2 | awk '{ print $3 }' | grep -v 'Running' &> /dev/null
  [ $? != 0 ] && echo -e "${YELLOW}logger deployed!${NC}" || echo -e "${RED}logger not deploy!${NC}"

  #mariadb
  #kubectl apply -f https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/6-landlord-mariadb.yaml
  curl -s https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/6-landlord-mariadb.yaml | kubectl apply -f -
  k9s -c pods -n ${NAME_SPACE_7}
  kubectl get pods -n ${NAME_SPACE_7} | tail -n +2 | awk '{ print $3 }' | grep -v 'Running' &> /dev/null
  [ $? != 0 ] && echo -e "${YELLOW}mariadb deployed!${NC}" || echo -e "${RED}mariadb not deploy!${NC}"

  #tenant
  #kubectl apply -f https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/7-landlord-tenant.yaml
  curl -s https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/7-landlord-tenant.yaml | sed "s/<storageclass>/${STORAGE_CLASS}/g" | kubectl apply -f -
  k9s -c pods -n ${NAME_SPACE_7}
  kubectl get pods -n ${NAME_SPACE_7} | tail -n +2 | awk '{ print $3 }' | grep -v 'Running' &> /dev/null
  [ $? != 0 ] && echo -e "${YELLOW}tenant deployed!${NC}" || echo -e "${RED}tenant not deploy!${NC}"
;;

landlord-rm) #Delete landlorsd on kubernetes.
  #tenant
  curl -s https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/7-landlord-tenant.yaml | sed "s/<storageclass>/${STORAGE_CLASS}/g" | kubectl delete -f -
  #mariadb
  curl -s https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/6-landlord-mariadb.yaml | kubectl delete -f -
  #logger
  curl -s https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/5-landlord-logger.yaml | kubectl delete -f -
  #kuser
  curl -s https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/4-landlord-kuser.yaml | kubectl delete -f -
  #gateway
  curl -s https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/3-landlord-gateway.yaml | kubectl delete -f -
  #PVC
  curl -s https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/2-landlord-PVC.yaml | sed "s/<storageclass>/${STORAGE_CLASS}/g" | kubectl delete -f -
  #service
  curl -s https://raw.githubusercontent.com/Happylasky/Kubernetes-yaml/main/1-landlord-service.yaml | kubectl delete -f -
  #configmap & namespace
  kubectl delete -n ${NAME_SPACE_7} configmap kuser-conf
  kubectl delete ns ${NAME_SPACE_7}
;;

nodes) #Check all nodes status.
  nc -z -w 1 ${IP} 10250 > /dev/null 2>&1
  [ $? == 0 ] && k9s -c nodes || echo -e " ${YELLOW}●${NC} This node not activate."
;;

pods) #Check all pods status.
  nc -z -w 1 ${IP} 10250 > /dev/null 2>&1
  [ $? == 0 ] && k9s -c pods -A || echo -e " ${YELLOW}●${NC} This node not activate."
;;

images) #Check cluster images.
  [ -z ${2} ] && node-message ${@} && exit
  node-selector ${@}
  for cwlist in ${cp_nodes} ${wk_nodes}
    do
      echo -en "${YELLOW}${cwlist} | images list${NC} | quantity: "
      ssh ${cwlist} sudo podman images | grep -v 'REPOSITORY' | wc -l
      ssh ${cwlist} 'sudo podman images'
      echo
    done
;;

image-send) #save >> scp >> load target image to every worker node [ <image-name> <name.tar> ]
  image=$(echo ${2} | cut -d ":" -f 1)
  sudo podman images | grep "${image}"
  [ $? != 0 ] && sudo podman pull ${2} || echo "Image is already exists."
  sudo podman save ${2} > ~/${3} 2> /dev/null
  for cwlist in ${ALL_NODES_EX_LOCALHOST}
    do
      scp ~/${3} ${cwlist}:
      ssh ${cwlist} "sudo podman rmi ${2} 2> /dev/null"
      ssh ${cwlist} "sudo podman load < ~/${3} 2> /dev/null"
      ssh ${cwlist} "rm ~/${3}"
    done
  rm ./${3}
;;

image-rm) #Remove dangling images on cluster.
  [ -z ${2} ] && node-message ${@} && exit
  node-selector ${@}
  message="${RED}Please confirm this command will delete unuse images on node:${YELLOW} ${cp_nodes} ${wk_nodes}${RED}!${NC}"
  interrupt ${message}
  for cwlist in ${cp_nodes} ${wk_nodes}
    do
      ssh ${cwlist} 'sudo podman image prune -f'
      ssh ${cwlist} 'sudo podman rmi -a &> /dev/null'
      echo -en "${YELLOW}${cwlist} | in-use images list${NC} | quantity: "
      ssh ${cwlist} sudo podman images | grep -v 'REPOSITORY' | wc -l
      ssh ${cwlist} 'sudo podman images'
      echo
    done
;;

helm-repo) #Check helm repository.
  [ -z ${2} ] && echo -e "${RED}Please input parameter after ${YELLOW}\"helm-repo\" \n > [ update | check ]${NC}\n" && exit
  node-selector hosts
  [ "${2}" == "update" ] && helm-repo-update
  [ "${2}" == "check" ] && helm-repo-check
  [ "${2}" == "add" ] && helm-repo-add
;;

cluster-info) #Check kubernetes cluster info.
  if [ "${2}" == "cidr" ]
    then
      kubectl get node > /dev/null 2>&1
      [ $? == 0 ] && echo -e "${YELLOW}POD-CIDR: ${RED}`kubectl cluster-info dump -o yaml | grep -m 1 cluster-cidr | cut -d '=' -f 2`${NC}" || echo "- This node not join Kubernetes"
      kubectl get node > /dev/null 2>&1
      [ $? == 0 ] && echo -e "${YELLOW}SVC-CIDR: ${RED}`kubectl cluster-info dump -o yaml | grep -m 1 service-cluster | cut -d '=' -f 2`${NC}" || echo "- This node not join Kubernetes"
  elif [ "${2}" == "taints" ]
    then
      for kube_node in $(kubectl get nodes | awk '{ print $1 }' | tail -n +2);
        do
          role=$(kubectl describe node $kube_node | grep 'Roles' | awk '{ print $2 }')
          echo -en "${YELLOW}${kube_node}: ${RED}${role}"
          echo -e "${NC} |" $(kubectl describe node ${kube_node} | grep Taint)
        done
  elif [ "${2}" == "etcd" ]
    then
      etcd_pod=$(kubectl get pods -n kube-system | grep 'etcd' | awk '{ print $1 }' | head -n 1)
      etcd_endpoints=$(echo ${etcd_pod} | cut -d '-' -f 2)
      kubectl exec -it ${etcd_pod} -n kube-system -- etcdctl --endpoints ${NETID}.${etcd_endpoints}:2379 --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key --cacert=/etc/kubernetes/pki/etcd/ca.crt member list
      echo
  elif [ "${2}" == "all" ]
    then
      kdm cluster-info cidr
      kdm cluster-info taints
      kdm cluster-info etcd
    else
      echo -e "${RED}Please input parameter after \"taints\" \n ${YELLOW}> [ cidr | taints | etcd | all ]${NC}"
  fi
;;

cluster-upgrade) #Upgrade cluster [ upgrade kubeadm、kubectl、kubelet、crio ]
  [ -z ${2} ] && node-selector hosts || node-selector ${@}

  #Exclude non-join nodes
  exclude-non-join

  message="${RED}Please confirm this command will upgrade nodes to ${KUBE_INIT_VER}: ${YELLOW}${cp_nodes} ${wk_nodes}!${NC}"
  interrupt ${message}

  first_control_plane=`hostname`
  other_control_plane=$(echo "${cp_nodes} ${wk_nodes}" | tr -s ' ' '\n' | sed "/`hostname`/d" | grep '\-m' | tr -s '\n' ' ')
  export CURRENT_VER=$(kubectl get nodes | grep `hostname` | awk '{ print $ 5}')

  for checklist in ${first_control_plane} ${other_control_plane} ${wk_nodes}
    do
      CHECK_VER=$(kubectl get nodes | grep ${checklist} | awk '{ print $ 5}')
      echo "${CHECK_VER}" | grep ${KUBE_INIT_VER} &> /dev/null
      [ $? == 0 ] && status=0 || status=1
      [ "${status}" == "0" ] && echo -e "${YELLOW}${checklist} version is already been ${RED}${KUBE_INIT_VER}${NC}"
      [ "${status}" == "1" ] && echo -e "${GREEN}${checklist} Upgrade version checked: ${RED}${CHECK_VER} >> ${KUBE_INIT_VER}${NC}"
    done
  [ "${status}" == "0" ] && echo && exit

  #[ -z ${2} ] && kdm pkg-repo add hosts || kdm pkg-repo add ${cp_nodes} ${wk_nodes}
  kdm pkg-repo add ${cp_nodes} ${wk_nodes}
  os-detection

  message="${RED}Start upgrade procedure?${NC}"
  interrupt ${message}

  for FCP in ${first_control_plane}
    do
      if [ "${KUBE_INIT_VER}" == "${CURRENT_VER}" ]
        then
          echo -e "${YELLOW}Cluster upgrade procedure${NC}"
          echo ${cp_nodes} ${wk_nodes} | grep `hostname` &> /dev/null
          [ $? == 0 ] && echo -e "${YELLOW} - ${first_control_plane} version is already been ${RED}${KUBE_INIT_VER}${NC}"
          continue
      fi
      echo -e "${YELLOW}${FCP} | upgrade procedure${NC}"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${FCP} "sudo dnf versionlock delete kubeadm"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${FCP} "sudo dnf install -y kubeadm-${KUBE_SUBVER} --disableexcludes=kubernetes" 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${FCP} "sudo dnf versionlock add kubeadm"

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${FCP} "sudo dnf versionlock delete kubeadm"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${FCP} "sudo dnf install -y kubeadm-${KUBE_SUBVER} --disableexcludes=kubernetes" 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${FCP} "sudo dnf versionlock add kubeadm"

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${FCP} "sudo apt-mark unhold kubeadm"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${FCP} "sudo apt-get install -qy kubeadm=${KUBE_SUBVER}-*"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${FCP} "sudo apt-mark hold kubeadm"

      ssh ${FCP} "sudo kubeadm upgrade plan ${KUBE_INIT_VER}"
      ssh ${FCP} "sudo kubeadm upgrade apply --force ${KUBE_INIT_VER}" #sudo kubeadm upgrade node

      kubectl drain ${FCP} --ignore-daemonsets

      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${FCP} "sudo dnf versionlock delete kubelet kubectl"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${FCP} "sudo dnf install -y kubelet-${KUBE_SUBVER} kubectl-${KUBE_SUBVER} --disableexcludes=kubernetes" 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${FCP} "sudo dnf versionlock add kubelet kubectl"

    status=0
    CRI_PROVIDES=$(sudo dnf provides cri-o 2> /dev/null | grep 'Provide' | head -n 5 | cut -d '=' -f 2 | grep ${CRI_RELEASE} | head -n 1)

      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${FCP} "sudo dnf versionlock delete cri-o"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && [ "${VER_SWITCH}" == "sub" ] && ssh ${FCP} "sudo dnf install -y cri-o-${CRI_SUBVER}-* crun" > /dev/null 2>&1 && status=1
      [ "${status}" == "0" ] && ssh ${FCP} "sudo dnf install -y cri-o-${CRI_PROVIDES} crun" > /dev/null 2>&1 && status=1
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && [ "${VER_SWITCH}" == "latest" ] && ssh ${FCP} "sudo dnf install -y cri-o-${CRI_RELEASE}.* crun" > /dev/null 2>&1
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${FCP} "sudo dnf versionlock add cri-o"

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${FCP} "sudo dnf versionlock delete kubelet kubectl"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${FCP} "sudo dnf install -y kubelet-${KUBE_SUBVER} kubectl-${KUBE_SUBVER} --disableexcludes=kubernetes" 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${FCP} "sudo dnf versionlock add kubelet kubectl"

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${FCP} "sudo dnf versionlock delete cri-o"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && [ "${VER_SWITCH}" == "sub" ] && ssh ${FCP} "sudo dnf install -y cri-o-${CRI_SUBVER}-* crun" > /dev/null 2>&1 && status=1
      [ "${status}" == "0" ] && ssh ${FCP} "sudo dnf install -y cri-o-${CRI_PROVIDES} crun" > /dev/null 2>&1 && status=1
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && [ "${VER_SWITCH}" == "latest" ] && ssh ${FCP} "sudo dnf install -y cri-o-${CRI_RELEASE}.* crun" > /dev/null 2>&1
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${FCP} "sudo dnf versionlock add cri-o"

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${FCP} "sudo apt-mark unhold kubelet kubectl"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${FCP} "sudo apt-get install -qy kubelet=${KUBE_SUBVER}-* kubectl=${KUBE_SUBVER}-*"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${FCP} "sudo apt-mark hold kubelet kubectl"

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${FCP} "sudo apt-mark unhold cri-o"&> /dev/null
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${FCP} "sudo apt-get install -qy -o Dpkg::Options::="--force-confold" cri-o=${CRI_SUBVER}~*" &> /dev/null && status=1
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${FCP} "sudo apt-mark hold" &> /dev/null

      ssh ${FCP} "sudo systemctl daemon-reload"
      ssh ${FCP} "sudo systemctl restart --now crio"
      ssh ${FCP} "sudo systemctl restart --now kubelet"
      
      kubectl uncordon ${FCP}
    done

  for OCP in ${other_control_plane}
    do
      OCP_VER=$(kubectl get nodes | grep "${OCP}" | awk '{ print $ 5}')
      if [ "${KUBE_INIT_VER}" == "${OCP_VER}" ]
        then
          echo -e "${YELLOW} - ${OCP} version is already been ${RED}${KUBE_INIT_VER}${NC}"
          continue
      fi
      echo -e "${YELLOW}${OCP} | upgrade procedure${NC}"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${OCP} "sudo dnf versionlock delete kubeadm"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${OCP} "sudo dnf install -y kubeadm-${KUBE_SUBVER} --disableexcludes=kubernetes" 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${OCP} "sudo dnf versionlock add kubeadm"

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${OCP} "sudo dnf versionlock delete kubeadm"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${OCP} "sudo dnf install -y kubeadm-${KUBE_SUBVER} --disableexcludes=kubernetes" 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${OCP} "sudo dnf versionlock add kubeadm"

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${OCP} "sudo apt-get update"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${OCP} "sudo apt-mark unhold kubeadm"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${OCP} "sudo apt-get install -qy kubeadm=${KUBE_SUBVER}-*"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${OCP} "sudo apt-mark hold kubeadm"

      ssh ${OCP} "sudo kubeadm upgrade plan ${KUBE_INIT_VER}"
      ssh ${OCP} "sudo kubeadm upgrade node"

      kubectl drain ${OCP} --ignore-daemonsets

      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${OCP} "sudo dnf versionlock delete kubelet kubectl"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${OCP} "sudo dnf install -y kubelet-${KUBE_SUBVER} kubectl-${KUBE_SUBVER} --disableexcludes=kubernetes" 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${OCP} "sudo dnf versionlock add kubelet kubectl"
      
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${OCP} "sudo dnf versionlock delete cri-o"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && [ "${VER_SWITCH}" == "sub" ] && ssh ${OCP} "sudo dnf install -y cri-o-${CRI_SUBVER}-* crun" > /dev/null 2>&1 && status=1
      [ "${status}" == "0" ] && ssh ${OCP} "sudo dnf install -y cri-o-${CRI_PROVIDES} crun" > /dev/null 2>&1 && status=1
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && [ "${VER_SWITCH}" == "latest" ] && ssh ${OCP} "sudo dnf install -y cri-o-${CRI_RELEASE}.* crun" > /dev/null 2>&1
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${OCP} "sudo dnf versionlock add cri-o"

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${OCP} "sudo dnf versionlock delete kubelet kubectl"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${OCP} "sudo dnf install -y kubelet-${KUBE_SUBVER} kubectl-${KUBE_SUBVER} --disableexcludes=kubernetes" 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${OCP} "sudo dnf versionlock add kubelet kubectl"
      
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${OCP} "sudo dnf versionlock delete cri-o"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && [ "${VER_SWITCH}" == "sub" ] && ssh ${OCP} "sudo dnf install -y cri-o-${CRI_SUBVER}-* crun" > /dev/null 2>&1 && status=1
      [ "${status}" == "0" ] && ssh ${OCP} "sudo dnf install -y cri-o-${CRI_PROVIDES} crun" > /dev/null 2>&1 && status=1
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && [ "${VER_SWITCH}" == "latest" ] && ssh ${OCP} "sudo dnf install -y cri-o-${CRI_RELEASE}.* crun" > /dev/null 2>&1
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${OCP} "sudo dnf versionlock add cri-o"

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${OCP} "sudo apt-mark unhold kubelet kubectl"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${OCP} "sudo apt-get install -qy kubelet=${KUBE_SUBVER}-* kubectl=${KUBE_SUBVER}-*"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${OCP} "sudo apt-mark hold kubelet kubectl"

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${OCP} "sudo apt-mark unhold cri-o"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${OCP} "sudo apt-get install -qy -o Dpkg::Options::="--force-confold" cri-o=${CRI_SUBVER}~*"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${OCP} "sudo apt-mark hold cri-o"

      ssh ${OCP} "sudo systemctl daemon-reload"
      ssh ${OCP} "sudo systemctl restart --now crio"
      ssh ${OCP} "sudo systemctl restart --now kubelet"
      
      kubectl uncordon ${OCP}
    done

  for wlist in ${wk_nodes}
    do
      WORKER_VER=$(kubectl get nodes | grep "${wlist}" | awk '{ print $ 5}')
      if [ "${KUBE_INIT_VER}" == "${WORKER_VER}" ]
        then
          echo -e "${YELLOW} - ${wlist} version is already been ${RED}${KUBE_INIT_VER}${NC}"
          continue
      fi
      echo -e "${YELLOW}${wlist} | upgrade procedure${NC}"

      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf versionlock delete kubeadm"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf install -y kubeadm-${KUBE_SUBVER} --disableexcludes=kubernetes" 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf versionlock add kubeadm"

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf versionlock delete kubeadm"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf install -y kubeadm-${KUBE_SUBVER} --disableexcludes=kubernetes" 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf versionlock add kubeadm"

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-get update"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-mark unhold kubeadm"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-get install -qy kubeadm=${KUBE_SUBVER}-*"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-mark hold kubeadm"
      ssh ${wlist} "sudo kubeadm upgrade node"

      kubectl drain ${wlist} --ignore-daemonsets

      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf versionlock delete kubelet kubectl"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf install -y kubelet-${KUBE_SUBVER} kubectl-${KUBE_SUBVER} --disableexcludes=kubernetes" 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf versionlock add kubelet kubectl"

      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf versionlock delete cri-o"
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && [ "${VER_SWITCH}" == "sub" ] && ssh ${wlist} "sudo dnf install -y cri-o-${CRI_SUBVER}-* crun" > /dev/null 2>&1 && status=1
      [ "${status}" == "0" ] && ssh ${wlist} "sudo dnf install -y cri-o-${CRI_PROVIDES} crun" > /dev/null 2>&1 && status=1
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && [ "${VER_SWITCH}" == "latest" ] && ssh ${wlist} "sudo dnf install -y cri-o-${CRI_RELEASE}.* crun" > /dev/null 2>&1
      [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${wlist} "sudo dnf versionlock add cri-o"

      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf versionlock delete kubelet kubectl"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf install -y kubelet-${KUBE_SUBVER} kubectl-${KUBE_SUBVER} --disableexcludes=kubernetes" 2> /dev/null
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf versionlock add kubelet kubectl"
      
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf versionlock delete cri-o"
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && [ "${VER_SWITCH}" == "sub" ] && ssh ${wlist} "sudo dnf install -y cri-o-${CRI_SUBVER}-* crun" > /dev/null 2>&1 && status=1
      [ "${status}" == "0" ] && ssh ${wlist} "sudo dnf install -y cri-o-${CRI_PROVIDES} crun" > /dev/null 2>&1 && status=1
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && [ "${VER_SWITCH}" == "latest" ] && ssh ${wlist} "sudo dnf install -y cri-o-${CRI_RELEASE}.* crun" > /dev/null 2>&1
      [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${wlist} "sudo dnf versionlock add cri-o"

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-mark unhold kubelet kubectl"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-get install -qy kubelet=${KUBE_SUBVER}-* kubectl=${KUBE_SUBVER}-*"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-mark hold kubelet kubectl"

      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-mark unhold cri-o"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-get install -qy -o Dpkg::Options::="--force-confold" cri-o=${CRI_SUBVER}~*"
      [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${wlist} "sudo apt-mark hold cri-o"

      ssh ${wlist} "sudo systemctl daemon-reload"
      ssh ${wlist} "sudo systemctl restart --now crio"
      ssh ${wlist} "sudo systemctl restart --now kubelet"

      kubectl uncordon ${wlist}
    done; echo
    kubectl get nodes | tail -n +2 | awk '{ print $5 }' | grep ${KUBE_INIT_VER} &> /dev/null
    [ $? == 0 ] && echo -e "${YELLOW}Cluster has been upgraded to ${RED}${KUBE_INIT_VER}${NC}\n" || echo -e "${RED}Cluster has not upgrade to ${RED}${KUBE_INIT_VER}${NC}\n"
;;

cluster-reset) #Reset kubernetes cluster.
  node-selector hosts

  start-info; echo
  echo -e "${YELLOW}StorageClass:${NC}"
  kubectl get storageclass -A | grep 'rook-ceph' | awk '{ print $1 }' | sed ":a;N;s/\n/\ | /g"
  message="${RED}Please confirm this command will destruction cluster!${NC}"
  interrupt ${message}

  echo -n "As you wish"; echo -n "."; sleep 0.5; echo -n "."; sleep 0.5; echo "."; sleep 0.5
  echo -en "${GREEN}"
  #helm calico network
  helm delete calico -n tigera-operator
  kubectl delete namespace tigera-operator
  helm repo remove projectcalico
  #helm metrics
  helm delete metrics-server -n kube-system
  helm repo remove metrics-server
  #delete all
  kubectl delete all --all --all-namespaces
  kubectl delete --all namespaces
  echo -en "${NC}"

  for wclist in ${wk_nodes} ${cp_nodes}
    do
      echo; echo -e "${YELLOW}${wclist} | delete process${NC}"
      echo -en "${GREEN}"
      ssh ${wclist} 'sudo kubeadm reset -f'
      dir-delete-list
      ssh ${wclist} "sudo systemctl restart --now crio"
      ssh ${wclist} "sudo systemctl restart --now kubelet"
      nc -z -w 1 ${IP} 10250 > /dev/null 2>&1
      [ $? == 0 ] && kubectl delete node ${wclist}
    done
  kdm csi-rook wipe-data hosts ${CEPH_DISK}
  kdm csi-rook clean-data
  echo -en "${NC}"
;;

cri-upgrade) #Update crio package.
  node-selector ${@}
  message="${RED}Please confirm this command will let${YELLOW} ${cp_nodes} ${wk_nodes} ${RED}cri-o upgrade!${NC}"
  interrupt ${message}

  for cwlist in ${cp_nodes} ${wk_nodes}
  do
    kubectl drain ${cwlist} --ignore-daemonsets 2> /dev/null
    #install & setup cri-o
    echo -e "\n${YELLOW}${cwlist} | package upgrade procedure${NC}"
    #Add crio、kubernetes package repositories
    pkg-repo-add

    status=0
    CRI_PROVIDES=$(sudo dnf provides cri-o 2> /dev/null | grep 'Provide' | head -n 5 | cut -d '=' -f 2 | grep ${CRI_RELEASE} | head -n 1)

    [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo dnf versionlock delete cri-o" &> /dev/null
    [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && [ "${VER_SWITCH}" == "sub" ] && ssh ${cwlist} "sudo dnf install -y cri-o-${CRI_SUBVER}-* crun" > /dev/null 2>&1 && status=1
    [ "${status}" == "0" ] && ssh ${cwlist} "sudo dnf install -y cri-o-${CRI_PROVIDES} crun" > /dev/null 2>&1 && status=1
    [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && [ "${VER_SWITCH}" == "latest" ] && ssh ${cwlist} "sudo dnf install -y cri-o-${CRI_RELEASE}.* crun" > /dev/null 2>&1
    [ "${CRIO_OS_VERSION}" == "RHEL_8" ] && ssh ${cwlist} "sudo dnf versionlock add cri-o" &> /dev/null

    [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "sudo dnf versionlock delete cri-o" &> /dev/null
    [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && [ "${VER_SWITCH}" == "sub" ] && ssh ${cwlist} "sudo dnf install -y cri-o-${CRI_SUBVER}-* crun" > /dev/null 2>&1 && status=1
    [ "${status}" == "0" ] && ssh ${cwlist} "sudo dnf install -y cri-o-${CRI_PROVIDES} crun" > /dev/null 2>&1 && status=1
    [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && [ "${VER_SWITCH}" == "latest" ] && ssh ${cwlist} "sudo dnf install -y cri-o-${CRI_RELEASE}.* crun" > /dev/null 2>&1
    [ "${CRIO_OS_VERSION}" == "CentOS_8_Stream" ] && ssh ${cwlist} "sudo dnf versionlock add cri-o" &> /dev/null
    
    [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "sudo apt-mark unhold cri-o" &> /dev/null
    [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "sudo apt-get install -qy -o Dpkg::Options::="--force-confold" cri-o=${CRI_SUBVER}~*" &> /dev/null && status=1
    [ "${CRIO_OS_VERSION}" == "xUbuntu_20.04" ] && ssh ${cwlist} "sudo apt-mark hold" &> /dev/null

    echo "`crio-check ${cwlist}`"
    ssh ${cwlist} "sudo systemctl daemon-reload" && echo
    kubectl uncordon ${cwlist}
  done
;;

cri-check) #Check CRI running pods.
  [ -z ${2} ] && node-message ${@} && exit
  node-selector ${@}
  for cwlist in ${cp_nodes} ${wk_nodes}
    do
      echo -e "${YELLOW}${cwlist} | check list${NC}"
      ssh ${cwlist} "sudo crictl ps -a"; echo
    done
;;

cri-clean) #Remove CRI running pods.
  [ -z ${2} ] && node-message ${@} && exit
  node-selector ${@}
  message="${RED}Please confirm this command will delete all container via crio on node:${YELLOW} ${cp_nodes} ${wk_nodes}${NC}"
  interrupt ${message}
  for cwlist in ${cp_nodes} ${wk_nodes}
    do
      echo "${cwlist} | check list"
      cri_list=$(ssh ${cwlist} sudo crictl ps -a | tail -n +2 | awk '{ print $9 }' | tr -s '\n' ' ')
      for list in ${cri_list}
        do
          ssh ${cwlist} "sudo crictl stopp ${list}" &> /dev/null
          ssh ${cwlist} "sudo crictl rmp ${list}" &> /dev/null
        done
      ssh ${cwlist} "sudo crictl ps -a"
      echo
    done
;;

node-check) #Check nodes port | hostname. [ node-check <NETID> <Start> <End> <Port> hostname ]
  [ -z ${2} ] && node-message ${@} && exit

  if [ "${2}" == "hosts" ]
    then
      [ -z ${3} ] && echo -e "${RED}Please input port number. [ node-check hosts <Port> ]${NC}\n" && exit
      port=${3}
      list=$(cat /etc/hosts | grep -v '#' | grep -E '\-m|\-w|kube-vip' | grep "${NETID}" | awk '{ print $1 }')
      echo "Node-checker running..."
      for nodelist in ${list}
        do
          nc -w 1 -z ${nodelist} ${port} &> /dev/null
          port_status=$(echo $?)
          if [ "${4}" == "hostname" ]
            then
              [ "${port_status}" == "0" ] && ssh -o ConnectTimeout=1 -o BatchMode=yes ${nodelist} 'hostname' 2>&1 | grep '@' &> /dev/null
              [ $? == 0 ] && hostname="NO SSH-KEY" || hostname=$(ssh -o ConnectTimeout=1 -o BatchMode=yes ${nodelist} 'hostname' 2> /dev/null)
              [ "${hostname}" != "NO SSH-KEY" ] && ssh -o ConnectTimeout=1 -o BatchMode=yes ${nodelist} 'hostname' 2>&1 | grep 'fingerprint' &> /dev/null
              [ $? == 0 ] && hostname="WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!"
              [ "${port_status}" == "0" ] && echo "${port} Port Pass | ${nodelist} | Hostname: ${hostname}" || echo "- ${port} Port Not Pass | ${nodelist} | Hostname: --"
            else
              [ "${port_status}" == "0" ] && echo "${port} Port Pass | ${nodelist}" || echo "- ${port} Port Not Pass | ${nodelist}"
          fi
        done
    elif [ "${2}" == "non-join" ]
      then
        nc -z -w 1 `hostname` 10250 > /dev/null 2>&1
        [ $? == 0 ] && cluster_list=$(kubectl get nodes | tail -n +2 | awk '{ print $1 }' | tr -s '\n' '|' | sed '$ s/.$//') || echo -e "${RED}This node is not active!${NC}\n" && exit
        echo -e "${YELLOW}non join node list${NC}"
        [ "${cluster_list}" != "" ] && echo -e " > All nodes are joined" || echo -e "`cat /etc/hosts | grep -vE '#|ip6|k8s.org' | grep "${NETID}" | awk '{ print $2 }' | grep -vE ${cluster_list} | tr -s '\n' ' '`\n"
    else
      [ -z "${3}" ] && echo -e "${RED}Please input port number. [ hosts <Port> or <NETID> <Start> <End> <Port> ]${NC}\n" && exit
      declare -i start=$3 end=$4 port=$5; net=$2; nodelist=0
      echo "Node-checker running..."
      for ((start;start<=end; start=start+1))
        do
          nodelist=$(echo "${net}.${start}")
          nc -w 1 -z ${nodelist} ${port} &> /dev/null
          port_status=$(echo $?)
          if [ "${6}" == "hostname" ]
            then
              [ "${port_status}" == "0" ] && ssh -o ConnectTimeout=1 -o BatchMode=yes ${nodelist} 'hostname' 2>&1 | grep '@' &> /dev/null
              [ $? == 0 ] && hostname="NO SSH-KEY" || hostname=$(ssh -o ConnectTimeout=1 -o BatchMode=yes ${nodelist} 'hostname' 2> /dev/null)
              [ "${hostname}" != "NO SSH-KEY" ] && ssh -o ConnectTimeout=1 -o BatchMode=yes ${nodelist} 'hostname' 2>&1 | grep 'fingerprint' &> /dev/null
              [ $? == 0 ] && hostname="WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!"
              [ "${port_status}" == "0" ] && echo "${port} Port Pass | ${nodelist} | Hostname: ${hostname}" || echo "- ${port} Port Not Pass | ${nodelist} | Hostname: --"
            else
              [ "${port_status}" == "0" ] && echo "${port} Port Pass | ${nodelist}" || echo "- ${port} Port Not Pass | ${nodelist}"
          fi
        done
  fi
;;

node-reset) #Reset hosts | specify nodes. [ node-reset <node-name> ... ]
  [ -z ${2} ] && node-message ${@} && exit
  node-selector ${@}
  message="${RED}Please confirm this command will destruction node:${YELLOW} ${cp_nodes} ${wk_nodes}${RED}!${NC}"
  interrupt ${message}

  echo -n "As you wish"; echo -n "."; sleep 0.5; echo -n "."; sleep 0.5; echo "."; sleep 0.5

  for clist in ${cp_nodes}
    do
      status=0
      etcd_pod=$(kubectl get pods -n kube-system | grep 'etcd' | awk '{ print $1 }' | head -n 1)
      etcd_endpoints=$(echo ${etcd_pod} | cut -d '-' -f 2)
      echo -e "${YELLOW}${clist} | delete process${NC}"
      kubectl get nodes | grep "${clist}" &> /dev/null
      [ $? == 0 ] && kubectl delete node ${clist} && status=1
      [ "${status}" == "1" ] && remove_id=$(kubectl exec -it ${etcd_pod} -n kube-system -- etcdctl --endpoints ${NETID}.${etcd_endpoints}:2379 --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key --cacert=/etc/kubernetes/pki/etcd/ca.crt member list | grep "${clist}" | cut -d ',' -f 1)
      [ "${status}" == "1" ] && kubectl exec -it ${etcd_pod} -n kube-system -- etcdctl --endpoints ${NETID}.${etcd_endpoints}:2379 --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key --cacert=/etc/kubernetes/pki/etcd/ca.crt member remove ${remove_id}
      ssh ${clist} 'sudo kubeadm reset -f'
      dir-delete-list

      ssh ${clist} "sudo systemctl enable --now crio"
      ssh ${clist} "sudo systemctl enable --now kubelet"
    done; echo

  for wlist in ${wk_nodes}
    do
      status=0
      echo -e "${YELLOW}${wlist} | delete process${NC}"
      kubectl get nodes | grep "${wlist}" &> /dev/null
      [ $? == 0 ] && kubectl delete node ${wlist} && status=1
      ssh ${wlist} 'sudo kubeadm reset -f'
      dir-delete-list

      ssh ${wlist} "sudo systemctl enable --now crio"
      ssh ${wlist} "sudo systemctl enable --now kubelet"
    done; echo

  node-power reboot ${@}
;;

node-power) #Reboot/Poweroff hosts | specify node. [ <node-name> ... ]
  node-power ${@}
;;
deploy) #Automatic deploy kubernetes cluster. [ kdm deploy calico/flannel hosts 160 169 local-path/rook-ceph ]
  #kdm deploy calico hosts 180 189 rook-ceph
  kdm cp-init ${2}
  kdm cp-join ${3}
  kdm wk-join ${3}
  kdm dns-rollout
  kdm controller-deploy ${4} ${5}
  kdm metrics-deploy
  kdm csi-deploy ${6}
;;

help) #Show script parameters information.
  ls ~/kdm/kdm &> /dev/null
  [ $? == 0 ] && stage=0
  ls ~/bin/kdm &> /dev/null
  [ $? == 0 ] && stage=1
  [ ${stage} == 0 ] && path="kdm/kdm"
  [ ${stage} == 1 ] && path="bin/kdm"

  list=" > sys-| > set-| > sync-| > pkg-| > k9s-"
  number=$(cat ${path} | grep "[a-z])" | sed '/\$/d;/echo/d' | sed 's/)/:/g' | sed 's/^/ > /' | sed 's/#//g' | grep -E "${list}" | wc -l)
  echo -e "${RED}sys-setup | ${number}${NC}"
  
  echo -en "${YELLOW}"
  cat ${path} | grep "[a-z])" | sed '/\$/d;/echo/d' | sed 's/)/:/g' | sed 's/^/ > /' | sed 's/#//g' | grep -E "${list}"; echo
  echo -en "${NC}"

  list=" > cp-| > wk-| > cni-| > csi-| > dns-"
  number=$(cat ${path} | grep "[a-z])" | sed '/\$/d;/echo/d' | sed 's/)/:/g' | sed 's/^/ > /' | sed 's/#//g' | grep -E "${list}" | wc -l)
  echo -e "${RED}Kubernetes-deploy | ${number}${NC}"
  echo "  └─cp-init >> cp-join >> wk-join >> dns-rollout >> controller-deploy >> metrics-deploy >> csi-deploy"
  
  echo -en "${YELLOW}"
  cat ${path} | grep "[a-z])" | sed '/\$/d;/echo/d' | sed 's/)/:/g' | sed 's/^/ > /' | sed 's/#//g' | grep -E "${list}"; echo
  echo -en "${NC}"

  list=" > nodes:| > node-| > pods:| > images:| > image-| > helm-| > cluster-| > cri-| > help:"
  number=$(cat ${path} | grep "[a-z])" | sed '/\$/d;/echo/d' | sed 's/)/:/g' | sed 's/^/ > /' | sed 's/#//g' | grep -E "${list}" | wc -l)
  echo -e "${RED}Kubernetes-functions | $((${number}+2))${NC}"
  service_list=$(cat ${path} | grep "[a-z])" | sed '/\$/d;/echo/d' | sed 's/)//g' | grep '\-deploy' | grep -vE 'cni|csi' | sed 's/-deploy//g' | tr -s '#' '\n' | grep -v '^D' | sed ":a;N;s/\n/| /g;ta")
  echo -en "${YELLOW}"
  echo -e " > <project-name>-deploy: Deploy Kubenetes projects.\n  ${NC}└─ [ ${service_list} ]${YELLOW}"
  echo -e " > <project-name>-rm: Delete Kubenetes projects.\n  ${NC}└─ [ ${service_list} ]${YELLOW}"
  
  cat ${path} | grep "[a-z])" | sed '/\$/d;/echo/d' | sed 's/)/:/g' | sed 's/^/ > /' | sed 's/#//g' | grep -E "${list}"; echo
  echo -en "${NC}"
;;

parm-check) #List all script parameter.
  ls ~/kdm/kdm &> /dev/null
  [ $? == 0 ] && stage=0
  ls ~/bin/kdm &> /dev/null
  [ $? == 0 ] && stage=1
  [ ${stage} == 0 ] && path="kdm/kdm"
  [ ${stage} == 1 ] && path="bin/kdm"
  echo -e "${YELLOW}Parameters check list${NC}"
  cat ${path} | grep "[a-z])" | sed '/\$/d;/echo/d' | sed 's/)/:/g' | sed 's/^/ > /' | sed 's/#//g'; echo
;;

code)
  node-selector hosts
  shift
  for cwlist in ${cp_nodes} ${wk_nodes}
    do
      ssh ${cwlist} "${@}"
    done
;;

test)
  node-selector ${@}

  for cwlist in ${cp_nodes} ${wk_nodes}
    do
      ssh ${cwlist} 'cat /etc/hosts | grep '127.0.0.1' | grep ${HOSTNAME}' &> /dev/null
      [ $? != 0 ] && ssh ${cwlist} 'sudo sed -i "s|127.0.0.1   |127.0.0.1   ${HOSTNAME} |g" /etc/hosts'
      echo "${cwlist} /etc/hosts:"
      ssh ${cwlist} 'cat /etc/hosts | grep '127.0.0.1' | grep ${HOSTNAME}'
    done
;;

"")
  start-info
  echo
;;

*)
  echo -e "${YELLOW} \"${@}\" ${NC}is not effective parameter!"
  echo -e "${RED} Input parameter \"help\" display more information${NC}"
;;

esac